[1mdiff --git a/app.js b/app.js[m
[1mindex 0e0e909..8253667 100644[m
[1m--- a/app.js[m
[1m+++ b/app.js[m
[36m@@ -11,7 +11,26 @@[m [mvar Application = (function () {[m
         var stormpath = require('express-stormpath');[m
         // New Code[m
         var mongo = require('mongodb');[m
[32m+[m[32m        //var uri = 'mongodb://test:testpassword@ds059524.mongolab.com:59524/heroku_0zm5dvb3'[m[41m[m
         var monk = require('monk');[m
[32m+[m[32m        // var MongoClient = mongo.MongoClient[m[41m[m
[32m+[m[32m        // , assert = require('assert');[m[41m[m
[32m+[m[32m        // var MongoDatabase = mongo.MongoDatabase;[m[41m[m
[32m+[m[32m        //[m[41m[m
[32m+[m[32m        // MongoClient.connect(uri, function(err, db) {[m[41m[m
[32m+[m[32m        //   assert.equal(null, err);[m[41m[m
[32m+[m[32m        //   console.log("Connected correctly to server");[m[41m[m
[32m+[m[32m        //   console.log(db)[m[41m[m
[32m+[m[32m        //   db.close();[m[41m[m
[32m+[m[32m        // });[m[41m[m
[32m+[m[32m        //var db = client.GetServer().GetDatabase(uri);[m[41m[m
[32m+[m[32m        // var collection = db.GetCollection("mycollection");[m[41m[m
[32m+[m[32m        // mongo.MongoClient.connect(uri, function(err, db) {[m[41m[m
[32m+[m[32m        //   if(err) throw err;[m[41m[m
[32m+[m[32m        //   //var collection = db.get('marketCollection');[m[41m[m
[32m+[m[32m        //   //console.log(collection);[m[41m[m
[32m+[m[32m        // });[m[41m[m
[32m+[m[32m        // var monk = require('monk');[m[41m[m
         var db = monk('localhost:27017/test2');[m
         var routes = require('./routes/index');[m
         var users = require('./routes/users');[m
[1mdiff --git a/app.ts b/app.ts[m
[1mindex 170e581..1a5adbd 100644[m
[1m--- a/app.ts[m
[1m+++ b/app.ts[m
[36m@@ -19,9 +19,30 @@[m [mclass Application {[m
       var stormpath = require('express-stormpath');[m
       // New Code[m
       var mongo = require('mongodb');[m
[31m-      var monk = require('monk');[m
[32m+[m[32m      //var uri = 'mongodb://test:testpassword@ds059524.mongolab.com:59524/heroku_0zm5dvb3'[m
[32m+[m[32m      var monk = require('monk')[m
[32m+[m[32m      // var MongoClient = mongo.MongoClient[m
[32m+[m[32m      // , assert = require('assert');[m
[32m+[m[32m      // var MongoDatabase = mongo.MongoDatabase;[m
[32m+[m[32m      //[m
[32m+[m[32m      // MongoClient.connect(uri, function(err, db) {[m
[32m+[m[32m      //   assert.equal(null, err);[m
[32m+[m[32m      //   console.log("Connected correctly to server");[m
[32m+[m[32m      //   console.log(db)[m
[32m+[m[32m      //   db.close();[m
[32m+[m[32m      // });[m
[32m+[m[32m      //var db = client.GetServer().GetDatabase(uri);[m
[32m+[m[32m      // var collection = db.GetCollection("mycollection");[m
[32m+[m[32m      // mongo.MongoClient.connect(uri, function(err, db) {[m
[32m+[m[32m      //   if(err) throw err;[m
[32m+[m[32m      //   //var collection = db.get('marketCollection');[m
[32m+[m[32m      //   //console.log(collection);[m
[32m+[m[32m      // });[m
[32m+[m
[32m+[m[32m      // var monk = require('monk');[m
       var db = monk('localhost:27017/test2');[m
 [m
[32m+[m
       var routes = require('./routes/index');[m
       var users = require('./routes/users');[m
       // var fm = require('./routes/foodmarket/FoodMarket');[m
[1mdiff --git a/node_modules/mongodb/node_modules/bson/build/binding.sln b/node_modules/mongodb/node_modules/bson/build/binding.sln[m
[1mindex c8bda8f..5f7e969 100644[m
[1m--- a/node_modules/mongodb/node_modules/bson/build/binding.sln[m
[1m+++ b/node_modules/mongodb/node_modules/bson/build/binding.sln[m
[36m@@ -1,19 +1,19 @@[m
[31m-Microsoft Visual Studio Solution File, Format Version 9.00[m
[31m-# Visual Studio 2005[m
[31m-Project("{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}") = "bson", "bson.vcproj", "{E31A84B9-024B-0643-ADB1-CF3D6769BF22}"[m
[31m-EndProject[m
[31m-Global[m
[31m-	GlobalSection(SolutionConfigurationPlatforms) = preSolution[m
[31m-		Debug|x64 = Debug|x64[m
[31m-		Release|x64 = Release|x64[m
[31m-	EndGlobalSection[m
[31m-	GlobalSection(ProjectConfigurationPlatforms) = postSolution[m
[31m-		{E31A84B9-024B-0643-ADB1-CF3D6769BF22}.Debug|x64.ActiveCfg = Debug|x64[m
[31m-		{E31A84B9-024B-0643-ADB1-CF3D6769BF22}.Debug|x64.Build.0 = Debug|x64[m
[31m-		{E31A84B9-024B-0643-ADB1-CF3D6769BF22}.Release|x64.ActiveCfg = Release|x64[m
[31m-		{E31A84B9-024B-0643-ADB1-CF3D6769BF22}.Release|x64.Build.0 = Release|x64[m
[31m-	EndGlobalSection[m
[31m-	GlobalSection(SolutionProperties) = preSolution[m
[31m-		HideSolutionNode = FALSE[m
[31m-	EndGlobalSection[m
[31m-EndGlobal[m
[32m+[m[32mMicrosoft Visual Studio Solution File, Format Version 13.00[m[41m[m
[32m+[m[32m# Visual Studio 2013[m[41m[m
[32m+[m[32mProject("{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}") = "bson", "bson.vcxproj", "{7BE172C4-F077-9CAD-C3CB-D2EACF81685F}"[m[41m[m
[32m+[m[32mEndProject[m[41m[m
[32m+[m[32mGlobal[m[41m[m
[32m+[m	[32mGlobalSection(SolutionConfigurationPlatforms) = preSolution[m[41m[m
[32m+[m		[32mDebug|x64 = Debug|x64[m[41m[m
[32m+[m		[32mRelease|x64 = Release|x64[m[41m[m
[32m+[m	[32mEndGlobalSection[m[41m[m
[32m+[m	[32mGlobalSection(ProjectConfigurationPlatforms) = postSolution[m[41m[m
[32m+[m		[32m{7BE172C4-F077-9CAD-C3CB-D2EACF81685F}.Debug|x64.ActiveCfg = Debug|x64[m[41m[m
[32m+[m		[32m{7BE172C4-F077-9CAD-C3CB-D2EACF81685F}.Debug|x64.Build.0 = Debug|x64[m[41m[m
[32m+[m		[32m{7BE172C4-F077-9CAD-C3CB-D2EACF81685F}.Release|x64.ActiveCfg = Release|x64[m[41m[m
[32m+[m		[32m{7BE172C4-F077-9CAD-C3CB-D2EACF81685F}.Release|x64.Build.0 = Release|x64[m[41m[m
[32m+[m	[32mEndGlobalSection[m[41m[m
[32m+[m	[32mGlobalSection(SolutionProperties) = preSolution[m[41m[m
[32m+[m		[32mHideSolutionNode = FALSE[m[41m[m
[32m+[m	[32mEndGlobalSection[m[41m[m
[32m+[m[32mEndGlobal[m[41m[m
[1mdiff --git a/node_modules/mongodb/node_modules/bson/build/binding.sln.cache b/node_modules/mongodb/node_modules/bson/build/binding.sln.cache[m
[1mdeleted file mode 100644[m
[1mindex 324e30c..0000000[m
[1m--- a/node_modules/mongodb/node_modules/bson/build/binding.sln.cache[m
[1m+++ /dev/null[m
[36m@@ -1,101 +0,0 @@[m
[31m-ï»¿<Project DefaultTargets="Build" ToolsVersion="2.0" InitialTargets="ValidateSolutionConfiguration;ValidateToolsVersions" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">[m
[31m-  <PropertyGroup>[m
[31m-    <_SolutionProjectConfiguration>Debug|x64</_SolutionProjectConfiguration>[m
[31m-    <_SolutionProjectToolsVersion>2.0</_SolutionProjectToolsVersion>[m
[31m-    <_SolutionProjectCacheVersion>4.0</_SolutionProjectCacheVersion>[m
[31m-  </PropertyGroup>[m
[31m-  <ItemGroup>[m
[31m-    <_SolutionProjectProjects Include="bson.vcproj" />[m
[31m-  </ItemGroup>[m
[31m-  <UsingTask TaskName="Microsoft.Build.Tasks.CreateTemporaryVCProject" AssemblyName="Microsoft.Build.Tasks, Version=2.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a" />[m
[31m-  <UsingTask TaskName="Microsoft.Build.Tasks.ResolveVCProjectOutput" AssemblyName="Microsoft.Build.Tasks, Version=2.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a" />[m
[31m-  <PropertyGroup Condition=" '$(Configuration)' == '' ">[m
[31m-    <Configuration>Debug</Configuration>[m
[31m-  </PropertyGroup>[m
[31m-  <PropertyGroup Condition=" '$(Platform)' == '' ">[m
[31m-    <Platform>x64</Platform>[m
[31m-  </PropertyGroup>[m
[31m-  <PropertyGroup Condition=" ('$(AspNetConfiguration)' == '') ">[m
[31m-    <AspNetConfiguration>$(Configuration)</AspNetConfiguration>[m
[31m-  </PropertyGroup>[m
[31m-  <PropertyGroup>[m
[31m-    <SolutionDir>C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\</SolutionDir>[m
[31m-    <SolutionExt>.sln</SolutionExt>[m
[31m-    <SolutionFileName>binding.sln</SolutionFileName>[m
[31m-    <SolutionName>binding</SolutionName>[m
[31m-    <SolutionPath>C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\binding.sln</SolutionPath>[m
[31m-  </PropertyGroup>[m
[31m-  <PropertyGroup>[m
[31m-    <TargetFrameworkVersion Condition="'$(TargetFrameworkVersion)' == '' and '$(MSBuildToolsVersion)' == '2.0'">v2.0</TargetFrameworkVersion>[m
[31m-    <TargetFrameworkVersion Condition="'$(TargetFrameworkVersion)' == '' and ('$(MSBuildToolsVersion)' == '3.5' or '$(MSBuildToolsVersion)' == '3.0')">v3.5</TargetFrameworkVersion>[m
[31m-    <TargetFrameworkVersion Condition="'$(TargetFrameworkVersion)' == '' and '$(MSBuildToolsVersion)' == '4.0'">v4.0</TargetFrameworkVersion>[m
[31m-  </PropertyGroup>[m
[31m-  <PropertyGroup Condition=" ('$(Configuration)' == 'Debug') and ('$(Platform)' == 'x64') ">[m
[31m-    <CurrentSolutionConfigurationContents>[m
[31m-      <SolutionConfiguration xmlns="">[m
[31m-        <ProjectConfiguration Project="{E31A84B9-024B-0643-ADB1-CF3D6769BF22}">Debug|x64</ProjectConfiguration>[m
[31m-      </SolutionConfiguration>[m
[31m-    </CurrentSolutionConfigurationContents>[m
[31m-  </PropertyGroup>[m
[31m-  <PropertyGroup Condition=" ('$(Configuration)' == 'Release') and ('$(Platform)' == 'x64') ">[m
[31m-    <CurrentSolutionConfigurationContents>[m
[31m-      <SolutionConfiguration xmlns="">[m
[31m-        <ProjectConfiguration Project="{E31A84B9-024B-0643-ADB1-CF3D6769BF22}">Release|x64</ProjectConfiguration>[m
[31m-      </SolutionConfiguration>[m
[31m-    </CurrentSolutionConfigurationContents>[m
[31m-  </PropertyGroup>[m
[31m-  <Target Name="ValidateSolutionConfiguration">[m
[31m-    <Error Text="The specified solution configuration &quot;$(Configuration)|$(Platform)&quot; is invalid. Please specify a valid solution configuration using the Configuration and Platform properties (e.g. MSBuild.exe Solution.sln /p:Configuration=Debug /p:Platform=&quot;Any CPU&quot;) or leave those properties blank to use the default solution configuration." Code="MSB4126" HelpKeyword="MSBuild.SolutionInvalidSolutionConfiguration" Condition="('$(CurrentSolutionConfigurationContents)' == '') and ('$(SkipInvalidConfigurations)' != 'true')" />[m
[31m-    <Warning Text="The specified solution configuration &quot;$(Configuration)|$(Platform)&quot; is invalid. Please specify a valid solution configuration using the Configuration and Platform properties (e.g. MSBuild.exe Solution.sln /p:Configuration=Debug /p:Platform=&quot;Any CPU&quot;) or leave those properties blank to use the default solution configuration." Code="MSB4126" HelpKeyword="MSBuild.SolutionInvalidSolutionConfiguration" Condition="('$(CurrentSolutionConfigurationContents)' == '') and ('$(SkipInvalidConfigurations)' == 'true')" />[m
[31m-    <Message Text="Building solution configuration &quot;$(Configuration)|$(Platform)&quot;." Condition="'$(CurrentSolutionConfigurationContents)' != ''" />[m
[31m-  </Target>[m
[31m-  <Target Name="ValidateToolsVersions">[m
[31m-    <Error Text="The tools version &quot;$(MSBuildToolsVersion)&quot; of the solution does not support building projects with a different tools version." Code="MSB4149" HelpKeyword="MSBuild.SolutionToolsVersionDoesNotSupportProjectToolsVersion" Condition="'$(MSBuildToolsVersion)' == '2.0' and ('$(ProjectToolsVersion)' != '2.0' and '$(ProjectToolsVersion)' != '')" />[m
[31m-  </Target>[m
[31m-  <Target Name="bson" Condition="'$(CurrentSolutionConfigurationContents)' != ''">[m
[31m-    <VCBuild Projects="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\bson.vcproj" ToolPath="$(VCBuildToolPath)" Configuration="Debug|x64" SolutionFile="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\binding.sln" Override="$(VCBuildOverride)" AdditionalLibPaths="$(VCBuildAdditionalLibPaths)" UserEnvironment="$(VCBuildUserEnvironment)" AdditionalOptions="$(VCBuildAdditionalOptions)" Condition=" ('$(Configuration)' == 'Debug') and ('$(Platform)' == 'x64') " />[m
[31m-    <VCBuild Projects="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\bson.vcproj" ToolPath="$(VCBuildToolPath)" Configuration="Release|x64" SolutionFile="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\binding.sln" Override="$(VCBuildOverride)" AdditionalLibPaths="$(VCBuildAdditionalLibPaths)" UserEnvironment="$(VCBuildUserEnvironment)" AdditionalOptions="$(VCBuildAdditionalOptions)" Condition=" ('$(Configuration)' == 'Release') and ('$(Platform)' == 'x64') " />[m
[31m-  </Target>[m
[31m-  <Target Name="bson:Clean" Condition="'$(CurrentSolutionConfigurationContents)' != ''">[m
[31m-    <VCBuild Projects="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\bson.vcproj" ToolPath="$(VCBuildToolPath)" Configuration="Debug|x64" SolutionFile="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\binding.sln" Clean="true" Override="$(VCBuildOverride)" AdditionalLibPaths="$(VCBuildAdditionalLibPaths)" UserEnvironment="$(VCBuildUserEnvironment)" AdditionalOptions="$(VCBuildAdditionalOptions)" Condition=" ('$(Configuration)' == 'Debug') and ('$(Platform)' == 'x64') " />[m
[31m-    <VCBuild Projects="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\bson.vcproj" ToolPath="$(VCBuildToolPath)" Configuration="Release|x64" SolutionFile="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\binding.sln" Clean="true" Override="$(VCBuildOverride)" AdditionalLibPaths="$(VCBuildAdditionalLibPaths)" UserEnvironment="$(VCBuildUserEnvironment)" AdditionalOptions="$(VCBuildAdditionalOptions)" Condition=" ('$(Configuration)' == 'Release') and ('$(Platform)' == 'x64') " />[m
[31m-  </Target>[m
[31m-  <Target Name="bson:Rebuild" Condition="'$(CurrentSolutionConfigurationContents)' != ''">[m
[31m-    <VCBuild Projects="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\bson.vcproj" ToolPath="$(VCBuildToolPath)" Configuration="Debug|x64" SolutionFile="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\binding.sln" Rebuild="true" Override="$(VCBuildOverride)" AdditionalLibPaths="$(VCBuildAdditionalLibPaths)" UserEnvironment="$(VCBuildUserEnvironment)" AdditionalOptions="$(VCBuildAdditionalOptions)" Condition=" ('$(Configuration)' == 'Debug') and ('$(Platform)' == 'x64') " />[m
[31m-    <VCBuild Projects="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\bson.vcproj" ToolPath="$(VCBuildToolPath)" Configuration="Release|x64" SolutionFile="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\binding.sln" Rebuild="true" Override="$(VCBuildOverride)" AdditionalLibPaths="$(VCBuildAdditionalLibPaths)" UserEnvironment="$(VCBuildUserEnvironment)" AdditionalOptions="$(VCBuildAdditionalOptions)" Condition=" ('$(Configuration)' == 'Release') and ('$(Platform)' == 'x64') " />[m
[31m-  </Target>[m
[31m-  <Target Name="bson:Publish" Condition="'$(CurrentSolutionConfigurationContents)' != ''">[m
[31m-    <Warning Text="VC projects do not support the &quot;Publish&quot; target." Code="MSB4076" HelpKeyword="MSBuild.SolutionVCProjectNoPublish" />[m
[31m-    <VCBuild Projects="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\bson.vcproj" ToolPath="$(VCBuildToolPath)" Configuration="Debug|x64" SolutionFile="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\binding.sln" Override="$(VCBuildOverride)" AdditionalLibPaths="$(VCBuildAdditionalLibPaths)" UserEnvironment="$(VCBuildUserEnvironment)" AdditionalOptions="$(VCBuildAdditionalOptions)" Condition=" ('$(Configuration)' == 'Debug') and ('$(Platform)' == 'x64') " />[m
[31m-    <VCBuild Projects="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\bson.vcproj" ToolPath="$(VCBuildToolPath)" Configuration="Release|x64" SolutionFile="C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson\build\binding.sln" Override="$(VCBuildOverride)" AdditionalLibPaths="$(VCBuildAdditionalLibPaths)" UserEnvironment="$(VCBuildUserEnvironment)" AdditionalOptions="$(VCBuildAdditionalOptions)" Condition=" ('$(Configuration)' == 'Release') and ('$(Platform)' == 'x64') " />[m
[31m-  </Target>[m
[31m-  <Target Name="Build" Condition="'$(CurrentSolutionConfigurationContents)' != ''" Outputs="@(CollectedBuildOutput)">[m
[31m-    <MSBuild Condition="@(BuildLevel0) != ''" Projects="@(BuildLevel0)" Properties="Configuration=%(Configuration); Platform=%(Platform); BuildingSolutionFile=true; CurrentSolutionConfigurationContents=$(CurrentSolutionConfigurationContents); SolutionDir=$(SolutionDir); SolutionExt=$(SolutionExt); SolutionFileName=$(SolutionFileName); SolutionName=$(SolutionName); SolutionPath=$(SolutionPath)">[m
[31m-      <Output TaskParameter="TargetOutputs" ItemName="CollectedBuildOutput" />[m
[31m-    </MSBuild>[m
[31m-    <Message Text="The project &quot;%(SkipLevel0.Identity)&quot; is not selected for building in solution configuration &quot;$(Configuration)|$(Platform)&quot;." Condition="@(SkipLevel0) != ''" />[m
[31m-    <Warning Text="The project configuration for project &quot;%(MissingConfigLevel0.Identity)&quot; was not specified in the solution file for the solution configuration &quot;$(Configuration)|$(Platform)&quot;." Code="MSB4121" HelpKeyword="MSBuild.SolutionProjectConfigurationMissing" Condition="@(MissingConfigLevel0) != ''" />[m
[31m-    <CallTarget Targets="bson" RunEachTargetSeparately="true" />[m
[31m-  </Target>[m
[31m-  <Target Name="Clean" Condition="'$(CurrentSolutionConfigurationContents)' != ''">[m
[31m-    <MSBuild Condition="@(BuildLevel0) != ''" Projects="@(BuildLevel0)" Properties="Configuration=%(Configuration); Platform=%(Platform); BuildingSolutionFile=true; CurrentSolutionConfigurationContents=$(CurrentSolutionConfigurationContents); SolutionDir=$(SolutionDir); SolutionExt=$(SolutionExt); SolutionFileName=$(SolutionFileName); SolutionName=$(SolutionName); SolutionPath=$(SolutionPath)" Targets="Clean" />[m
[31m-    <Message Text="The project &quot;%(SkipLevel0.Identity)&quot; is not selected for building in solution configuration &quot;$(Configuration)|$(Platform)&quot;." Condition="@(SkipLevel0) != ''" />[m
[31m-    <Warning Text="The project configuration for project &quot;%(MissingConfigLevel0.Identity)&quot; was not specified in the solution file for the solution configuration &quot;$(Configuration)|$(Platform)&quot;." Code="MSB4121" HelpKeyword="MSBuild.SolutionProjectConfigurationMissing" Condition="@(MissingConfigLevel0) != ''" />[m
[31m-    <CallTarget Targets="bson:Clean" RunEachTargetSeparately="true" />[m
[31m-    <Delete Files="binding.sln.cache" />[m
[31m-  </Target>[m
[31m-  <Target Name="Rebuild" Condition="'$(CurrentSolutionConfigurationContents)' != ''" Outputs="@(CollectedBuildOutput)">[m
[31m-    <MSBuild Condition="@(BuildLevel0) != ''" Projects="@(BuildLevel0)" Properties="Configuration=%(Configuration); Platform=%(Platform); BuildingSolutionFile=true; CurrentSolutionConfigurationContents=$(CurrentSolutionConfigurationContents); SolutionDir=$(SolutionDir); SolutionExt=$(SolutionExt); SolutionFileName=$(SolutionFileName); SolutionName=$(SolutionName); SolutionPath=$(SolutionPath)" Targets="Rebuild">[m
[31m-      <Output TaskParameter="TargetOutputs" ItemName="CollectedBuildOutput" />[m
[31m-    </MSBuild>[m
[31m-    <Message Text="The project &quot;%(SkipLevel0.Identity)&quot; is not selected for building in solution configuration &quot;$(Configuration)|$(Platform)&quot;." Condition="@(SkipLevel0) != ''" />[m
[31m-    <Warning Text="The project configuration for project &quot;%(MissingConfigLevel0.Identity)&quot; was not specified in the solution file for the solution configuration &quot;$(Configuration)|$(Platform)&quot;." Code="MSB4121" HelpKeyword="MSBuild.SolutionProjectConfigurationMissing" Condition="@(MissingConfigLevel0) != ''" />[m
[31m-    <CallTarget Targets="bson:Rebuild" RunEachTargetSeparately="true" />[m
[31m-  </Target>[m
[31m-  <Target Name="Publish" Condition="'$(CurrentSolutionConfigurationContents)' != ''">[m
[31m-    <MSBuild Condition="@(BuildLevel0) != ''" Projects="@(BuildLevel0)" Properties="Configuration=%(Configuration); Platform=%(Platform); BuildingSolutionFile=true; CurrentSolutionConfigurationContents=$(CurrentSolutionConfigurationContents); SolutionDir=$(SolutionDir); SolutionExt=$(SolutionExt); SolutionFileName=$(SolutionFileName); SolutionName=$(SolutionName); SolutionPath=$(SolutionPath)" Targets="Publish" />[m
[31m-    <Message Text="The project &quot;%(SkipLevel0.Identity)&quot; is not selected for building in solution configuration &quot;$(Configuration)|$(Platform)&quot;." Condition="@(SkipLevel0) != ''" />[m
[31m-    <Warning Text="The project configuration for project &quot;%(MissingConfigLevel0.Identity)&quot; was not specified in the solution file for the solution configuration &quot;$(Configuration)|$(Platform)&quot;." Code="MSB4121" HelpKeyword="MSBuild.SolutionProjectConfigurationMissing" Condition="@(MissingConfigLevel0) != ''" />[m
[31m-    <CallTarget Targets="bson:Publish" RunEachTargetSeparately="true" />[m
[31m-  </Target>[m
[31m-</Project>[m
\ No newline at end of file[m
[1mdiff --git a/node_modules/mongodb/node_modules/bson/build/bson.vcproj b/node_modules/mongodb/node_modules/bson/build/bson.vcproj[m
[1mdeleted file mode 100644[m
[1mindex 460e746..0000000[m
[1m--- a/node_modules/mongodb/node_modules/bson/build/bson.vcproj[m
[1m+++ /dev/null[m
[36m@@ -1 +0,0 @@[m
[31m-<?xml version="1.0" encoding="Windows-1252"?><VisualStudioProject Keyword="Win32Proj" Name="bson" ProjectGUID="{E31A84B9-024B-0643-ADB1-CF3D6769BF22}" ProjectType="Visual C++" RootNamespace="bson" Version="8.00"><Platforms><Platform Name="x64"/></Platforms><ToolFiles/><Configurations><Configuration ConfigurationType="2" IntermediateDirectory="$(ConfigurationName)\obj\$(ProjectName)\" Name="Debug|x64" OutputDirectory="$(SolutionDir)$(ConfigurationName)\"><Tool AdditionalIncludeDirectories="C:\Users\Silken\.node-gyp\5.0.0\include\node;C:\Users\Silken\.node-gyp\5.0.0\src;C:\Users\Silken\.node-gyp\5.0.0\deps\uv\include;C:\Users\Silken\.node-gyp\5.0.0\deps\v8\include;..\..\..\..\nan" BasicRuntimeChecks="3" BufferSecurityCheck="true" DebugInformationFormat="3" DisableSpecificWarnings="4351;4355;4800;4251" ExceptionHandling="0" MinimalRebuild="false" Name="VCCLCompilerTool" OmitFramePointers="false" Optimization="0" PreprocessorDefinitions="&quot;NODE_GYP_MODULE_NAME=bson&quot;;&quot;WIN32&quot;;&quot;_CRT_SECURE_NO_DEPRECATE&quot;;&quot;_CRT_NONSTDC_NO_DEPRECATE&quot;;&quot;_HAS_EXCEPTIONS=0&quot;;&quot;BUILDING_V8_SHARED=1&quot;;&quot;BUILDING_UV_SHARED=1&quot;;&quot;BUILDING_NODE_EXTENSION&quot;;&quot;DEBUG&quot;;&quot;_DEBUG&quot;" ProgramDataBaseFileName="$(IntDir)$(ProjectName)\vc80.pdb" RuntimeLibrary="1" StringPooling="true" SuppressStartupBanner="true" WarnAsError="false" WarningLevel="3"/><Tool AdditionalIncludeDirectories="C:\Users\Silken\.node-gyp\5.0.0\include\node;C:\Users\Silken\.node-gyp\5.0.0\src;C:\Users\Silken\.node-gyp\5.0.0\deps\uv\include;C:\Users\Silken\.node-gyp\5.0.0\deps\v8\include;..\..\..\..\nan" Name="VCResourceCompilerTool" PreprocessorDefinitions="&quot;NODE_GYP_MODULE_NAME=bson&quot;;&quot;WIN32&quot;;&quot;_CRT_SECURE_NO_DEPRECATE&quot;;&quot;_CRT_NONSTDC_NO_DEPRECATE&quot;;&quot;_HAS_EXCEPTIONS=0&quot;;&quot;BUILDING_V8_SHARED=1&quot;;&quot;BUILDING_UV_SHARED=1&quot;;&quot;BUILDING_NODE_EXTENSION&quot;;&quot;DEBUG&quot;;&quot;_DEBUG&quot;"/><Tool AdditionalDependencies="$(NOINHERIT) kernel32.lib user32.lib gdi32.lib winspool.lib comdlg32.lib advapi32.lib shell32.lib ole32.lib oleaut32.lib uuid.lib odbc32.lib DelayImp.lib &quot;C:\Users\Silken\.node-gyp\5.0.0\$(ConfigurationName)\node.lib&quot;" AdditionalOptions="/ignore:4199" AllowIsolation="true" DataExecutionPrevention="2" DelayLoadDLLs="iojs.exe;node.exe" GenerateDebugInformation="true" GenerateMapFile="true" IgnoreImportLibrary="true" LinkIncremental="2" MapExports="true" Name="VCLinkerTool" OutputFile="$(OutDir)\$(ProjectName).node" RandomizedBaseAddress="2" SuppressStartupBanner="true" TargetMachine="17"/></Configuration><Configuration ConfigurationType="2" IntermediateDirectory="$(ConfigurationName)\obj\$(ProjectName)\" Name="Release|x64" OutputDirectory="$(SolutionDir)$(ConfigurationName)\"><Tool AdditionalIncludeDirectories="C:\Users\Silken\.node-gyp\5.0.0\include\node;C:\Users\Silken\.node-gyp\5.0.0\src;C:\Users\Silken\.node-gyp\5.0.0\deps\uv\include;C:\Users\Silken\.node-gyp\5.0.0\deps\v8\include;..\..\..\..\nan" AdditionalOptions="/MP" BufferSecurityCheck="true" DebugInformationFormat="3" DisableSpecificWarnings="4351;4355;4800;4251" EnableFunctionLevelLinking="true" EnableIntrinsicFunctions="true" ExceptionHandling="0" FavorSizeOrSpeed="1" InlineFunctionExpansion="2" Name="VCCLCompilerTool" OmitFramePointers="true" Optimization="3" PreprocessorDefinitions="&quot;NODE_GYP_MODULE_NAME=bson&quot;;&quot;WIN32&quot;;&quot;_CRT_SECURE_NO_DEPRECATE&quot;;&quot;_CRT_NONSTDC_NO_DEPRECATE&quot;;&quot;_HAS_EXCEPTIONS=0&quot;;&quot;BUILDING_V8_SHARED=1&quot;;&quot;BUILDING_UV_SHARED=1&quot;;&quot;BUILDING_NODE_EXTENSION&quot;" ProgramDataBaseFileName="$(IntDir)$(ProjectName)\vc80.pdb" RuntimeLibrary="0" RuntimeTypeInfo="false" StringPooling="true" SuppressStartupBanner="true" WarnAsError="false" WarningLevel="3" WholeProgramOptimization="true"/><Tool AdditionalIncludeDirectories="C:\Users\Silken\.node-gyp\5.0.0\include\node;C:\Users\Silken\.node-gyp\5.0.0\src;C:\Users\Silken\.node-gyp\5.0.0\deps\uv\include;C:\Users\Silken\.node-gyp\5.0.0\deps\v8\include;..\..\..\..\nan" Name="VCResourceCompilerTool" PreprocessorDefinitions="&quot;NODE_GYP_MODULE_NAME=bson&quot;;&quot;WIN32&quot;;&quot;_CRT_SECURE_NO_DEPRECATE&quot;;&quot;_CRT_NONSTDC_NO_DEPRECATE&quot;;&quot;_HAS_EXCEPTIONS=0&quot;;&quot;BUILDING_V8_SHARED=1&quot;;&quot;BUILDING_UV_SHARED=1&quot;;&quot;BUILDING_NODE_EXTENSION&quot;"/><Tool AdditionalOptions="/LTCG" Name="VCLibrarianTool"/><Tool AdditionalDependencies="$(NOINHERIT) kernel32.lib user32.lib gdi32.lib winspool.lib comdlg32.lib advapi32.lib shell32.lib ole32.lib oleaut32.lib uuid.lib odbc32.lib DelayImp.lib &quot;C:\Users\Silken\.node-gyp\5.0.0\$(ConfigurationName)\node.lib&quot;" AdditionalOptions="/ignore:4199" AllowIsolation="true" DataExecutionPrevention="2" DelayLoadDLLs="iojs.exe;node.exe" EnableCOMDATFolding="2" GenerateDebugInformation="true" GenerateMapFile="true" IgnoreImportLibrary="true" LinkIncremental="1" LinkTimeCodeGeneration="1" MapExports="true" Name="VCLinkerTool" OptimizeReferences="2" OutputFile="$(OutDir)\$(ProjectName).node" RandomizedBaseAddress="2" SuppressStartupBanner="true" TargetMachine="17"/></Configuration></Configurations><References/><Files><Filter Name=".."><File RelativePath="..\binding.gyp"/><Filter Name="ext"><File RelativePath="..\ext\bson.cc"/></Filter></Filter><Filter Name="C:"><Filter Name="node"><Filter Name="node_modules"><Filter Name="npm"><Filter Name="node_modules"><Filter Name="node-gyp"><Filter Name="src"><File RelativePath="C:\node\node_modules\npm\node_modules\node-gyp\src\win_delay_load_hook.c"/></Filter></Filter></Filter></Filter></Filter></Filter></Filter></Files><Globals/></VisualStudioProject>[m
\ No newline at end of file[m
[1mdiff --git a/node_modules/mongodb/node_modules/bson/build/config.gypi b/node_modules/mongodb/node_modules/bson/build/config.gypi[m
[1mindex 16da611..823097b 100644[m
[1m--- a/node_modules/mongodb/node_modules/bson/build/config.gypi[m
[1m+++ b/node_modules/mongodb/node_modules/bson/build/config.gypi[m
[36m@@ -10,14 +10,14 @@[m
   "variables": {[m
     "asan": 0,[m
     "host_arch": "x64",[m
[31m-    "icu_data_file": "icudt56l.dat",[m
[31m-    "icu_data_in": "../../deps/icu/source/data/in\\icudt56l.dat",[m
[32m+[m[32m    "icu_data_file": "icudt55l.dat",[m
[32m+[m[32m    "icu_data_in": "../../deps/icu/source/data/in\\icudt55l.dat",[m
     "icu_endianness": "l",[m
     "icu_gyp_path": "tools/icu/icu-generic.gyp",[m
     "icu_locales": "en,root",[m
     "icu_path": "deps\\icu",[m
     "icu_small": "true",[m
[31m-    "icu_ver_major": "56",[m
[32m+[m[32m    "icu_ver_major": "55",[m
     "node_byteorder": "little",[m
     "node_install_npm": "true",[m
     "node_prefix": "/usr/local",[m
[36m@@ -43,16 +43,15 @@[m
     "v8_random_seed": 0,[m
     "v8_use_snapshot": 1,[m
     "want_separate_host_toolset": 0,[m
[31m-    "nodedir": "C:\\Users\\Silken\\.node-gyp\\5.0.0",[m
[32m+[m[32m    "nodedir": "C:\\Users\\Felix\\.node-gyp\\4.1.0",[m
     "copy_dev_lib": "true",[m
     "standalone_static_library": 1,[m
     "access": "",[m
[31m-    "also": "",[m
     "always_auth": "",[m
     "bin_links": "true",[m
     "browser": "",[m
     "ca": "",[m
[31m-    "cache": "C:\\Users\\Silken\\AppData\\Roaming\\npm-cache",[m
[32m+[m[32m    "cache": "C:\\Users\\Felix\\AppData\\Roaming\\npm-cache",[m
     "cache_lock_retries": "10",[m
     "cache_lock_stale": "60000",[m
     "cache_lock_wait": "10000",[m
[36m@@ -64,7 +63,6 @@[m
     "depth": "Infinity",[m
     "description": "true",[m
     "dev": "",[m
[31m-    "dry_run": "",[m
     "editor": "notepad.exe",[m
     "engine_strict": "",[m
     "fetch_retries": "2",[m
[36m@@ -75,8 +73,8 @@[m
     "git": "git",[m
     "git_tag_version": "true",[m
     "global": "",[m
[31m-    "globalconfig": "C:\\Users\\Silken\\AppData\\Roaming\\npm\\etc\\npmrc",[m
[31m-    "globalignorefile": "C:\\Users\\Silken\\AppData\\Roaming\\npm\\etc\\npmignore",[m
[32m+[m[32m    "globalconfig": "C:\\Users\\Felix\\AppData\\Roaming\\npm\\etc\\npmrc",[m
[32m+[m[32m    "globalignorefile": "C:\\Users\\Felix\\AppData\\Roaming\\npm\\etc\\npmignore",[m
     "group": "",[m
     "heading": "npm",[m
     "https_proxy": "",[m
[36m@@ -86,7 +84,7 @@[m
     "init_author_name": "",[m
     "init_author_url": "",[m
     "init_license": "ISC",[m
[31m-    "init_module": "C:\\Users\\Silken\\.npm-init.js",[m
[32m+[m[32m    "init_module": "C:\\Users\\Felix\\.npm-init.js",[m
     "init_version": "1.0.0",[m
     "json": "",[m
     "key": "",[m
[36m@@ -94,20 +92,18 @@[m
     "local_address": "",[m
     "long": "",[m
     "message": "%s",[m
[31m-    "node_version": "5.0.0",[m
[32m+[m[32m    "node_version": "4.1.0",[m
     "npat": "",[m
     "onload_script": "",[m
[31m-    "only": "",[m
     "optional": "true",[m
     "parseable": "",[m
[31m-    "prefix": "C:\\Users\\Silken\\AppData\\Roaming\\npm",[m
[32m+[m[32m    "prefix": "C:\\Users\\Felix\\AppData\\Roaming\\npm",[m
     "production": "",[m
[31m-    "progress": "true",[m
     "proprietary_attribs": "true",[m
     "rebuild_bundle": "true",[m
     "registry": "https://registry.npmjs.org/",[m
     "rollback": "true",[m
[31m-    "save": "",[m
[32m+[m[32m    "save": "true",[m
     "save_bundle": "",[m
     "save_dev": "",[m
     "save_exact": "",[m
[36m@@ -117,20 +113,21 @@[m
     "searchexclude": "",[m
     "searchopts": "",[m
     "searchsort": "name",[m
[31m-    "shell": "C:\\WINDOWS\\system32\\cmd.exe",[m
[32m+[m[32m    "shell": "C:\\Windows\\system32\\cmd.exe",[m
     "shrinkwrap": "true",[m
     "sign_git_tag": "",[m
[32m+[m[32m    "spin": "true",[m
     "strict_ssl": "true",[m
     "tag": "latest",[m
     "tag_version_prefix": "v",[m
[31m-    "tmp": "C:\\Users\\Silken\\AppData\\Local\\Temp",[m
[32m+[m[32m    "tmp": "C:\\Users\\Felix\\AppData\\Local\\Temp",[m
     "umask": "0000",[m
     "unicode": "true",[m
     "unsafe_perm": "true",[m
     "usage": "",[m
     "user": "",[m
[31m-    "userconfig": "C:\\Users\\Silken\\.npmrc",[m
[31m-    "user_agent": "npm/3.3.6 node/v5.0.0 win32 x64",[m
[32m+[m[32m    "userconfig": "C:\\Users\\Felix\\.npmrc",[m
[32m+[m[32m    "user_agent": "npm/2.14.3 node/v4.1.0 win32 x64",[m
     "version": "",[m
     "versions": "",[m
     "viewer": "browser"[m
[1mdiff --git a/node_modules/mongodb/node_modules/bson/builderror.log b/node_modules/mongodb/node_modules/bson/builderror.log[m
[1mindex 5f076f4..45aedf6 100644[m
[1m--- a/node_modules/mongodb/node_modules/bson/builderror.log[m
[1m+++ b/node_modules/mongodb/node_modules/bson/builderror.log[m
[36m@@ -1,12 +1,14 @@[m
 gyp ERR! build error [m
[31m-gyp ERR! stack Error: `C:\Windows\Microsoft.NET\Framework\v4.0.30319\msbuild.exe` failed with exit code: 1[m
[31m-gyp ERR! stack     at ChildProcess.onExit (C:\node\node_modules\npm\node_modules\node-gyp\lib\build.js:270:23)[m
[31m-gyp ERR! stack     at emitTwo (events.js:87:13)[m
[31m-gyp ERR! stack     at ChildProcess.emit (events.js:172:7)[m
[31m-gyp ERR! stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:200:12)[m
[32m+[m[32mgyp ERR! stack Error: Can't find "msbuild.exe". Do you have Microsoft Visual Studio C++ 2008+ installed?[m
[32m+[m[32mgyp ERR! stack     at findMsbuild (c:\Program Files\nodejs\node_modules\npm\node_modules\node-gyp\lib\build.js:122:23)[m
[32m+[m[32mgyp ERR! stack     at c:\Program Files\nodejs\node_modules\npm\node_modules\node-gyp\lib\build.js:104:11[m
[32m+[m[32mgyp ERR! stack     at F (c:\Program Files\nodejs\node_modules\npm\node_modules\which\which.js:72:25)[m
[32m+[m[32mgyp ERR! stack     at E (c:\Program Files\nodejs\node_modules\npm\node_modules\which\which.js:75:29)[m
[32m+[m[32mgyp ERR! stack     at c:\Program Files\nodejs\node_modules\npm\node_modules\which\which.js:83:16[m
[32m+[m[32mgyp ERR! stack     at FSReqWrap.oncomplete (fs.js:82:15)[m
 gyp ERR! System Windows_NT 6.3.9600[m
[31m-gyp ERR! command "C:\\node\\node.exe" "C:\\node\\node_modules\\npm\\node_modules\\node-gyp\\bin\\node-gyp.js" "rebuild"[m
[31m-gyp ERR! cwd C:\Users\Silken\node\IDE-A\node_modules\mongodb\node_modules\bson[m
[31m-gyp ERR! node -v v5.0.0[m
[32m+[m[32mgyp ERR! command "c:\\Program Files\\nodejs\\node.exe" "c:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\node-gyp\\bin\\node-gyp.js" "rebuild"[m
[32m+[m[32mgyp ERR! cwd c:\node\nodetest2\IDE-A\node_modules\mongodb\node_modules\bson[m
[32m+[m[32mgyp ERR! node -v v4.1.0[m
 gyp ERR! node-gyp -v v3.0.3[m
 gyp ERR! not ok [m
[1mdiff --git a/node_modules/mongodb/node_modules/bson/ext/bson.cc b/node_modules/mongodb/node_modules/bson/ext/bson.cc[m
[1mindex 0c41049..90e2ef9 100644[m
[1m--- a/node_modules/mongodb/node_modules/bson/ext/bson.cc[m
[1m+++ b/node_modules/mongodb/node_modules/bson/ext/bson.cc[m
[36m@@ -1,1072 +1,1072 @@[m
[31m-//===========================================================================[m
[31m-[m
[31m-#include <stdarg.h>[m
[31m-#include <cstdlib>[m
[31m-#include <cstring>[m
[31m-#include <string.h>[m
[31m-#include <stdlib.h>[m
[31m-[m
[31m-#ifdef __clang__[m
[31m-#pragma clang diagnostic push[m
[31m-#pragma clang diagnostic ignored "-Wunused-parameter"[m
[31m-#endif[m
[31m-[m
[31m-#include <v8.h>[m
[31m-[m
[31m-// this and the above block must be around the v8.h header otherwise[m
[31m-// v8 is not happy[m
[31m-#ifdef __clang__[m
[31m-#pragma clang diagnostic pop[m
[31m-#endif[m
[31m-[m
[31m-#include <node.h>[m
[31m-#include <node_version.h>[m
[31m-#include <node_buffer.h>[m
[31m-[m
[31m-#include <cmath>[m
[31m-#include <iostream>[m
[31m-#include <limits>[m
[31m-#include <vector>[m
[31m-#include <errno.h>[m
[31m-[m
[31m-#if defined(__sun) || defined(_AIX)[m
[31m-	#include <alloca.h>[m
[31m-#endif[m
[31m-[m
[31m-#include "bson.h"[m
[31m-[m
[31m-using namespace v8;[m
[31m-using namespace node;[m
[31m-[m
[31m-void die(const char *message) {[m
[31m-	if(errno) {[m
[31m-		perror(message);[m
[31m-	} else {[m
[31m-		printf("ERROR: %s\n", message);[m
[31m-	}[m
[31m-[m
[31m-	exit(1);[m
[31m-}[m
[31m-[m
[31m-//===========================================================================[m
[31m-[m
[31m-void DataStream::WriteObjectId(const Handle<Object>& object, const Handle<String>& key)[m
[31m-{[m
[31m-	uint16_t buffer[12];[m
[31m-	object->Get(key)->ToString()->Write(buffer, 0, 12);[m
[31m-	for(uint32_t i = 0; i < 12; ++i)[m
[31m-	{[m
[31m-		*p++ = (char) buffer[i];[m
[31m-	}[m
[31m-}[m
[31m-[m
[31m-void ThrowAllocatedStringException(size_t allocationSize, const char* format, ...)[m
[31m-{[m
[31m-	va_list args;[m
[31m-	va_start(args, format);[m
[31m-	char* string = (char*) malloc(allocationSize);[m
[31m-	if(string == NULL) die("Failed to allocate ThrowAllocatedStringException");[m
[31m-	vsprintf(string, format, args);[m
[31m-	va_end(args);[m
[31m-	throw string;[m
[31m-}[m
[31m-[m
[31m-void DataStream::CheckKey(const Local<String>& keyName)[m
[31m-{[m
[31m-	size_t keyLength = keyName->Utf8Length();[m
[31m-	if(keyLength == 0) return;[m
[31m-[m
[31m-	// Allocate space for the key, do not need to zero terminate as WriteUtf8 does it[m
[31m-	char* keyStringBuffer = (char*) alloca(keyLength + 1);[m
[31m-	// Write the key to the allocated buffer[m
[31m-	keyName->WriteUtf8(keyStringBuffer);[m
[31m-	// Check for the zero terminator[m
[31m-	char* terminator = strchr(keyStringBuffer, 0x00);[m
[31m-[m
[31m-	// If the location is not at the end of the string we've got an illegal 0x00 byte somewhere[m
[31m-	if(terminator != &keyStringBuffer[keyLength]) {[m
[31m-		ThrowAllocatedStringException(64+keyLength, "key %s must not contain null bytes", keyStringBuffer);[m
[31m-	}[m
[31m-[m
[31m-	if(keyStringBuffer[0] == '$')[m
[31m-	{[m
[31m-		ThrowAllocatedStringException(64+keyLength, "key %s must not start with '$'", keyStringBuffer);[m
[31m-	}[m
[31m-[m
[31m-	if(strchr(keyStringBuffer, '.') != NULL)[m
[31m-	{[m
[31m-		ThrowAllocatedStringException(64+keyLength, "key %s must not contain '.'", keyStringBuffer);[m
[31m-	}[m
[31m-}[m
[31m-[m
[31m-template<typename T> void BSONSerializer<T>::SerializeDocument(const Handle<Value>& value)[m
[31m-{[m
[31m-	void* documentSize = this->BeginWriteSize();[m
[31m-	Local<Object> object = bson->GetSerializeObject(value);[m
[31m-[m
[31m-	// Get the object property names[m
[31m-  Local<Array> propertyNames = object->GetPropertyNames();[m
[31m-[m
[31m-	// Length of the property[m
[31m-	int propertyLength = propertyNames->Length();[m
[31m-	for(int i = 0;  i < propertyLength; ++i)[m
[31m-	{[m
[31m-		const Local<String>& propertyName = propertyNames->Get(i)->ToString();[m
[31m-		if(checkKeys) this->CheckKey(propertyName);[m
[31m-[m
[31m-		const Local<Value>& propertyValue = object->Get(propertyName);[m
[31m-[m
[31m-		if(serializeFunctions || !propertyValue->IsFunction())[m
[31m-		{[m
[31m-			void* typeLocation = this->BeginWriteType();[m
[31m-			this->WriteString(propertyName);[m
[31m-			SerializeValue(typeLocation, propertyValue);[m
[31m-		}[m
[31m-	}[m
[31m-[m
[31m-	this->WriteByte(0);[m
[31m-	this->CommitSize(documentSize);[m
[31m-}[m
[31m-[m
[31m-template<typename T> void BSONSerializer<T>::SerializeArray(const Handle<Value>& value)[m
[31m-{[m
[31m-	void* documentSize = this->BeginWriteSize();[m
[31m-[m
[31m-	Local<Array> array = Local<Array>::Cast(value->ToObject());[m
[31m-	uint32_t arrayLength = array->Length();[m
[31m-[m
[31m-	for(uint32_t i = 0;  i < arrayLength; ++i)[m
[31m-	{[m
[31m-		void* typeLocation = this->BeginWriteType();[m
[31m-		this->WriteUInt32String(i);[m
[31m-		SerializeValue(typeLocation, array->Get(i));[m
[31m-	}[m
[31m-[m
[31m-	this->WriteByte(0);[m
[31m-	this->CommitSize(documentSize);[m
[31m-}[m
[31m-[m
[31m-// This is templated so that we can use this function to both count the number of bytes, and to serialize those bytes.[m
[31m-// The template approach eliminates almost all of the inspection of values unless they're required (eg. string lengths)[m
[31m-// and ensures that there is always consistency between bytes counted and bytes written by design.[m
[31m-template<typename T> void BSONSerializer<T>::SerializeValue(void* typeLocation, const Handle<Value> constValue)[m
[31m-{[m
[31m-	// Turn into local value[m
[31m-	Local<Value> value = NanNew<Value>(constValue);[m
[31m-[m
[31m-	// Check for toBSON function[m
[31m-	if(value->IsObject()) {[m
[31m-		Local<Object> object = value->ToObject();[m
[31m-[m
[31m-		// NanNew<String>("toBSON")[m
[31m-		// NanNew(BSON::_toBSONString)[m
[31m-[m
[31m-		if(object->Has(NanNew<String>("toBSON"))) {[m
[31m-			const Local<Value>& toBSON = object->Get(NanNew<String>("toBSON"));[m
[31m-			if(!toBSON->IsFunction()) ThrowAllocatedStringException(64, "toBSON is not a function");[m
[31m-			value = Local<Function>::Cast(toBSON)->Call(object, 0, NULL);[m
[31m-		}[m
[31m-	}[m
[31m-[m
[31m-	// Process all the values[m
[31m-	if(value->IsNumber())[m
[31m-	{[m
[31m-		double doubleValue = value->NumberValue();[m
[31m-		int intValue = (int) doubleValue;[m
[31m-		if(intValue == doubleValue)[m
[31m-		{[m
[31m-			this->CommitType(typeLocation, BSON_TYPE_INT);[m
[31m-			this->WriteInt32(intValue);[m
[31m-		}[m
[31m-		else[m
[31m-		{[m
[31m-			this->CommitType(typeLocation, BSON_TYPE_NUMBER);[m
[31m-			this->WriteDouble(doubleValue);[m
[31m-		}[m
[31m-	}[m
[31m-	else if(value->IsString())[m
[31m-	{[m
[31m-		this->CommitType(typeLocation, BSON_TYPE_STRING);[m
[31m-		this->WriteLengthPrefixedString(value->ToString());[m
[31m-	}[m
[31m-	else if(value->IsBoolean())[m
[31m-	{[m
[31m-		this->CommitType(typeLocation, BSON_TYPE_BOOLEAN);[m
[31m-		this->WriteBool(value);[m
[31m-	}[m
[31m-	else if(value->IsArray())[m
[31m-	{[m
[31m-		this->CommitType(typeLocation, BSON_TYPE_ARRAY);[m
[31m-		SerializeArray(value);[m
[31m-	}[m
[31m-	else if(value->IsDate())[m
[31m-	{[m
[31m-		this->CommitType(typeLocation, BSON_TYPE_DATE);[m
[31m-		this->WriteInt64(value);[m
[31m-	}[m
[31m-	else if(value->IsRegExp())[m
[31m-	{[m
[31m-		this->CommitType(typeLocation, BSON_TYPE_REGEXP);[m
[31m-		const Handle<RegExp>& regExp = Handle<RegExp>::Cast(value);[m
[31m-[m
[31m-		this->WriteString(regExp->GetSource());[m
[31m-[m
[31m-		int flags = regExp->GetFlags();[m
[31m-		if(flags & RegExp::kGlobal) this->WriteByte('s');[m
[31m-		if(flags & RegExp::kIgnoreCase) this->WriteByte('i');[m
[31m-		if(flags & RegExp::kMultiline) this->WriteByte('m');[m
[31m-		this->WriteByte(0);[m
[31m-	}[m
[31m-	else if(value->IsFunction())[m
[31m-	{[m
[31m-		this->CommitType(typeLocation, BSON_TYPE_CODE);[m
[31m-		this->WriteLengthPrefixedString(value->ToString());[m
[31m-	}[m
[31m-	else if(value->IsObject())[m
[31m-	{[m
[31m-		const Local<Object>& object = value->ToObject();[m
[31m-		if(object->Has(NanNew(bson->_bsontypeString)))[m
[31m-		{[m
[31m-			const Local<String>& constructorString = object->Get(NanNew(bson->_bsontypeString))->ToString();[m
[31m-			if(NanNew(bson->longString)->StrictEquals(constructorString))[m
[31m-			{[m
[31m-				this->CommitType(typeLocation, BSON_TYPE_LONG);[m
[31m-				this->WriteInt32(object, NanNew(bson->_longLowString));[m
[31m-				this->WriteInt32(object, NanNew(bson->_longHighString));[m
[31m-			}[m
[31m-			else if(NanNew(bson->timestampString)->StrictEquals(constructorString))[m
[31m-			{[m
[31m-				this->CommitType(typeLocation, BSON_TYPE_TIMESTAMP);[m
[31m-				this->WriteInt32(object, NanNew(bson->_longLowString));[m
[31m-				this->WriteInt32(object, NanNew(bson->_longHighString));[m
[31m-			}[m
[31m-			else if(NanNew(bson->objectIDString)->StrictEquals(constructorString))[m
[31m-			{[m
[31m-				this->CommitType(typeLocation, BSON_TYPE_OID);[m
[31m-				this->WriteObjectId(object, NanNew(bson->_objectIDidString));[m
[31m-			}[m
[31m-			else if(NanNew(bson->binaryString)->StrictEquals(constructorString))[m
[31m-			{[m
[31m-				this->CommitType(typeLocation, BSON_TYPE_BINARY);[m
[31m-[m
[31m-				uint32_t length = object->Get(NanNew(bson->_binaryPositionString))->Uint32Value();[m
[31m-				Local<Object> bufferObj = object->Get(NanNew(bson->_binaryBufferString))->ToObject();[m
[31m-[m
[31m-				this->WriteInt32(length);[m
[31m-				this->WriteByte(object, NanNew(bson->_binarySubTypeString));	// write subtype[m
[31m-				// If type 0x02 write the array length aswell[m
[31m-				if(object->Get(NanNew(bson->_binarySubTypeString))->Int32Value() == 0x02) {[m
[31m-					this->WriteInt32(length);[m
[31m-				}[m
[31m-				// Write the actual data[m
[31m-				this->WriteData(Buffer::Data(bufferObj), length);[m
[31m-			}[m
[31m-			else if(NanNew(bson->doubleString)->StrictEquals(constructorString))[m
[31m-			{[m
[31m-				this->CommitType(typeLocation, BSON_TYPE_NUMBER);[m
[31m-				this->WriteDouble(object, NanNew(bson->_doubleValueString));[m
[31m-			}[m
[31m-			else if(NanNew(bson->symbolString)->StrictEquals(constructorString))[m
[31m-			{[m
[31m-				this->CommitType(typeLocation, BSON_TYPE_SYMBOL);[m
[31m-				this->WriteLengthPrefixedString(object->Get(NanNew(bson->_symbolValueString))->ToString());[m
[31m-			}[m
[31m-			else if(NanNew(bson->codeString)->StrictEquals(constructorString))[m
[31m-			{[m
[31m-				const Local<String>& function = object->Get(NanNew(bson->_codeCodeString))->ToString();[m
[31m-				const Local<Object>& scope = object->Get(NanNew(bson->_codeScopeString))->ToObject();[m
[31m-[m
[31m-				// For Node < 0.6.X use the GetPropertyNames[m
[31m-	      #if NODE_MAJOR_VERSION == 0 && NODE_MINOR_VERSION < 6[m
[31m-	        uint32_t propertyNameLength = scope->GetPropertyNames()->Length();[m
[31m-	      #else[m
[31m-	        uint32_t propertyNameLength = scope->GetOwnPropertyNames()->Length();[m
[31m-	      #endif[m
[31m-[m
[31m-				if(propertyNameLength > 0)[m
[31m-				{[m
[31m-					this->CommitType(typeLocation, BSON_TYPE_CODE_W_SCOPE);[m
[31m-					void* codeWidthScopeSize = this->BeginWriteSize();[m
[31m-					this->WriteLengthPrefixedString(function->ToString());[m
[31m-					SerializeDocument(scope);[m
[31m-					this->CommitSize(codeWidthScopeSize);[m
[31m-				}[m
[31m-				else[m
[31m-				{[m
[31m-					this->CommitType(typeLocation, BSON_TYPE_CODE);[m
[31m-					this->WriteLengthPrefixedString(function->ToString());[m
[31m-				}[m
[31m-			}[m
[31m-			else if(NanNew(bson->dbrefString)->StrictEquals(constructorString))[m
[31m-			{[m
[31m-				this->CommitType(typeLocation, BSON_TYPE_OBJECT);[m
[31m-[m
[31m-				void* dbRefSize = this->BeginWriteSize();[m
[31m-[m
[31m-				void* refType = this->BeginWriteType();[m
[31m-				this->WriteData("$ref", 5);[m
[31m-				SerializeValue(refType, object->Get(NanNew(bson->_dbRefNamespaceString)));[m
[31m-[m
[31m-				void* idType = this->BeginWriteType();[m
[31m-				this->WriteData("$id", 4);[m
[31m-				SerializeValue(idType, object->Get(NanNew(bson->_dbRefOidString)));[m
[31m-[m
[31m-				const Local<Value>& refDbValue = object->Get(NanNew(bson->_dbRefDbString));[m
[31m-				if(!refDbValue->IsUndefined())[m
[31m-				{[m
[31m-					void* dbType = this->BeginWriteType();[m
[31m-					this->WriteData("$db", 4);[m
[31m-					SerializeValue(dbType, refDbValue);[m
[31m-				}[m
[31m-[m
[31m-				this->WriteByte(0);[m
[31m-				this->CommitSize(dbRefSize);[m
[31m-			}[m
[31m-			else if(NanNew(bson->minKeyString)->StrictEquals(constructorString))[m
[31m-			{[m
[31m-				this->CommitType(typeLocation, BSON_TYPE_MIN_KEY);[m
[31m-			}[m
[31m-			else if(NanNew(bson->maxKeyString)->StrictEquals(constructorString))[m
[31m-			{[m
[31m-				this->CommitType(typeLocation, BSON_TYPE_MAX_KEY);[m
[31m-			}[m
[31m-		}[m
[31m-		else if(Buffer::HasInstance(value))[m
[31m-		{[m
[31m-			this->CommitType(typeLocation, BSON_TYPE_BINARY);[m
[31m-[m
[31m-	    #if NODE_MAJOR_VERSION == 0 && NODE_MINOR_VERSION < 3[m
[31m-       Local<Object> buffer = ObjectWrap::Unwrap<Buffer>(value->ToObject());[m
[31m-			 uint32_t length = object->length();[m
[31m-	    #else[m
[31m-			 uint32_t length = Buffer::Length(value->ToObject());[m
[31m-	    #endif[m
[31m-[m
[31m-			this->WriteInt32(length);[m
[31m-			this->WriteByte(0);[m
[31m-			this->WriteData(Buffer::Data(value->ToObject()), length);[m
[31m-		}[m
[31m-		else[m
[31m-		{[m
[31m-			this->CommitType(typeLocation, BSON_TYPE_OBJECT);[m
[31m-			SerializeDocument(value);[m
[31m-		}[m
[31m-	}[m
[31m-	else if(value->IsNull() || value->IsUndefined())[m
[31m-	{[m
[31m-		this->CommitType(typeLocation, BSON_TYPE_NULL);[m
[31m-	}[m
[31m-}[m
[31m-[m
[31m-// Data points to start of element list, length is length of entire document including '\0' but excluding initial size[m
[31m-BSONDeserializer::BSONDeserializer(BSON* aBson, char* data, size_t length)[m
[31m-: bson(aBson),[m
[31m-  pStart(data),[m
[31m-  p(data),[m
[31m-  pEnd(data + length - 1)[m
[31m-{[m
[31m-	if(*pEnd != '\0') ThrowAllocatedStringException(64, "Missing end of document marker '\\0'");[m
[31m-}[m
[31m-[m
[31m-BSONDeserializer::BSONDeserializer(BSONDeserializer& parentSerializer, size_t length)[m
[31m-: bson(parentSerializer.bson),[m
[31m-  pStart(parentSerializer.p),[m
[31m-  p(parentSerializer.p),[m
[31m-  pEnd(parentSerializer.p + length - 1)[m
[31m-{[m
[31m-	parentSerializer.p += length;[m
[31m-	if(pEnd > parentSerializer.pEnd) ThrowAllocatedStringException(64, "Child document exceeds parent's bounds");[m
[31m-	if(*pEnd != '\0') ThrowAllocatedStringException(64, "Missing end of document marker '\\0'");[m
[31m-}[m
[31m-[m
[31m-Handle<Value> BSONDeserializer::ReadCString()[m
[31m-{[m
[31m-	char* start = p;[m
[31m-	while(*p++ && (p < pEnd)) { }[m
[31m-	if(p > pEnd) {[m
[31m-		return NanNull();[m
[31m-	}[m
[31m-	return NanNew<String>(start, (int32_t) (p-start-1) );[m
[31m-}[m
[31m-[m
[31m-int32_t BSONDeserializer::ReadRegexOptions()[m
[31m-{[m
[31m-	int32_t options = 0;[m
[31m-	for(;;)[m
[31m-	{[m
[31m-		switch(*p++)[m
[31m-		{[m
[31m-		case '\0': return options;[m
[31m-		case 's': options |= RegExp::kGlobal; break;[m
[31m-		case 'i': options |= RegExp::kIgnoreCase; break;[m
[31m-		case 'm': options |= RegExp::kMultiline; break;[m
[31m-		}[m
[31m-	}[m
[31m-}[m
[31m-[m
[31m-uint32_t BSONDeserializer::ReadIntegerString()[m
[31m-{[m
[31m-	uint32_t value = 0;[m
[31m-	while(*p)[m
[31m-	{[m
[31m-		if(*p < '0' || *p > '9') ThrowAllocatedStringException(64, "Invalid key for array");[m
[31m-		value = value * 10 + *p++ - '0';[m
[31m-	}[m
[31m-	++p;[m
[31m-	return value;[m
[31m-}[m
[31m-[m
[31m-Local<String> BSONDeserializer::ReadString()[m
[31m-{[m
[31m-	uint32_t length = ReadUInt32();[m
[31m-	char* start = p;[m
[31m-	p += length;[m
[31m-	return NanNew<String>(start, length-1);[m
[31m-}[m
[31m-[m
[31m-Local<String> BSONDeserializer::ReadObjectId()[m
[31m-{[m
[31m-	uint16_t objectId[12];[m
[31m-	for(size_t i = 0; i < 12; ++i)[m
[31m-	{[m
[31m-		objectId[i] = *reinterpret_cast<unsigned char*>(p++);[m
[31m-	}[m
[31m-	return NanNew<String>(objectId, 12);[m
[31m-}[m
[31m-[m
[31m-Handle<Value> BSONDeserializer::DeserializeDocument(bool promoteLongs)[m
[31m-{[m
[31m-	uint32_t length = ReadUInt32();[m
[31m-	if(length < 5) ThrowAllocatedStringException(64, "Bad BSON: Document is less than 5 bytes");[m
[31m-[m
[31m-	BSONDeserializer documentDeserializer(*this, length-4);[m
[31m-	return documentDeserializer.DeserializeDocumentInternal(promoteLongs);[m
[31m-}[m
[31m-[m
[31m-Handle<Value> BSONDeserializer::DeserializeDocumentInternal(bool promoteLongs)[m
[31m-{[m
[31m-	Local<Object> returnObject = NanNew<Object>();[m
[31m-[m
[31m-	while(HasMoreData())[m
[31m-	{[m
[31m-		BsonType type = (BsonType) ReadByte();[m
[31m-		const Handle<Value>& name = ReadCString();[m
[31m-		if(name->IsNull()) ThrowAllocatedStringException(64, "Bad BSON Document: illegal CString");[m
[31m-		// name->Is[m
[31m-		const Handle<Value>& value = DeserializeValue(type, promoteLongs);[m
[31m-		returnObject->ForceSet(name, value);[m
[31m-	}[m
[31m-	if(p != pEnd) ThrowAllocatedStringException(64, "Bad BSON Document: Serialize consumed unexpected number of bytes");[m
[31m-[m
[31m-	// From JavaScript:[m
[31m-	// if(object['$id'] != null) object = new DBRef(object['$ref'], object['$id'], object['$db']);[m
[31m-	if(returnObject->Has(NanNew(bson->_dbRefIdRefString)))[m
[31m-	{[m
[31m-		Local<Value> argv[] = { returnObject->Get(NanNew(bson->_dbRefRefString)), returnObject->Get(NanNew(bson->_dbRefIdRefString)), returnObject->Get(NanNew(bson->_dbRefDbRefString)) };[m
[31m-		return NanNew(bson->dbrefConstructor)->NewInstance(3, argv);[m
[31m-	}[m
[31m-	else[m
[31m-	{[m
[31m-		return returnObject;[m
[31m-	}[m
[31m-}[m
[31m-[m
[31m-Handle<Value> BSONDeserializer::DeserializeArray(bool promoteLongs)[m
[31m-{[m
[31m-	uint32_t length = ReadUInt32();[m
[31m-	if(length < 5) ThrowAllocatedStringException(64, "Bad BSON: Array Document is less than 5 bytes");[m
[31m-[m
[31m-	BSONDeserializer documentDeserializer(*this, length-4);[m
[31m-	return documentDeserializer.DeserializeArrayInternal(promoteLongs);[m
[31m-}[m
[31m-[m
[31m-Handle<Value> BSONDeserializer::DeserializeArrayInternal(bool promoteLongs)[m
[31m-{[m
[31m-	Local<Array> returnArray = NanNew<Array>();[m
[31m-[m
[31m-	while(HasMoreData())[m
[31m-	{[m
[31m-		BsonType type = (BsonType) ReadByte();[m
[31m-		uint32_t index = ReadIntegerString();[m
[31m-		const Handle<Value>& value = DeserializeValue(type, promoteLongs);[m
[31m-		returnArray->Set(index, value);[m
[31m-	}[m
[31m-	if(p != pEnd) ThrowAllocatedStringException(64, "Bad BSON Array: Serialize consumed unexpected number of bytes");[m
[31m-[m
[31m-	return returnArray;[m
[31m-}[m
[31m-[m
[31m-Handle<Value> BSONDeserializer::DeserializeValue(BsonType type, bool promoteLongs)[m
[31m-{[m
[31m-	switch(type)[m
[31m-	{[m
[31m-	case BSON_TYPE_STRING:[m
[31m-		return ReadString();[m
[31m-[m
[31m-	case BSON_TYPE_INT:[m
[31m-		return NanNew<Integer>(ReadInt32());[m
[31m-[m
[31m-	case BSON_TYPE_NUMBER:[m
[31m-		return NanNew<Number>(ReadDouble());[m
[31m-[m
[31m-	case BSON_TYPE_NULL:[m
[31m-		return NanNull();[m
[31m-[m
[31m-	case BSON_TYPE_UNDEFINED:[m
[31m-		return NanNull();[m
[31m-[m
[31m-	case BSON_TYPE_TIMESTAMP:[m
[31m-		{[m
[31m-			int32_t lowBits = ReadInt32();[m
[31m-			int32_t highBits = ReadInt32();[m
[31m-			Local<Value> argv[] = { NanNew<Int32>(lowBits), NanNew<Int32>(highBits) };[m
[31m-			return NanNew(bson->timestampConstructor)->NewInstance(2, argv);[m
[31m-		}[m
[31m-[m
[31m-	case BSON_TYPE_BOOLEAN:[m
[31m-		return (ReadByte() != 0) ? NanTrue() : NanFalse();[m
[31m-[m
[31m-	case BSON_TYPE_REGEXP:[m
[31m-		{[m
[31m-			const Handle<Value>& regex = ReadCString();[m
[31m-			if(regex->IsNull()) ThrowAllocatedStringException(64, "Bad BSON Document: illegal CString");[m
[31m-			int32_t options = ReadRegexOptions();[m
[31m-			return NanNew<RegExp>(regex->ToString(), (RegExp::Flags) options);[m
[31m-		}[m
[31m-[m
[31m-	case BSON_TYPE_CODE:[m
[31m-		{[m
[31m-			const Local<Value>& code = ReadString();[m
[31m-			const Local<Value>& scope = NanNew<Object>();[m
[31m-			Local<Value> argv[] = { code, scope };[m
[31m-			return NanNew(bson->codeConstructor)->NewInstance(2, argv);[m
[31m-		}[m
[31m-[m
[31m-	case BSON_TYPE_CODE_W_SCOPE:[m
[31m-		{[m
[31m-			ReadUInt32();[m
[31m-			const Local<Value>& code = ReadString();[m
[31m-			const Handle<Value>& scope = DeserializeDocument(promoteLongs);[m
[31m-			Local<Value> argv[] = { code, scope->ToObject() };[m
[31m-			return NanNew(bson->codeConstructor)->NewInstance(2, argv);[m
[31m-		}[m
[31m-[m
[31m-	case BSON_TYPE_OID:[m
[31m-		{[m
[31m-			Local<Value> argv[] = { ReadObjectId() };[m
[31m-			return NanNew(bson->objectIDConstructor)->NewInstance(1, argv);[m
[31m-		}[m
[31m-[m
[31m-	case BSON_TYPE_BINARY:[m
[31m-		{[m
[31m-			uint32_t length = ReadUInt32();[m
[31m-			uint32_t subType = ReadByte();[m
[31m-			if(subType == 0x02) {[m
[31m-				length = ReadInt32();[m
[31m-			}[m
[31m-[m
[31m-			Local<Object> buffer = NanNewBufferHandle(p, length);[m
[31m-			p += length;[m
[31m-[m
[31m-			Handle<Value> argv[] = { buffer, NanNew<Uint32>(subType) };[m
[31m-			return NanNew(bson->binaryConstructor)->NewInstance(2, argv);[m
[31m-		}[m
[31m-[m
[31m-	case BSON_TYPE_LONG:[m
[31m-		{[m
[31m-			// Read 32 bit integers[m
[31m-			int32_t lowBits = (int32_t) ReadInt32();[m
[31m-			int32_t highBits = (int32_t) ReadInt32();[m
[31m-[m
[31m-			// Promote long is enabled[m
[31m-			if(promoteLongs) {[m
[31m-				// If value is < 2^53 and >-2^53[m
[31m-				if((highBits < 0x200000 || (highBits == 0x200000 && lowBits == 0)) && highBits >= -0x200000) {[m
[31m-					// Adjust the pointer and read as 64 bit value[m
[31m-					p -= 8;[m
[31m-					// Read the 64 bit value[m
[31m-					int64_t finalValue = (int64_t) ReadInt64();[m
[31m-					return NanNew<Number>(finalValue);[m
[31m-				}[m
[31m-			}[m
[31m-[m
[31m-			// Decode the Long value[m
[31m-			Local<Value> argv[] = { NanNew<Int32>(lowBits), NanNew<Int32>(highBits) };[m
[31m-			return NanNew(bson->longConstructor)->NewInstance(2, argv);[m
[31m-		}[m
[31m-[m
[31m-	case BSON_TYPE_DATE:[m
[31m-		return NanNew<Date>((double) ReadInt64());[m
[31m-[m
[31m-	case BSON_TYPE_ARRAY:[m
[31m-		return DeserializeArray(promoteLongs);[m
[31m-[m
[31m-	case BSON_TYPE_OBJECT:[m
[31m-		return DeserializeDocument(promoteLongs);[m
[31m-[m
[31m-	case BSON_TYPE_SYMBOL:[m
[31m-		{[m
[31m-			const Local<String>& string = ReadString();[m
[31m-			Local<Value> argv[] = { string };[m
[31m-			return NanNew(bson->symbolConstructor)->NewInstance(1, argv);[m
[31m-		}[m
[31m-[m
[31m-	case BSON_TYPE_MIN_KEY:[m
[31m-		return NanNew(bson->minKeyConstructor)->NewInstance();[m
[31m-[m
[31m-	case BSON_TYPE_MAX_KEY:[m
[31m-		return NanNew(bson->maxKeyConstructor)->NewInstance();[m
[31m-[m
[31m-	default:[m
[31m-		ThrowAllocatedStringException(64, "Unhandled BSON Type: %d", type);[m
[31m-	}[m
[31m-[m
[31m-	return NanNull();[m
[31m-}[m
[31m-[m
[31m-Persistent<FunctionTemplate> BSON::constructor_template;[m
[31m-[m
[31m-BSON::BSON() : ObjectWrap()[m
[31m-{[m
[31m-	// Setup pre-allocated comparision objects[m
[31m-  NanAssignPersistent(_bsontypeString, NanNew<String>("_bsontype"));[m
[31m-  NanAssignPersistent(_longLowString, NanNew<String>("low_"));[m
[31m-  NanAssignPersistent(_longHighString, NanNew<String>("high_"));[m
[31m-  NanAssignPersistent(_objectIDidString, NanNew<String>("id"));[m
[31m-  NanAssignPersistent(_binaryPositionString, NanNew<String>("position"));[m
[31m-  NanAssignPersistent(_binarySubTypeString, NanNew<String>("sub_type"));[m
[31m-  NanAssignPersistent(_binaryBufferString, NanNew<String>("buffer"));[m
[31m-  NanAssignPersistent(_doubleValueString, NanNew<String>("value"));[m
[31m-  NanAssignPersistent(_symbolValueString, NanNew<String>("value"));[m
[31m-  NanAssignPersistent(_dbRefRefString, NanNew<String>("$ref"));[m
[31m-  NanAssignPersistent(_dbRefIdRefString, NanNew<String>("$id"));[m
[31m-  NanAssignPersistent(_dbRefDbRefString, NanNew<String>("$db"));[m
[31m-  NanAssignPersistent(_dbRefNamespaceString, NanNew<String>("namespace"));[m
[31m-  NanAssignPersistent(_dbRefDbString, NanNew<String>("db"));[m
[31m-  NanAssignPersistent(_dbRefOidString, NanNew<String>("oid"));[m
[31m-  NanAssignPersistent(_codeCodeString, NanNew<String>("code"));[m
[31m-  NanAssignPersistent(_codeScopeString, NanNew<String>("scope"));[m
[31m-  NanAssignPersistent(_toBSONString, NanNew<String>("toBSON"));[m
[31m-[m
[31m-  NanAssignPersistent(longString, NanNew<String>("Long"));[m
[31m-  NanAssignPersistent(objectIDString, NanNew<String>("ObjectID"));[m
[31m-  NanAssignPersistent(binaryString, NanNew<String>("Binary"));[m
[31m-  NanAssignPersistent(codeString, NanNew<String>("Code"));[m
[31m-  NanAssignPersistent(dbrefString, NanNew<String>("DBRef"));[m
[31m-  NanAssignPersistent(symbolString, NanNew<String>("Symbol"));[m
[31m-  NanAssignPersistent(doubleString, NanNew<String>("Double"));[m
[31m-  NanAssignPersistent(timestampString, NanNew<String>("Timestamp"));[m
[31m-  NanAssignPersistent(minKeyString, NanNew<String>("MinKey"));[m
[31m-  NanAssignPersistent(maxKeyString, NanNew<String>("MaxKey"));[m
[31m-}[m
[31m-[m
[31m-void BSON::Initialize(v8::Handle<v8::Object> target)[m
[31m-{[m
[31m-	// Grab the scope of the call from Node[m
[31m-	NanScope();[m
[31m-	// Define a new function template[m
[31m-	Local<FunctionTemplate> t = NanNew<FunctionTemplate>(New);[m
[31m-	t->InstanceTemplate()->SetInternalFieldCount(1);[m
[31m-	t->SetClassName(NanNew<String>("BSON"));[m
[31m-[m
[31m-	// Instance methods[m
[31m-	NODE_SET_PROTOTYPE_METHOD(t, "calculateObjectSize", CalculateObjectSize);[m
[31m-	NODE_SET_PROTOTYPE_METHOD(t, "serialize", BSONSerialize);[m
[31m-	NODE_SET_PROTOTYPE_METHOD(t, "serializeWithBufferAndIndex", SerializeWithBufferAndIndex);[m
[31m-	NODE_SET_PROTOTYPE_METHOD(t, "deserialize", BSONDeserialize);[m
[31m-	NODE_SET_PROTOTYPE_METHOD(t, "deserializeStream", BSONDeserializeStream);[m
[31m-[m
[31m-	NanAssignPersistent(constructor_template, t);[m
[31m-[m
[31m-	target->ForceSet(NanNew<String>("BSON"), t->GetFunction());[m
[31m-}[m
[31m-[m
[31m-// Create a new instance of BSON and passing it the existing context[m
[31m-NAN_METHOD(BSON::New)[m
[31m-{[m
[31m-	NanScope();[m
[31m-[m
[31m-	// Check that we have an array[m
[31m-	if(args.Length() == 1 && args[0]->IsArray())[m
[31m-	{[m
[31m-		// Cast the array to a local reference[m
[31m-		Local<Array> array = Local<Array>::Cast(args[0]);[m
[31m-[m
[31m-		if(array->Length() > 0)[m
[31m-		{[m
[31m-			// Create a bson object instance and return it[m
[31m-			BSON *bson = new BSON();[m
[31m-[m
[31m-			uint32_t foundClassesMask = 0;[m
[31m-[m
[31m-			// Iterate over all entries to save the instantiate functions[m
[31m-			for(uint32_t i = 0; i < array->Length(); i++) {[m
[31m-				// Let's get a reference to the function[m
[31m-				Local<Function> func = Local<Function>::Cast(array->Get(i));[m
[31m-				Local<String> functionName = func->GetName()->ToString();[m
[31m-[m
[31m-				// Save the functions making them persistant handles (they don't get collected)[m
[31m-				if(functionName->StrictEquals(NanNew(bson->longString))) {[m
[31m-					NanAssignPersistent(bson->longConstructor, func);[m
[31m-					foundClassesMask |= 1;[m
[31m-				} else if(functionName->StrictEquals(NanNew(bson->objectIDString))) {[m
[31m-					NanAssignPersistent(bson->objectIDConstructor, func);[m
[31m-					foundClassesMask |= 2;[m
[31m-				} else if(functionName->StrictEquals(NanNew(bson->binaryString))) {[m
[31m-					NanAssignPersistent(bson->binaryConstructor, func);[m
[31m-					foundClassesMask |= 4;[m
[31m-				} else if(functionName->StrictEquals(NanNew(bson->codeString))) {[m
[31m-					NanAssignPersistent(bson->codeConstructor, func);[m
[31m-					foundClassesMask |= 8;[m
[31m-				} else if(functionName->StrictEquals(NanNew(bson->dbrefString))) {[m
[31m-					NanAssignPersistent(bson->dbrefConstructor, func);[m
[31m-					foundClassesMask |= 0x10;[m
[31m-				} else if(functionName->StrictEquals(NanNew(bson->symbolString))) {[m
[31m-					NanAssignPersistent(bson->symbolConstructor, func);[m
[31m-					foundClassesMask |= 0x20;[m
[31m-				} else if(functionName->StrictEquals(NanNew(bson->doubleString))) {[m
[31m-					NanAssignPersistent(bson->doubleConstructor, func);[m
[31m-					foundClassesMask |= 0x40;[m
[31m-				} else if(functionName->StrictEquals(NanNew(bson->timestampString))) {[m
[31m-					NanAssignPersistent(bson->timestampConstructor, func);[m
[31m-					foundClassesMask |= 0x80;[m
[31m-				} else if(functionName->StrictEquals(NanNew(bson->minKeyString))) {[m
[31m-					NanAssignPersistent(bson->minKeyConstructor, func);[m
[31m-					foundClassesMask |= 0x100;[m
[31m-				} else if(functionName->StrictEquals(NanNew(bson->maxKeyString))) {[m
[31m-					NanAssignPersistent(bson->maxKeyConstructor, func);[m
[31m-					foundClassesMask |= 0x200;[m
[31m-				}[m
[31m-			}[m
[31m-[m
[31m-			// Check if we have the right number of constructors otherwise throw an error[m
[31m-			if(foundClassesMask != 0x3ff) {[m
[31m-				delete bson;[m
[31m-				return NanThrowError("Missing function constructor for either [Long/ObjectID/Binary/Code/DbRef/Symbol/Double/Timestamp/MinKey/MaxKey]");[m
[31m-			} else {[m
[31m-				bson->Wrap(args.This());[m
[31m-				NanReturnValue(args.This());[m
[31m-			}[m
[31m-		}[m
[31m-		else[m
[31m-		{[m
[31m-			return NanThrowError("No types passed in");[m
[31m-		}[m
[31m-	}[m
[31m-	else[m
[31m-	{[m
[31m-		return NanThrowTypeError("Argument passed in must be an array of types");[m
[31m-	}[m
[31m-}[m
[31m-[m
[31m-//------------------------------------------------------------------------------------------------[m
[31m-//------------------------------------------------------------------------------------------------[m
[31m-//------------------------------------------------------------------------------------------------[m
[31m-//------------------------------------------------------------------------------------------------[m
[31m-[m
[31m-NAN_METHOD(BSON::BSONDeserialize)[m
[31m-{[m
[31m-	NanScope();[m
[31m-[m
[31m-	// Fail if the first argument is not a string or a buffer[m
[31m-	if(args.Length() > 1 && !args[0]->IsString() && !Buffer::HasInstance(args[0]))[m
[31m-		return NanThrowError("First Argument must be a Buffer or String.");[m
[31m-[m
[31m-	// Promote longs[m
[31m-	bool promoteLongs = true;[m
[31m-[m
[31m-	// If we have an options object[m
[31m-	if(args.Length() == 2 && args[1]->IsObject()) {[m
[31m-		Local<Object> options = args[1]->ToObject();[m
[31m-[m
[31m-		if(options->Has(NanNew<String>("promoteLongs"))) {[m
[31m-			promoteLongs = options->Get(NanNew<String>("promoteLongs"))->ToBoolean()->Value();[m
[31m-		}[m
[31m-	}[m
[31m-[m
[31m-	// Define pointer to data[m
[31m-	Local<Object> obj = args[0]->ToObject();[m
[31m-[m
[31m-	// Unpack the BSON parser instance[m
[31m-	BSON *bson = ObjectWrap::Unwrap<BSON>(args.This());[m
[31m-[m
[31m-	// If we passed in a buffer, let's unpack it, otherwise let's unpack the string[m
[31m-	if(Buffer::HasInstance(obj))[m
[31m-	{[m
[31m-#if NODE_MAJOR_VERSION == 0 && NODE_MINOR_VERSION < 3[m
[31m-		Local<Object> buffer = ObjectWrap::Unwrap<Buffer>(obj);[m
[31m-		char* data = buffer->data();[m
[31m-		size_t length = buffer->length();[m
[31m-#else[m
[31m-		char* data = Buffer::Data(obj);[m
[31m-		size_t length = Buffer::Length(obj);[m
[31m-#endif[m
[31m-[m
[31m-		// Validate that we have at least 5 bytes[m
[31m-		if(length < 5) return NanThrowError("corrupt bson message < 5 bytes long");[m
[31m-[m
[31m-		try[m
[31m-		{[m
[31m-			BSONDeserializer deserializer(bson, data, length);[m
[31m-			// deserializer.promoteLongs = promoteLongs;[m
[31m-			NanReturnValue(deserializer.DeserializeDocument(promoteLongs));[m
[31m-		}[m
[31m-		catch(char* exception)[m
[31m-		{[m
[31m-			Local<String> error = NanNew<String>(exception);[m
[31m-			free(exception);[m
[31m-			return NanThrowError(error);[m
[31m-		}[m
[31m-[m
[31m-	}[m
[31m-	else[m
[31m-	{[m
[31m-		// The length of the data for this encoding[m
[31m-		ssize_t len = DecodeBytes(args[0], BINARY);[m
[31m-[m
[31m-		// Validate that we have at least 5 bytes[m
[31m-		if(len < 5) return NanThrowError("corrupt bson message < 5 bytes long");[m
[31m-[m
[31m-		// Let's define the buffer size[m
[31m-		char* data = (char *)malloc(len);[m
[31m-		if(data == NULL) die("Failed to allocate char buffer for BSON serialization");[m
[31m-		DecodeWrite(data, len, args[0], BINARY);[m
[31m-[m
[31m-		try[m
[31m-		{[m
[31m-			BSONDeserializer deserializer(bson, data, len);[m
[31m-			// deserializer.promoteLongs = promoteLongs;[m
[31m-			Handle<Value> result = deserializer.DeserializeDocument(promoteLongs);[m
[31m-			free(data);[m
[31m-			NanReturnValue(result);[m
[31m-[m
[31m-		}[m
[31m-		catch(char* exception)[m
[31m-		{[m
[31m-			Local<String> error = NanNew<String>(exception);[m
[31m-			free(exception);[m
[31m-			free(data);[m
[31m-			return NanThrowError(error);[m
[31m-		}[m
[31m-	}[m
[31m-}[m
[31m-[m
[31m-Local<Object> BSON::GetSerializeObject(const Handle<Value>& argValue)[m
[31m-{[m
[31m-	Local<Object> object = argValue->ToObject();[m
[31m-	if(object->Has(NanNew(_toBSONString)))[m
[31m-	{[m
[31m-		const Local<Value>& toBSON = object->Get(NanNew(_toBSONString));[m
[31m-		if(!toBSON->IsFunction()) ThrowAllocatedStringException(64, "toBSON is not a function");[m
[31m-[m
[31m-		Local<Value> result = Local<Function>::Cast(toBSON)->Call(object, 0, NULL);[m
[31m-		if(!result->IsObject()) ThrowAllocatedStringException(64, "toBSON function did not return an object");[m
[31m-		return result->ToObject();[m
[31m-	}[m
[31m-	else[m
[31m-	{[m
[31m-		return object;[m
[31m-	}[m
[31m-}[m
[31m-[m
[31m-NAN_METHOD(BSON::BSONSerialize)[m
[31m-{[m
[31m-	NanScope();[m
[31m-[m
[31m-	if(args.Length() == 1 && !args[0]->IsObject()) return NanThrowError("One, two or tree arguments required - [object] or [object, boolean] or [object, boolean, boolean]");[m
[31m-	if(args.Length() == 2 && !args[0]->IsObject() && !args[1]->IsBoolean()) return NanThrowError("One, two or tree arguments required - [object] or [object, boolean] or [object, boolean, boolean]");[m
[31m-	if(args.Length() == 3 && !args[0]->IsObject() && !args[1]->IsBoolean() && !args[2]->IsBoolean()) return NanThrowError("One, two or tree arguments required - [object] or [object, boolean] or [object, boolean, boolean]");[m
[31m-	if(args.Length() == 4 && !args[0]->IsObject() && !args[1]->IsBoolean() && !args[2]->IsBoolean() && !args[3]->IsBoolean()) return NanThrowError("One, two or tree arguments required - [object] or [object, boolean] or [object, boolean, boolean] or [object, boolean, boolean, boolean]");[m
[31m-	if(args.Length() > 4) return NanThrowError("One, two, tree or four arguments required - [object] or [object, boolean] or [object, boolean, boolean] or [object, boolean, boolean, boolean]");[m
[31m-[m
[31m-	// Check if we have an array as the object[m
[31m-	if(args[0]->IsArray()) return NanThrowError("Only javascript objects supported");[m
[31m-[m
[31m-	// Unpack the BSON parser instance[m
[31m-	BSON *bson = ObjectWrap::Unwrap<BSON>(args.This());[m
[31m-[m
[31m-	// Calculate the total size of the document in binary form to ensure we only allocate memory once[m
[31m-	// With serialize function[m
[31m-	bool serializeFunctions = (args.Length() >= 4) && args[3]->BooleanValue();[m
[31m-[m
[31m-	char *serialized_object = NULL;[m
[31m-	size_t object_size;[m
[31m-	try[m
[31m-	{[m
[31m-		Local<Object> object = bson->GetSerializeObject(args[0]);[m
[31m-[m
[31m-		BSONSerializer<CountStream> counter(bson, false, serializeFunctions);[m
[31m-		counter.SerializeDocument(object);[m
[31m-		object_size = counter.GetSerializeSize();[m
[31m-[m
[31m-		// Allocate the memory needed for the serialization[m
[31m-		serialized_object = (char *)malloc(object_size);[m
[31m-		if(serialized_object == NULL) die("Failed to allocate memory for object");[m
[31m-[m
[31m-		// Check if we have a boolean value[m
[31m-		bool checkKeys = args.Length() >= 3 && args[1]->IsBoolean() && args[1]->BooleanValue();[m
[31m-		BSONSerializer<DataStream> data(bson, checkKeys, serializeFunctions, serialized_object);[m
[31m-		data.SerializeDocument(object);[m
[31m-	}[m
[31m-	catch(char *err_msg)[m
[31m-	{[m
[31m-		free(serialized_object);[m
[31m-		Local<String> error = NanNew<String>(err_msg);[m
[31m-		free(err_msg);[m
[31m-		return NanThrowError(error);[m
[31m-	}[m
[31m-[m
[31m-	// If we have 3 arguments[m
[31m-	if(args.Length() == 3 || args.Length() == 4)[m
[31m-	{[m
[31m-		Local<Object> buffer = NanNewBufferHandle(serialized_object, object_size);[m
[31m-		free(serialized_object);[m
[31m-		NanReturnValue(buffer);[m
[31m-	}[m
[31m-	else[m
[31m-	{[m
[31m-		Local<Value> bin_value = Encode(serialized_object, object_size, BINARY)->ToString();[m
[31m-		free(serialized_object);[m
[31m-		NanReturnValue(bin_value);[m
[31m-	}[m
[31m-}[m
[31m-[m
[31m-NAN_METHOD(BSON::CalculateObjectSize)[m
[31m-{[m
[31m-	NanScope();[m
[31m-	// Ensure we have a valid object[m
[31m-	if(args.Length() == 1 && !args[0]->IsObject()) return NanThrowError("One argument required - [object]");[m
[31m-	if(args.Length() == 2 && !args[0]->IsObject() && !args[1]->IsBoolean())  return NanThrowError("Two arguments required - [object, boolean]");[m
[31m-	if(args.Length() > 3) return NanThrowError("One or two arguments required - [object] or [object, boolean]");[m
[31m-[m
[31m-	// Unpack the BSON parser instance[m
[31m-	BSON *bson = ObjectWrap::Unwrap<BSON>(args.This());[m
[31m-	bool serializeFunctions = (args.Length() >= 2) && args[1]->BooleanValue();[m
[31m-	BSONSerializer<CountStream> countSerializer(bson, false, serializeFunctions);[m
[31m-	countSerializer.SerializeDocument(args[0]);[m
[31m-[m
[31m-	// Return the object size[m
[31m-	NanReturnValue(NanNew<Uint32>((uint32_t) countSerializer.GetSerializeSize()));[m
[31m-}[m
[31m-[m
[31m-NAN_METHOD(BSON::SerializeWithBufferAndIndex)[m
[31m-{[m
[31m-	NanScope();[m
[31m-[m
[31m-	//BSON.serializeWithBufferAndIndex = function serializeWithBufferAndIndex(object, ->, buffer, index) {[m
[31m-	// Ensure we have the correct values[m
[31m-	if(args.Length() > 5) return NanThrowError("Four or five parameters required [object, boolean, Buffer, int] or [object, boolean, Buffer, int, boolean]");[m
[31m-	if(args.Length() == 4 && !args[0]->IsObject() && !args[1]->IsBoolean() && !Buffer::HasInstance(args[2]) && !args[3]->IsUint32()) return NanThrowError("Four parameters required [object, boolean, Buffer, int]");[m
[31m-	if(args.Length() == 5 && !args[0]->IsObject() && !args[1]->IsBoolean() && !Buffer::HasInstance(args[2]) && !args[3]->IsUint32() && !args[4]->IsBoolean()) return NanThrowError("Four parameters required [object, boolean, Buffer, int, boolean]");[m
[31m-[m
[31m-	uint32_t index;[m
[31m-	size_t object_size;[m
[31m-[m
[31m-	try[m
[31m-	{[m
[31m-		BSON *bson = ObjectWrap::Unwrap<BSON>(args.This());[m
[31m-[m
[31m-		Local<Object> obj = args[2]->ToObject();[m
[31m-		char* data = Buffer::Data(obj);[m
[31m-		size_t length = Buffer::Length(obj);[m
[31m-[m
[31m-		index = args[3]->Uint32Value();[m
[31m-		bool checkKeys = args.Length() >= 4 && args[1]->IsBoolean() && args[1]->BooleanValue();[m
[31m-		bool serializeFunctions = (args.Length() == 5) && args[4]->BooleanValue();[m
[31m-[m
[31m-		BSONSerializer<DataStream> dataSerializer(bson, checkKeys, serializeFunctions, data+index);[m
[31m-		dataSerializer.SerializeDocument(bson->GetSerializeObject(args[0]));[m
[31m-		object_size = dataSerializer.GetSerializeSize();[m
[31m-[m
[31m-		if(object_size + index > length) return NanThrowError("Serious error - overflowed buffer!!");[m
[31m-	}[m
[31m-	catch(char *exception)[m
[31m-	{[m
[31m-		Local<String> error = NanNew<String>(exception);[m
[31m-		free(exception);[m
[31m-		return NanThrowError(error);[m
[31m-	}[m
[31m-[m
[31m-	NanReturnValue(NanNew<Uint32>((uint32_t) (index + object_size - 1)));[m
[31m-}[m
[31m-[m
[31m-NAN_METHOD(BSON::BSONDeserializeStream)[m
[31m-{[m
[31m-	NanScope();[m
[31m-[m
[31m-	// At least 3 arguments required[m
[31m-	if(args.Length() < 5) return NanThrowError("Arguments required (Buffer(data), Number(index in data), Number(number of documents to deserialize), Array(results), Number(index in the array), Object(optional))");[m
[31m-[m
[31m-	// If the number of argumets equals 3[m
[31m-	if(args.Length() >= 5)[m
[31m-	{[m
[31m-		if(!Buffer::HasInstance(args[0])) return NanThrowError("First argument must be Buffer instance");[m
[31m-		if(!args[1]->IsUint32()) return NanThrowError("Second argument must be a positive index number");[m
[31m-		if(!args[2]->IsUint32()) return NanThrowError("Third argument must be a positive number of documents to deserialize");[m
[31m-		if(!args[3]->IsArray()) return NanThrowError("Fourth argument must be an array the size of documents to deserialize");[m
[31m-		if(!args[4]->IsUint32()) return NanThrowError("Sixth argument must be a positive index number");[m
[31m-	}[m
[31m-[m
[31m-	// If we have 4 arguments[m
[31m-	if(args.Length() == 6 && !args[5]->IsObject()) return NanThrowError("Fifth argument must be an object with options");[m
[31m-[m
[31m-	// Define pointer to data[m
[31m-	Local<Object> obj = args[0]->ToObject();[m
[31m-	uint32_t numberOfDocuments = args[2]->Uint32Value();[m
[31m-	uint32_t index = args[1]->Uint32Value();[m
[31m-	uint32_t resultIndex = args[4]->Uint32Value();[m
[31m-	bool promoteLongs = true;[m
[31m-[m
[31m-	// Check for the value promoteLongs in the options object[m
[31m-	if(args.Length() == 6) {[m
[31m-		Local<Object> options = args[5]->ToObject();[m
[31m-[m
[31m-		// Check if we have the promoteLong variable[m
[31m-		if(options->Has(NanNew<String>("promoteLongs"))) {[m
[31m-			promoteLongs = options->Get(NanNew<String>("promoteLongs"))->ToBoolean()->Value();[m
[31m-		}[m
[31m-	}[m
[31m-[m
[31m-	// Unpack the BSON parser instance[m
[31m-	BSON *bson = ObjectWrap::Unwrap<BSON>(args.This());[m
[31m-[m
[31m-	// Unpack the buffer variable[m
[31m-#if NODE_MAJOR_VERSION == 0 && NODE_MINOR_VERSION < 3[m
[31m-	Local<Object> buffer = ObjectWrap::Unwrap<Buffer>(obj);[m
[31m-	char* data = buffer->data();[m
[31m-	size_t length = buffer->length();[m
[31m-#else[m
[31m-	char* data = Buffer::Data(obj);[m
[31m-	size_t length = Buffer::Length(obj);[m
[31m-#endif[m
[31m-[m
[31m-	// Fetch the documents[m
[31m-	Local<Object> documents = args[3]->ToObject();[m
[31m-[m
[31m-	BSONDeserializer deserializer(bson, data+index, length-index);[m
[31m-	for(uint32_t i = 0; i < numberOfDocuments; i++)[m
[31m-	{[m
[31m-		try[m
[31m-		{[m
[31m-			documents->Set(i + resultIndex, deserializer.DeserializeDocument(promoteLongs));[m
[31m-		}[m
[31m-		catch (char* exception)[m
[31m-		{[m
[31m-		        Local<String> error = NanNew<String>(exception);[m
[31m-			free(exception);[m
[31m-			return NanThrowError(error);[m
[31m-		}[m
[31m-	}[m
[31m-[m
[31m-	// Return new index of parsing[m
[31m-	NanReturnValue(NanNew<Uint32>((uint32_t) (index + deserializer.GetSerializeSize())));[m
[31m-}[m
[31m-[m
[31m-// Exporting function[m
[31m-extern "C" void init(Handle<Object> target)[m
[31m-{[m
[31m-	NanScope();[m
[31m-	BSON::Initialize(target);[m
[31m-}[m
[31m-[m
[31m-NODE_MODULE(bson, BSON::Initialize);[m
[32m+[m[32m//===========================================================================[m[41m[m
[32m+[m[41m[m
[32m+[m[32m#include <stdarg.h>[m[41m[m
[32m+[m[32m#include <cstdlib>[m[41m[m
[32m+[m[32m#include <cstring>[m[41m[m
[32m+[m[32m#include <string.h>[m[41m[m
[32m+[m[32m#include <stdlib.h>[m[41m[m
[32m+[m[41m[m
[32m+[m[32m#ifdef __clang__[m[41m[m
[32m+[m[32m#pragma clang diagnostic push[m[41m[m
[32m+[m[32m#pragma clang diagnostic ignored "-Wunused-parameter"[m[41m[m
[32m+[m[32m#endif[m[41m[m
[32m+[m[41m[m
[32m+[m[32m#include <v8.h>[m[41m[m
[32m+[m[41m[m
[32m+[m[32m// this and the above block must be around the v8.h header otherwise[m[41m[m
[32m+[m[32m// v8 is not happy[m[41m[m
[32m+[m[32m#ifdef __clang__[m[41m[m
[32m+[m[32m#pragma clang diagnostic pop[m[41m[m
[32m+[m[32m#endif[m[41m[m
[32m+[m[41m[m
[32m+[m[32m#include <node.h>[m[41m[m
[32m+[m[32m#include <node_version.h>[m[41m[m
[32m+[m[32m#include <node_buffer.h>[m[41m[m
[32m+[m[41m[m
[32m+[m[32m#include <cmath>[m[41m[m
[32m+[m[32m#include <iostream>[m[41m[m
[32m+[m[32m#include <limits>[m[41m[m
[32m+[m[32m#include <vector>[m[41m[m
[32m+[m[32m#include <errno.h>[m[41m[m
[32m+[m[41m[m
[32m+[m[32m#if defined(__sun) || defined(_AIX)[m[41m[m
[32m+[m	[32m#include <alloca.h>[m[41m[m
[32m+[m[32m#endif[m[41m[m
[32m+[m[41m[m
[32m+[m[32m#include "bson.h"[m[41m[m
[32m+[m[41m[m
[32m+[m[32musing namespace v8;[m[41m[m
[32m+[m[32musing namespace node;[m[41m[m
[32m+[m[41m[m
[32m+[m[32mvoid die(const char *message) {[m[41m[m
[32m+[m	[32mif(errno) {[m[41m[m
[32m+[m		[32mperror(message);[m[41m[m
[32m+[m	[32m} else {[m[41m[m
[32m+[m		[32mprintf("ERROR: %s\n", message);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mexit(1);[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32m//===========================================================================[m[41m[m
[32m+[m[41m[m
[32m+[m[32mvoid DataStream::WriteObjectId(const Handle<Object>& object, const Handle<String>& key)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32muint16_t buffer[12];[m[41m[m
[32m+[m	[32mobject->Get(key)->ToString()->Write(buffer, 0, 12);[m[41m[m
[32m+[m	[32mfor(uint32_t i = 0; i < 12; ++i)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32m*p++ = (char) buffer[i];[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mvoid ThrowAllocatedStringException(size_t allocationSize, const char* format, ...)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mva_list args;[m[41m[m
[32m+[m	[32mva_start(args, format);[m[41m[m
[32m+[m	[32mchar* string = (char*) malloc(allocationSize);[m[41m[m
[32m+[m	[32mif(string == NULL) die("Failed to allocate ThrowAllocatedStringException");[m[41m[m
[32m+[m	[32mvsprintf(string, format, args);[m[41m[m
[32m+[m	[32mva_end(args);[m[41m[m
[32m+[m	[32mthrow string;[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mvoid DataStream::CheckKey(const Local<String>& keyName)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32msize_t keyLength = keyName->Utf8Length();[m[41m[m
[32m+[m	[32mif(keyLength == 0) return;[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Allocate space for the key, do not need to zero terminate as WriteUtf8 does it[m[41m[m
[32m+[m	[32mchar* keyStringBuffer = (char*) alloca(keyLength + 1);[m[41m[m
[32m+[m	[32m// Write the key to the allocated buffer[m[41m[m
[32m+[m	[32mkeyName->WriteUtf8(keyStringBuffer);[m[41m[m
[32m+[m	[32m// Check for the zero terminator[m[41m[m
[32m+[m	[32mchar* terminator = strchr(keyStringBuffer, 0x00);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// If the location is not at the end of the string we've got an illegal 0x00 byte somewhere[m[41m[m
[32m+[m	[32mif(terminator != &keyStringBuffer[keyLength]) {[m[41m[m
[32m+[m		[32mThrowAllocatedStringException(64+keyLength, "key %s must not contain null bytes", keyStringBuffer);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mif(keyStringBuffer[0] == '$')[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mThrowAllocatedStringException(64+keyLength, "key %s must not start with '$'", keyStringBuffer);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mif(strchr(keyStringBuffer, '.') != NULL)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mThrowAllocatedStringException(64+keyLength, "key %s must not contain '.'", keyStringBuffer);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mtemplate<typename T> void BSONSerializer<T>::SerializeDocument(const Handle<Value>& value)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mvoid* documentSize = this->BeginWriteSize();[m[41m[m
[32m+[m	[32mLocal<Object> object = bson->GetSerializeObject(value);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Get the object property names[m[41m[m
[32m+[m[32m  Local<Array> propertyNames = object->GetPropertyNames();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Length of the property[m[41m[m
[32m+[m	[32mint propertyLength = propertyNames->Length();[m[41m[m
[32m+[m	[32mfor(int i = 0;  i < propertyLength; ++i)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mconst Local<String>& propertyName = propertyNames->Get(i)->ToString();[m[41m[m
[32m+[m		[32mif(checkKeys) this->CheckKey(propertyName);[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mconst Local<Value>& propertyValue = object->Get(propertyName);[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mif(serializeFunctions || !propertyValue->IsFunction())[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mvoid* typeLocation = this->BeginWriteType();[m[41m[m
[32m+[m			[32mthis->WriteString(propertyName);[m[41m[m
[32m+[m			[32mSerializeValue(typeLocation, propertyValue);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mthis->WriteByte(0);[m[41m[m
[32m+[m	[32mthis->CommitSize(documentSize);[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mtemplate<typename T> void BSONSerializer<T>::SerializeArray(const Handle<Value>& value)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mvoid* documentSize = this->BeginWriteSize();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mLocal<Array> array = Local<Array>::Cast(value->ToObject());[m[41m[m
[32m+[m	[32muint32_t arrayLength = array->Length();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mfor(uint32_t i = 0;  i < arrayLength; ++i)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mvoid* typeLocation = this->BeginWriteType();[m[41m[m
[32m+[m		[32mthis->WriteUInt32String(i);[m[41m[m
[32m+[m		[32mSerializeValue(typeLocation, array->Get(i));[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mthis->WriteByte(0);[m[41m[m
[32m+[m	[32mthis->CommitSize(documentSize);[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32m// This is templated so that we can use this function to both count the number of bytes, and to serialize those bytes.[m[41m[m
[32m+[m[32m// The template approach eliminates almost all of the inspection of values unless they're required (eg. string lengths)[m[41m[m
[32m+[m[32m// and ensures that there is always consistency between bytes counted and bytes written by design.[m[41m[m
[32m+[m[32mtemplate<typename T> void BSONSerializer<T>::SerializeValue(void* typeLocation, const Handle<Value> constValue)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32m// Turn into local value[m[41m[m
[32m+[m	[32mLocal<Value> value = NanNew<Value>(constValue);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Check for toBSON function[m[41m[m
[32m+[m	[32mif(value->IsObject()) {[m[41m[m
[32m+[m		[32mLocal<Object> object = value->ToObject();[m[41m[m
[32m+[m[41m[m
[32m+[m		[32m// NanNew<String>("toBSON")[m[41m[m
[32m+[m		[32m// NanNew(BSON::_toBSONString)[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mif(object->Has(NanNew<String>("toBSON"))) {[m[41m[m
[32m+[m			[32mconst Local<Value>& toBSON = object->Get(NanNew<String>("toBSON"));[m[41m[m
[32m+[m			[32mif(!toBSON->IsFunction()) ThrowAllocatedStringException(64, "toBSON is not a function");[m[41m[m
[32m+[m			[32mvalue = Local<Function>::Cast(toBSON)->Call(object, 0, NULL);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Process all the values[m[41m[m
[32m+[m	[32mif(value->IsNumber())[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mdouble doubleValue = value->NumberValue();[m[41m[m
[32m+[m		[32mint intValue = (int) doubleValue;[m[41m[m
[32m+[m		[32mif(intValue == doubleValue)[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mthis->CommitType(typeLocation, BSON_TYPE_INT);[m[41m[m
[32m+[m			[32mthis->WriteInt32(intValue);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m		[32melse[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mthis->CommitType(typeLocation, BSON_TYPE_NUMBER);[m[41m[m
[32m+[m			[32mthis->WriteDouble(doubleValue);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse if(value->IsString())[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mthis->CommitType(typeLocation, BSON_TYPE_STRING);[m[41m[m
[32m+[m		[32mthis->WriteLengthPrefixedString(value->ToString());[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse if(value->IsBoolean())[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mthis->CommitType(typeLocation, BSON_TYPE_BOOLEAN);[m[41m[m
[32m+[m		[32mthis->WriteBool(value);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse if(value->IsArray())[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mthis->CommitType(typeLocation, BSON_TYPE_ARRAY);[m[41m[m
[32m+[m		[32mSerializeArray(value);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse if(value->IsDate())[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mthis->CommitType(typeLocation, BSON_TYPE_DATE);[m[41m[m
[32m+[m		[32mthis->WriteInt64(value);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse if(value->IsRegExp())[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mthis->CommitType(typeLocation, BSON_TYPE_REGEXP);[m[41m[m
[32m+[m		[32mconst Handle<RegExp>& regExp = Handle<RegExp>::Cast(value);[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mthis->WriteString(regExp->GetSource());[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mint flags = regExp->GetFlags();[m[41m[m
[32m+[m		[32mif(flags & RegExp::kGlobal) this->WriteByte('s');[m[41m[m
[32m+[m		[32mif(flags & RegExp::kIgnoreCase) this->WriteByte('i');[m[41m[m
[32m+[m		[32mif(flags & RegExp::kMultiline) this->WriteByte('m');[m[41m[m
[32m+[m		[32mthis->WriteByte(0);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse if(value->IsFunction())[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mthis->CommitType(typeLocation, BSON_TYPE_CODE);[m[41m[m
[32m+[m		[32mthis->WriteLengthPrefixedString(value->ToString());[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse if(value->IsObject())[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mconst Local<Object>& object = value->ToObject();[m[41m[m
[32m+[m		[32mif(object->Has(NanNew(bson->_bsontypeString)))[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mconst Local<String>& constructorString = object->Get(NanNew(bson->_bsontypeString))->ToString();[m[41m[m
[32m+[m			[32mif(NanNew(bson->longString)->StrictEquals(constructorString))[m[41m[m
[32m+[m			[32m{[m[41m[m
[32m+[m				[32mthis->CommitType(typeLocation, BSON_TYPE_LONG);[m[41m[m
[32m+[m				[32mthis->WriteInt32(object, NanNew(bson->_longLowString));[m[41m[m
[32m+[m				[32mthis->WriteInt32(object, NanNew(bson->_longHighString));[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m			[32melse if(NanNew(bson->timestampString)->StrictEquals(constructorString))[m[41m[m
[32m+[m			[32m{[m[41m[m
[32m+[m				[32mthis->CommitType(typeLocation, BSON_TYPE_TIMESTAMP);[m[41m[m
[32m+[m				[32mthis->WriteInt32(object, NanNew(bson->_longLowString));[m[41m[m
[32m+[m				[32mthis->WriteInt32(object, NanNew(bson->_longHighString));[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m			[32melse if(NanNew(bson->objectIDString)->StrictEquals(constructorString))[m[41m[m
[32m+[m			[32m{[m[41m[m
[32m+[m				[32mthis->CommitType(typeLocation, BSON_TYPE_OID);[m[41m[m
[32m+[m				[32mthis->WriteObjectId(object, NanNew(bson->_objectIDidString));[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m			[32melse if(NanNew(bson->binaryString)->StrictEquals(constructorString))[m[41m[m
[32m+[m			[32m{[m[41m[m
[32m+[m				[32mthis->CommitType(typeLocation, BSON_TYPE_BINARY);[m[41m[m
[32m+[m[41m[m
[32m+[m				[32muint32_t length = object->Get(NanNew(bson->_binaryPositionString))->Uint32Value();[m[41m[m
[32m+[m				[32mLocal<Object> bufferObj = object->Get(NanNew(bson->_binaryBufferString))->ToObject();[m[41m[m
[32m+[m[41m[m
[32m+[m				[32mthis->WriteInt32(length);[m[41m[m
[32m+[m				[32mthis->WriteByte(object, NanNew(bson->_binarySubTypeString));	// write subtype[m[41m[m
[32m+[m				[32m// If type 0x02 write the array length aswell[m[41m[m
[32m+[m				[32mif(object->Get(NanNew(bson->_binarySubTypeString))->Int32Value() == 0x02) {[m[41m[m
[32m+[m					[32mthis->WriteInt32(length);[m[41m[m
[32m+[m				[32m}[m[41m[m
[32m+[m				[32m// Write the actual data[m[41m[m
[32m+[m				[32mthis->WriteData(Buffer::Data(bufferObj), length);[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m			[32melse if(NanNew(bson->doubleString)->StrictEquals(constructorString))[m[41m[m
[32m+[m			[32m{[m[41m[m
[32m+[m				[32mthis->CommitType(typeLocation, BSON_TYPE_NUMBER);[m[41m[m
[32m+[m				[32mthis->WriteDouble(object, NanNew(bson->_doubleValueString));[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m			[32melse if(NanNew(bson->symbolString)->StrictEquals(constructorString))[m[41m[m
[32m+[m			[32m{[m[41m[m
[32m+[m				[32mthis->CommitType(typeLocation, BSON_TYPE_SYMBOL);[m[41m[m
[32m+[m				[32mthis->WriteLengthPrefixedString(object->Get(NanNew(bson->_symbolValueString))->ToString());[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m			[32melse if(NanNew(bson->codeString)->StrictEquals(constructorString))[m[41m[m
[32m+[m			[32m{[m[41m[m
[32m+[m				[32mconst Local<String>& function = object->Get(NanNew(bson->_codeCodeString))->ToString();[m[41m[m
[32m+[m				[32mconst Local<Object>& scope = object->Get(NanNew(bson->_codeScopeString))->ToObject();[m[41m[m
[32m+[m[41m[m
[32m+[m				[32m// For Node < 0.6.X use the GetPropertyNames[m[41m[m
[32m+[m	[32m      #if NODE_MAJOR_VERSION == 0 && NODE_MINOR_VERSION < 6[m[41m[m
[32m+[m	[32m        uint32_t propertyNameLength = scope->GetPropertyNames()->Length();[m[41m[m
[32m+[m	[32m      #else[m[41m[m
[32m+[m	[32m        uint32_t propertyNameLength = scope->GetOwnPropertyNames()->Length();[m[41m[m
[32m+[m	[32m      #endif[m[41m[m
[32m+[m[41m[m
[32m+[m				[32mif(propertyNameLength > 0)[m[41m[m
[32m+[m				[32m{[m[41m[m
[32m+[m					[32mthis->CommitType(typeLocation, BSON_TYPE_CODE_W_SCOPE);[m[41m[m
[32m+[m					[32mvoid* codeWidthScopeSize = this->BeginWriteSize();[m[41m[m
[32m+[m					[32mthis->WriteLengthPrefixedString(function->ToString());[m[41m[m
[32m+[m					[32mSerializeDocument(scope);[m[41m[m
[32m+[m					[32mthis->CommitSize(codeWidthScopeSize);[m[41m[m
[32m+[m				[32m}[m[41m[m
[32m+[m				[32melse[m[41m[m
[32m+[m				[32m{[m[41m[m
[32m+[m					[32mthis->CommitType(typeLocation, BSON_TYPE_CODE);[m[41m[m
[32m+[m					[32mthis->WriteLengthPrefixedString(function->ToString());[m[41m[m
[32m+[m				[32m}[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m			[32melse if(NanNew(bson->dbrefString)->StrictEquals(constructorString))[m[41m[m
[32m+[m			[32m{[m[41m[m
[32m+[m				[32mthis->CommitType(typeLocation, BSON_TYPE_OBJECT);[m[41m[m
[32m+[m[41m[m
[32m+[m				[32mvoid* dbRefSize = this->BeginWriteSize();[m[41m[m
[32m+[m[41m[m
[32m+[m				[32mvoid* refType = this->BeginWriteType();[m[41m[m
[32m+[m				[32mthis->WriteData("$ref", 5);[m[41m[m
[32m+[m				[32mSerializeValue(refType, object->Get(NanNew(bson->_dbRefNamespaceString)));[m[41m[m
[32m+[m[41m[m
[32m+[m				[32mvoid* idType = this->BeginWriteType();[m[41m[m
[32m+[m				[32mthis->WriteData("$id", 4);[m[41m[m
[32m+[m				[32mSerializeValue(idType, object->Get(NanNew(bson->_dbRefOidString)));[m[41m[m
[32m+[m[41m[m
[32m+[m				[32mconst Local<Value>& refDbValue = object->Get(NanNew(bson->_dbRefDbString));[m[41m[m
[32m+[m				[32mif(!refDbValue->IsUndefined())[m[41m[m
[32m+[m				[32m{[m[41m[m
[32m+[m					[32mvoid* dbType = this->BeginWriteType();[m[41m[m
[32m+[m					[32mthis->WriteData("$db", 4);[m[41m[m
[32m+[m					[32mSerializeValue(dbType, refDbValue);[m[41m[m
[32m+[m				[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m				[32mthis->WriteByte(0);[m[41m[m
[32m+[m				[32mthis->CommitSize(dbRefSize);[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m			[32melse if(NanNew(bson->minKeyString)->StrictEquals(constructorString))[m[41m[m
[32m+[m			[32m{[m[41m[m
[32m+[m				[32mthis->CommitType(typeLocation, BSON_TYPE_MIN_KEY);[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m			[32melse if(NanNew(bson->maxKeyString)->StrictEquals(constructorString))[m[41m[m
[32m+[m			[32m{[m[41m[m
[32m+[m				[32mthis->CommitType(typeLocation, BSON_TYPE_MAX_KEY);[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m		[32melse if(Buffer::HasInstance(value))[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mthis->CommitType(typeLocation, BSON_TYPE_BINARY);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m    #if NODE_MAJOR_VERSION == 0 && NODE_MINOR_VERSION < 3[m[41m[m
[32m+[m[32m       Local<Object> buffer = ObjectWrap::Unwrap<Buffer>(value->ToObject());[m[41m[m
[32m+[m			[32m uint32_t length = object->length();[m[41m[m
[32m+[m	[32m    #else[m[41m[m
[32m+[m			[32m uint32_t length = Buffer::Length(value->ToObject());[m[41m[m
[32m+[m	[32m    #endif[m[41m[m
[32m+[m[41m[m
[32m+[m			[32mthis->WriteInt32(length);[m[41m[m
[32m+[m			[32mthis->WriteByte(0);[m[41m[m
[32m+[m			[32mthis->WriteData(Buffer::Data(value->ToObject()), length);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m		[32melse[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mthis->CommitType(typeLocation, BSON_TYPE_OBJECT);[m[41m[m
[32m+[m			[32mSerializeDocument(value);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse if(value->IsNull() || value->IsUndefined())[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mthis->CommitType(typeLocation, BSON_TYPE_NULL);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32m// Data points to start of element list, length is length of entire document including '\0' but excluding initial size[m[41m[m
[32m+[m[32mBSONDeserializer::BSONDeserializer(BSON* aBson, char* data, size_t length)[m[41m[m
[32m+[m[32m: bson(aBson),[m[41m[m
[32m+[m[32m  pStart(data),[m[41m[m
[32m+[m[32m  p(data),[m[41m[m
[32m+[m[32m  pEnd(data + length - 1)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mif(*pEnd != '\0') ThrowAllocatedStringException(64, "Missing end of document marker '\\0'");[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mBSONDeserializer::BSONDeserializer(BSONDeserializer& parentSerializer, size_t length)[m[41m[m
[32m+[m[32m: bson(parentSerializer.bson),[m[41m[m
[32m+[m[32m  pStart(parentSerializer.p),[m[41m[m
[32m+[m[32m  p(parentSerializer.p),[m[41m[m
[32m+[m[32m  pEnd(parentSerializer.p + length - 1)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mparentSerializer.p += length;[m[41m[m
[32m+[m	[32mif(pEnd > parentSerializer.pEnd) ThrowAllocatedStringException(64, "Child document exceeds parent's bounds");[m[41m[m
[32m+[m	[32mif(*pEnd != '\0') ThrowAllocatedStringException(64, "Missing end of document marker '\\0'");[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mHandle<Value> BSONDeserializer::ReadCString()[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mchar* start = p;[m[41m[m
[32m+[m	[32mwhile(*p++ && (p < pEnd)) { }[m[41m[m
[32m+[m	[32mif(p > pEnd) {[m[41m[m
[32m+[m		[32mreturn NanNull();[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32mreturn NanNew<String>(start, (int32_t) (p-start-1) );[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mint32_t BSONDeserializer::ReadRegexOptions()[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mint32_t options = 0;[m[41m[m
[32m+[m	[32mfor(;;)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mswitch(*p++)[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m		[32mcase '\0': return options;[m[41m[m
[32m+[m		[32mcase 's': options |= RegExp::kGlobal; break;[m[41m[m
[32m+[m		[32mcase 'i': options |= RegExp::kIgnoreCase; break;[m[41m[m
[32m+[m		[32mcase 'm': options |= RegExp::kMultiline; break;[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32muint32_t BSONDeserializer::ReadIntegerString()[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32muint32_t value = 0;[m[41m[m
[32m+[m	[32mwhile(*p)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mif(*p < '0' || *p > '9') ThrowAllocatedStringException(64, "Invalid key for array");[m[41m[m
[32m+[m		[32mvalue = value * 10 + *p++ - '0';[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32m++p;[m[41m[m
[32m+[m	[32mreturn value;[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mLocal<String> BSONDeserializer::ReadString()[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32muint32_t length = ReadUInt32();[m[41m[m
[32m+[m	[32mchar* start = p;[m[41m[m
[32m+[m	[32mp += length;[m[41m[m
[32m+[m	[32mreturn NanNew<String>(start, length-1);[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mLocal<String> BSONDeserializer::ReadObjectId()[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32muint16_t objectId[12];[m[41m[m
[32m+[m	[32mfor(size_t i = 0; i < 12; ++i)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mobjectId[i] = *reinterpret_cast<unsigned char*>(p++);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32mreturn NanNew<String>(objectId, 12);[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mHandle<Value> BSONDeserializer::DeserializeDocument(bool promoteLongs)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32muint32_t length = ReadUInt32();[m[41m[m
[32m+[m	[32mif(length < 5) ThrowAllocatedStringException(64, "Bad BSON: Document is less than 5 bytes");[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mBSONDeserializer documentDeserializer(*this, length-4);[m[41m[m
[32m+[m	[32mreturn documentDeserializer.DeserializeDocumentInternal(promoteLongs);[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mHandle<Value> BSONDeserializer::DeserializeDocumentInternal(bool promoteLongs)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mLocal<Object> returnObject = NanNew<Object>();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mwhile(HasMoreData())[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mBsonType type = (BsonType) ReadByte();[m[41m[m
[32m+[m		[32mconst Handle<Value>& name = ReadCString();[m[41m[m
[32m+[m		[32mif(name->IsNull()) ThrowAllocatedStringException(64, "Bad BSON Document: illegal CString");[m[41m[m
[32m+[m		[32m// name->Is[m[41m[m
[32m+[m		[32mconst Handle<Value>& value = DeserializeValue(type, promoteLongs);[m[41m[m
[32m+[m		[32mreturnObject->ForceSet(name, value);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32mif(p != pEnd) ThrowAllocatedStringException(64, "Bad BSON Document: Serialize consumed unexpected number of bytes");[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// From JavaScript:[m[41m[m
[32m+[m	[32m// if(object['$id'] != null) object = new DBRef(object['$ref'], object['$id'], object['$db']);[m[41m[m
[32m+[m	[32mif(returnObject->Has(NanNew(bson->_dbRefIdRefString)))[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mLocal<Value> argv[] = { returnObject->Get(NanNew(bson->_dbRefRefString)), returnObject->Get(NanNew(bson->_dbRefIdRefString)), returnObject->Get(NanNew(bson->_dbRefDbRefString)) };[m[41m[m
[32m+[m		[32mreturn NanNew(bson->dbrefConstructor)->NewInstance(3, argv);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mreturn returnObject;[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mHandle<Value> BSONDeserializer::DeserializeArray(bool promoteLongs)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32muint32_t length = ReadUInt32();[m[41m[m
[32m+[m	[32mif(length < 5) ThrowAllocatedStringException(64, "Bad BSON: Array Document is less than 5 bytes");[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mBSONDeserializer documentDeserializer(*this, length-4);[m[41m[m
[32m+[m	[32mreturn documentDeserializer.DeserializeArrayInternal(promoteLongs);[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mHandle<Value> BSONDeserializer::DeserializeArrayInternal(bool promoteLongs)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mLocal<Array> returnArray = NanNew<Array>();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mwhile(HasMoreData())[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mBsonType type = (BsonType) ReadByte();[m[41m[m
[32m+[m		[32muint32_t index = ReadIntegerString();[m[41m[m
[32m+[m		[32mconst Handle<Value>& value = DeserializeValue(type, promoteLongs);[m[41m[m
[32m+[m		[32mreturnArray->Set(index, value);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32mif(p != pEnd) ThrowAllocatedStringException(64, "Bad BSON Array: Serialize consumed unexpected number of bytes");[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mreturn returnArray;[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mHandle<Value> BSONDeserializer::DeserializeValue(BsonType type, bool promoteLongs)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mswitch(type)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m	[32mcase BSON_TYPE_STRING:[m[41m[m
[32m+[m		[32mreturn ReadString();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_INT:[m[41m[m
[32m+[m		[32mreturn NanNew<Integer>(ReadInt32());[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_NUMBER:[m[41m[m
[32m+[m		[32mreturn NanNew<Number>(ReadDouble());[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_NULL:[m[41m[m
[32m+[m		[32mreturn NanNull();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_UNDEFINED:[m[41m[m
[32m+[m		[32mreturn NanNull();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_TIMESTAMP:[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mint32_t lowBits = ReadInt32();[m[41m[m
[32m+[m			[32mint32_t highBits = ReadInt32();[m[41m[m
[32m+[m			[32mLocal<Value> argv[] = { NanNew<Int32>(lowBits), NanNew<Int32>(highBits) };[m[41m[m
[32m+[m			[32mreturn NanNew(bson->timestampConstructor)->NewInstance(2, argv);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_BOOLEAN:[m[41m[m
[32m+[m		[32mreturn (ReadByte() != 0) ? NanTrue() : NanFalse();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_REGEXP:[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mconst Handle<Value>& regex = ReadCString();[m[41m[m
[32m+[m			[32mif(regex->IsNull()) ThrowAllocatedStringException(64, "Bad BSON Document: illegal CString");[m[41m[m
[32m+[m			[32mint32_t options = ReadRegexOptions();[m[41m[m
[32m+[m			[32mreturn NanNew<RegExp>(regex->ToString(), (RegExp::Flags) options);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_CODE:[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mconst Local<Value>& code = ReadString();[m[41m[m
[32m+[m			[32mconst Local<Value>& scope = NanNew<Object>();[m[41m[m
[32m+[m			[32mLocal<Value> argv[] = { code, scope };[m[41m[m
[32m+[m			[32mreturn NanNew(bson->codeConstructor)->NewInstance(2, argv);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_CODE_W_SCOPE:[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mReadUInt32();[m[41m[m
[32m+[m			[32mconst Local<Value>& code = ReadString();[m[41m[m
[32m+[m			[32mconst Handle<Value>& scope = DeserializeDocument(promoteLongs);[m[41m[m
[32m+[m			[32mLocal<Value> argv[] = { code, scope->ToObject() };[m[41m[m
[32m+[m			[32mreturn NanNew(bson->codeConstructor)->NewInstance(2, argv);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_OID:[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mLocal<Value> argv[] = { ReadObjectId() };[m[41m[m
[32m+[m			[32mreturn NanNew(bson->objectIDConstructor)->NewInstance(1, argv);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_BINARY:[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32muint32_t length = ReadUInt32();[m[41m[m
[32m+[m			[32muint32_t subType = ReadByte();[m[41m[m
[32m+[m			[32mif(subType == 0x02) {[m[41m[m
[32m+[m				[32mlength = ReadInt32();[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m			[32mLocal<Object> buffer = NanNewBufferHandle(p, length);[m[41m[m
[32m+[m			[32mp += length;[m[41m[m
[32m+[m[41m[m
[32m+[m			[32mHandle<Value> argv[] = { buffer, NanNew<Uint32>(subType) };[m[41m[m
[32m+[m			[32mreturn NanNew(bson->binaryConstructor)->NewInstance(2, argv);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_LONG:[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32m// Read 32 bit integers[m[41m[m
[32m+[m			[32mint32_t lowBits = (int32_t) ReadInt32();[m[41m[m
[32m+[m			[32mint32_t highBits = (int32_t) ReadInt32();[m[41m[m
[32m+[m[41m[m
[32m+[m			[32m// Promote long is enabled[m[41m[m
[32m+[m			[32mif(promoteLongs) {[m[41m[m
[32m+[m				[32m// If value is < 2^53 and >-2^53[m[41m[m
[32m+[m				[32mif((highBits < 0x200000 || (highBits == 0x200000 && lowBits == 0)) && highBits >= -0x200000) {[m[41m[m
[32m+[m					[32m// Adjust the pointer and read as 64 bit value[m[41m[m
[32m+[m					[32mp -= 8;[m[41m[m
[32m+[m					[32m// Read the 64 bit value[m[41m[m
[32m+[m					[32mint64_t finalValue = (int64_t) ReadInt64();[m[41m[m
[32m+[m					[32mreturn NanNew<Number>(finalValue);[m[41m[m
[32m+[m				[32m}[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m			[32m// Decode the Long value[m[41m[m
[32m+[m			[32mLocal<Value> argv[] = { NanNew<Int32>(lowBits), NanNew<Int32>(highBits) };[m[41m[m
[32m+[m			[32mreturn NanNew(bson->longConstructor)->NewInstance(2, argv);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_DATE:[m[41m[m
[32m+[m		[32mreturn NanNew<Date>((double) ReadInt64());[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_ARRAY:[m[41m[m
[32m+[m		[32mreturn DeserializeArray(promoteLongs);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_OBJECT:[m[41m[m
[32m+[m		[32mreturn DeserializeDocument(promoteLongs);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_SYMBOL:[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mconst Local<String>& string = ReadString();[m[41m[m
[32m+[m			[32mLocal<Value> argv[] = { string };[m[41m[m
[32m+[m			[32mreturn NanNew(bson->symbolConstructor)->NewInstance(1, argv);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_MIN_KEY:[m[41m[m
[32m+[m		[32mreturn NanNew(bson->minKeyConstructor)->NewInstance();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mcase BSON_TYPE_MAX_KEY:[m[41m[m
[32m+[m		[32mreturn NanNew(bson->maxKeyConstructor)->NewInstance();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mdefault:[m[41m[m
[32m+[m		[32mThrowAllocatedStringException(64, "Unhandled BSON Type: %d", type);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mreturn NanNull();[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mPersistent<FunctionTemplate> BSON::constructor_template;[m[41m[m
[32m+[m[41m[m
[32m+[m[32mBSON::BSON() : ObjectWrap()[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32m// Setup pre-allocated comparision objects[m[41m[m
[32m+[m[32m  NanAssignPersistent(_bsontypeString, NanNew<String>("_bsontype"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_longLowString, NanNew<String>("low_"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_longHighString, NanNew<String>("high_"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_objectIDidString, NanNew<String>("id"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_binaryPositionString, NanNew<String>("position"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_binarySubTypeString, NanNew<String>("sub_type"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_binaryBufferString, NanNew<String>("buffer"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_doubleValueString, NanNew<String>("value"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_symbolValueString, NanNew<String>("value"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_dbRefRefString, NanNew<String>("$ref"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_dbRefIdRefString, NanNew<String>("$id"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_dbRefDbRefString, NanNew<String>("$db"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_dbRefNamespaceString, NanNew<String>("namespace"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_dbRefDbString, NanNew<String>("db"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_dbRefOidString, NanNew<String>("oid"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_codeCodeString, NanNew<String>("code"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_codeScopeString, NanNew<String>("scope"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(_toBSONString, NanNew<String>("toBSON"));[m[41m[m
[32m+[m[41m[m
[32m+[m[32m  NanAssignPersistent(longString, NanNew<String>("Long"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(objectIDString, NanNew<String>("ObjectID"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(binaryString, NanNew<String>("Binary"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(codeString, NanNew<String>("Code"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(dbrefString, NanNew<String>("DBRef"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(symbolString, NanNew<String>("Symbol"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(doubleString, NanNew<String>("Double"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(timestampString, NanNew<String>("Timestamp"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(minKeyString, NanNew<String>("MinKey"));[m[41m[m
[32m+[m[32m  NanAssignPersistent(maxKeyString, NanNew<String>("MaxKey"));[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mvoid BSON::Initialize(v8::Handle<v8::Object> target)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32m// Grab the scope of the call from Node[m[41m[m
[32m+[m	[32mNanScope();[m[41m[m
[32m+[m	[32m// Define a new function template[m[41m[m
[32m+[m	[32mLocal<FunctionTemplate> t = NanNew<FunctionTemplate>(New);[m[41m[m
[32m+[m	[32mt->InstanceTemplate()->SetInternalFieldCount(1);[m[41m[m
[32m+[m	[32mt->SetClassName(NanNew<String>("BSON"));[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Instance methods[m[41m[m
[32m+[m	[32mNODE_SET_PROTOTYPE_METHOD(t, "calculateObjectSize", CalculateObjectSize);[m[41m[m
[32m+[m	[32mNODE_SET_PROTOTYPE_METHOD(t, "serialize", BSONSerialize);[m[41m[m
[32m+[m	[32mNODE_SET_PROTOTYPE_METHOD(t, "serializeWithBufferAndIndex", SerializeWithBufferAndIndex);[m[41m[m
[32m+[m	[32mNODE_SET_PROTOTYPE_METHOD(t, "deserialize", BSONDeserialize);[m[41m[m
[32m+[m	[32mNODE_SET_PROTOTYPE_METHOD(t, "deserializeStream", BSONDeserializeStream);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mNanAssignPersistent(constructor_template, t);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mtarget->ForceSet(NanNew<String>("BSON"), t->GetFunction());[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32m// Create a new instance of BSON and passing it the existing context[m[41m[m
[32m+[m[32mNAN_METHOD(BSON::New)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mNanScope();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Check that we have an array[m[41m[m
[32m+[m	[32mif(args.Length() == 1 && args[0]->IsArray())[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32m// Cast the array to a local reference[m[41m[m
[32m+[m		[32mLocal<Array> array = Local<Array>::Cast(args[0]);[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mif(array->Length() > 0)[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32m// Create a bson object instance and return it[m[41m[m
[32m+[m			[32mBSON *bson = new BSON();[m[41m[m
[32m+[m[41m[m
[32m+[m			[32muint32_t foundClassesMask = 0;[m[41m[m
[32m+[m[41m[m
[32m+[m			[32m// Iterate over all entries to save the instantiate functions[m[41m[m
[32m+[m			[32mfor(uint32_t i = 0; i < array->Length(); i++) {[m[41m[m
[32m+[m				[32m// Let's get a reference to the function[m[41m[m
[32m+[m				[32mLocal<Function> func = Local<Function>::Cast(array->Get(i));[m[41m[m
[32m+[m				[32mLocal<String> functionName = func->GetName()->ToString();[m[41m[m
[32m+[m[41m[m
[32m+[m				[32m// Save the functions making them persistant handles (they don't get collected)[m[41m[m
[32m+[m				[32mif(functionName->StrictEquals(NanNew(bson->longString))) {[m[41m[m
[32m+[m					[32mNanAssignPersistent(bson->longConstructor, func);[m[41m[m
[32m+[m					[32mfoundClassesMask |= 1;[m[41m[m
[32m+[m				[32m} else if(functionName->StrictEquals(NanNew(bson->objectIDString))) {[m[41m[m
[32m+[m					[32mNanAssignPersistent(bson->objectIDConstructor, func);[m[41m[m
[32m+[m					[32mfoundClassesMask |= 2;[m[41m[m
[32m+[m				[32m} else if(functionName->StrictEquals(NanNew(bson->binaryString))) {[m[41m[m
[32m+[m					[32mNanAssignPersistent(bson->binaryConstructor, func);[m[41m[m
[32m+[m					[32mfoundClassesMask |= 4;[m[41m[m
[32m+[m				[32m} else if(functionName->StrictEquals(NanNew(bson->codeString))) {[m[41m[m
[32m+[m					[32mNanAssignPersistent(bson->codeConstructor, func);[m[41m[m
[32m+[m					[32mfoundClassesMask |= 8;[m[41m[m
[32m+[m				[32m} else if(functionName->StrictEquals(NanNew(bson->dbrefString))) {[m[41m[m
[32m+[m					[32mNanAssignPersistent(bson->dbrefConstructor, func);[m[41m[m
[32m+[m					[32mfoundClassesMask |= 0x10;[m[41m[m
[32m+[m				[32m} else if(functionName->StrictEquals(NanNew(bson->symbolString))) {[m[41m[m
[32m+[m					[32mNanAssignPersistent(bson->symbolConstructor, func);[m[41m[m
[32m+[m					[32mfoundClassesMask |= 0x20;[m[41m[m
[32m+[m				[32m} else if(functionName->StrictEquals(NanNew(bson->doubleString))) {[m[41m[m
[32m+[m					[32mNanAssignPersistent(bson->doubleConstructor, func);[m[41m[m
[32m+[m					[32mfoundClassesMask |= 0x40;[m[41m[m
[32m+[m				[32m} else if(functionName->StrictEquals(NanNew(bson->timestampString))) {[m[41m[m
[32m+[m					[32mNanAssignPersistent(bson->timestampConstructor, func);[m[41m[m
[32m+[m					[32mfoundClassesMask |= 0x80;[m[41m[m
[32m+[m				[32m} else if(functionName->StrictEquals(NanNew(bson->minKeyString))) {[m[41m[m
[32m+[m					[32mNanAssignPersistent(bson->minKeyConstructor, func);[m[41m[m
[32m+[m					[32mfoundClassesMask |= 0x100;[m[41m[m
[32m+[m				[32m} else if(functionName->StrictEquals(NanNew(bson->maxKeyString))) {[m[41m[m
[32m+[m					[32mNanAssignPersistent(bson->maxKeyConstructor, func);[m[41m[m
[32m+[m					[32mfoundClassesMask |= 0x200;[m[41m[m
[32m+[m				[32m}[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m			[32m// Check if we have the right number of constructors otherwise throw an error[m[41m[m
[32m+[m			[32mif(foundClassesMask != 0x3ff) {[m[41m[m
[32m+[m				[32mdelete bson;[m[41m[m
[32m+[m				[32mreturn NanThrowError("Missing function constructor for either [Long/ObjectID/Binary/Code/DbRef/Symbol/Double/Timestamp/MinKey/MaxKey]");[m[41m[m
[32m+[m			[32m} else {[m[41m[m
[32m+[m				[32mbson->Wrap(args.This());[m[41m[m
[32m+[m				[32mNanReturnValue(args.This());[m[41m[m
[32m+[m			[32m}[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m		[32melse[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mreturn NanThrowError("No types passed in");[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mreturn NanThrowTypeError("Argument passed in must be an array of types");[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32m//------------------------------------------------------------------------------------------------[m[41m[m
[32m+[m[32m//------------------------------------------------------------------------------------------------[m[41m[m
[32m+[m[32m//------------------------------------------------------------------------------------------------[m[41m[m
[32m+[m[32m//------------------------------------------------------------------------------------------------[m[41m[m
[32m+[m[41m[m
[32m+[m[32mNAN_METHOD(BSON::BSONDeserialize)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mNanScope();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Fail if the first argument is not a string or a buffer[m[41m[m
[32m+[m	[32mif(args.Length() > 1 && !args[0]->IsString() && !Buffer::HasInstance(args[0]))[m[41m[m
[32m+[m		[32mreturn NanThrowError("First Argument must be a Buffer or String.");[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Promote longs[m[41m[m
[32m+[m	[32mbool promoteLongs = true;[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// If we have an options object[m[41m[m
[32m+[m	[32mif(args.Length() == 2 && args[1]->IsObject()) {[m[41m[m
[32m+[m		[32mLocal<Object> options = args[1]->ToObject();[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mif(options->Has(NanNew<String>("promoteLongs"))) {[m[41m[m
[32m+[m			[32mpromoteLongs = options->Get(NanNew<String>("promoteLongs"))->ToBoolean()->Value();[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Define pointer to data[m[41m[m
[32m+[m	[32mLocal<Object> obj = args[0]->ToObject();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Unpack the BSON parser instance[m[41m[m
[32m+[m	[32mBSON *bson = ObjectWrap::Unwrap<BSON>(args.This());[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// If we passed in a buffer, let's unpack it, otherwise let's unpack the string[m[41m[m
[32m+[m	[32mif(Buffer::HasInstance(obj))[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m[32m#if NODE_MAJOR_VERSION == 0 && NODE_MINOR_VERSION < 3[m[41m[m
[32m+[m		[32mLocal<Object> buffer = ObjectWrap::Unwrap<Buffer>(obj);[m[41m[m
[32m+[m		[32mchar* data = buffer->data();[m[41m[m
[32m+[m		[32msize_t length = buffer->length();[m[41m[m
[32m+[m[32m#else[m[41m[m
[32m+[m		[32mchar* data = Buffer::Data(obj);[m[41m[m
[32m+[m		[32msize_t length = Buffer::Length(obj);[m[41m[m
[32m+[m[32m#endif[m[41m[m
[32m+[m[41m[m
[32m+[m		[32m// Validate that we have at least 5 bytes[m[41m[m
[32m+[m		[32mif(length < 5) return NanThrowError("corrupt bson message < 5 bytes long");[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mtry[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mBSONDeserializer deserializer(bson, data, length);[m[41m[m
[32m+[m			[32m// deserializer.promoteLongs = promoteLongs;[m[41m[m
[32m+[m			[32mNanReturnValue(deserializer.DeserializeDocument(promoteLongs));[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m		[32mcatch(char* exception)[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mLocal<String> error = NanNew<String>(exception);[m[41m[m
[32m+[m			[32mfree(exception);[m[41m[m
[32m+[m			[32mreturn NanThrowError(error);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32m// The length of the data for this encoding[m[41m[m
[32m+[m		[32mssize_t len = DecodeBytes(args[0], BINARY);[m[41m[m
[32m+[m[41m[m
[32m+[m		[32m// Validate that we have at least 5 bytes[m[41m[m
[32m+[m		[32mif(len < 5) return NanThrowError("corrupt bson message < 5 bytes long");[m[41m[m
[32m+[m[41m[m
[32m+[m		[32m// Let's define the buffer size[m[41m[m
[32m+[m		[32mchar* data = (char *)malloc(len);[m[41m[m
[32m+[m		[32mif(data == NULL) die("Failed to allocate char buffer for BSON serialization");[m[41m[m
[32m+[m		[32mDecodeWrite(data, len, args[0], BINARY);[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mtry[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mBSONDeserializer deserializer(bson, data, len);[m[41m[m
[32m+[m			[32m// deserializer.promoteLongs = promoteLongs;[m[41m[m
[32m+[m			[32mHandle<Value> result = deserializer.DeserializeDocument(promoteLongs);[m[41m[m
[32m+[m			[32mfree(data);[m[41m[m
[32m+[m			[32mNanReturnValue(result);[m[41m[m
[32m+[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m		[32mcatch(char* exception)[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mLocal<String> error = NanNew<String>(exception);[m[41m[m
[32m+[m			[32mfree(exception);[m[41m[m
[32m+[m			[32mfree(data);[m[41m[m
[32m+[m			[32mreturn NanThrowError(error);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mLocal<Object> BSON::GetSerializeObject(const Handle<Value>& argValue)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mLocal<Object> object = argValue->ToObject();[m[41m[m
[32m+[m	[32mif(object->Has(NanNew(_toBSONString)))[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mconst Local<Value>& toBSON = object->Get(NanNew(_toBSONString));[m[41m[m
[32m+[m		[32mif(!toBSON->IsFunction()) ThrowAllocatedStringException(64, "toBSON is not a function");[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mLocal<Value> result = Local<Function>::Cast(toBSON)->Call(object, 0, NULL);[m[41m[m
[32m+[m		[32mif(!result->IsObject()) ThrowAllocatedStringException(64, "toBSON function did not return an object");[m[41m[m
[32m+[m		[32mreturn result->ToObject();[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mreturn object;[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mNAN_METHOD(BSON::BSONSerialize)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mNanScope();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mif(args.Length() == 1 && !args[0]->IsObject()) return NanThrowError("One, two or tree arguments required - [object] or [object, boolean] or [object, boolean, boolean]");[m[41m[m
[32m+[m	[32mif(args.Length() == 2 && !args[0]->IsObject() && !args[1]->IsBoolean()) return NanThrowError("One, two or tree arguments required - [object] or [object, boolean] or [object, boolean, boolean]");[m[41m[m
[32m+[m	[32mif(args.Length() == 3 && !args[0]->IsObject() && !args[1]->IsBoolean() && !args[2]->IsBoolean()) return NanThrowError("One, two or tree arguments required - [object] or [object, boolean] or [object, boolean, boolean]");[m[41m[m
[32m+[m	[32mif(args.Length() == 4 && !args[0]->IsObject() && !args[1]->IsBoolean() && !args[2]->IsBoolean() && !args[3]->IsBoolean()) return NanThrowError("One, two or tree arguments required - [object] or [object, boolean] or [object, boolean, boolean] or [object, boolean, boolean, boolean]");[m[41m[m
[32m+[m	[32mif(args.Length() > 4) return NanThrowError("One, two, tree or four arguments required - [object] or [object, boolean] or [object, boolean, boolean] or [object, boolean, boolean, boolean]");[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Check if we have an array as the object[m[41m[m
[32m+[m	[32mif(args[0]->IsArray()) return NanThrowError("Only javascript objects supported");[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Unpack the BSON parser instance[m[41m[m
[32m+[m	[32mBSON *bson = ObjectWrap::Unwrap<BSON>(args.This());[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Calculate the total size of the document in binary form to ensure we only allocate memory once[m[41m[m
[32m+[m	[32m// With serialize function[m[41m[m
[32m+[m	[32mbool serializeFunctions = (args.Length() >= 4) && args[3]->BooleanValue();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mchar *serialized_object = NULL;[m[41m[m
[32m+[m	[32msize_t object_size;[m[41m[m
[32m+[m	[32mtry[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mLocal<Object> object = bson->GetSerializeObject(args[0]);[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mBSONSerializer<CountStream> counter(bson, false, serializeFunctions);[m[41m[m
[32m+[m		[32mcounter.SerializeDocument(object);[m[41m[m
[32m+[m		[32mobject_size = counter.GetSerializeSize();[m[41m[m
[32m+[m[41m[m
[32m+[m		[32m// Allocate the memory needed for the serialization[m[41m[m
[32m+[m		[32mserialized_object = (char *)malloc(object_size);[m[41m[m
[32m+[m		[32mif(serialized_object == NULL) die("Failed to allocate memory for object");[m[41m[m
[32m+[m[41m[m
[32m+[m		[32m// Check if we have a boolean value[m[41m[m
[32m+[m		[32mbool checkKeys = args.Length() >= 3 && args[1]->IsBoolean() && args[1]->BooleanValue();[m[41m[m
[32m+[m		[32mBSONSerializer<DataStream> data(bson, checkKeys, serializeFunctions, serialized_object);[m[41m[m
[32m+[m		[32mdata.SerializeDocument(object);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32mcatch(char *err_msg)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mfree(serialized_object);[m[41m[m
[32m+[m		[32mLocal<String> error = NanNew<String>(err_msg);[m[41m[m
[32m+[m		[32mfree(err_msg);[m[41m[m
[32m+[m		[32mreturn NanThrowError(error);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// If we have 3 arguments[m[41m[m
[32m+[m	[32mif(args.Length() == 3 || args.Length() == 4)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mLocal<Object> buffer = NanNewBufferHandle(serialized_object, object_size);[m[41m[m
[32m+[m		[32mfree(serialized_object);[m[41m[m
[32m+[m		[32mNanReturnValue(buffer);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32melse[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mLocal<Value> bin_value = Encode(serialized_object, object_size, BINARY)->ToString();[m[41m[m
[32m+[m		[32mfree(serialized_object);[m[41m[m
[32m+[m		[32mNanReturnValue(bin_value);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mNAN_METHOD(BSON::CalculateObjectSize)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mNanScope();[m[41m[m
[32m+[m	[32m// Ensure we have a valid object[m[41m[m
[32m+[m	[32mif(args.Length() == 1 && !args[0]->IsObject()) return NanThrowError("One argument required - [object]");[m[41m[m
[32m+[m	[32mif(args.Length() == 2 && !args[0]->IsObject() && !args[1]->IsBoolean())  return NanThrowError("Two arguments required - [object, boolean]");[m[41m[m
[32m+[m	[32mif(args.Length() > 3) return NanThrowError("One or two arguments required - [object] or [object, boolean]");[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Unpack the BSON parser instance[m[41m[m
[32m+[m	[32mBSON *bson = ObjectWrap::Unwrap<BSON>(args.This());[m[41m[m
[32m+[m	[32mbool serializeFunctions = (args.Length() >= 2) && args[1]->BooleanValue();[m[41m[m
[32m+[m	[32mBSONSerializer<CountStream> countSerializer(bson, false, serializeFunctions);[m[41m[m
[32m+[m	[32mcountSerializer.SerializeDocument(args[0]);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Return the object size[m[41m[m
[32m+[m	[32mNanReturnValue(NanNew<Uint32>((uint32_t) countSerializer.GetSerializeSize()));[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mNAN_METHOD(BSON::SerializeWithBufferAndIndex)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mNanScope();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m//BSON.serializeWithBufferAndIndex = function serializeWithBufferAndIndex(object, ->, buffer, index) {[m[41m[m
[32m+[m	[32m// Ensure we have the correct values[m[41m[m
[32m+[m	[32mif(args.Length() > 5) return NanThrowError("Four or five parameters required [object, boolean, Buffer, int] or [object, boolean, Buffer, int, boolean]");[m[41m[m
[32m+[m	[32mif(args.Length() == 4 && !args[0]->IsObject() && !args[1]->IsBoolean() && !Buffer::HasInstance(args[2]) && !args[3]->IsUint32()) return NanThrowError("Four parameters required [object, boolean, Buffer, int]");[m[41m[m
[32m+[m	[32mif(args.Length() == 5 && !args[0]->IsObject() && !args[1]->IsBoolean() && !Buffer::HasInstance(args[2]) && !args[3]->IsUint32() && !args[4]->IsBoolean()) return NanThrowError("Four parameters required [object, boolean, Buffer, int, boolean]");[m[41m[m
[32m+[m[41m[m
[32m+[m	[32muint32_t index;[m[41m[m
[32m+[m	[32msize_t object_size;[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mtry[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mBSON *bson = ObjectWrap::Unwrap<BSON>(args.This());[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mLocal<Object> obj = args[2]->ToObject();[m[41m[m
[32m+[m		[32mchar* data = Buffer::Data(obj);[m[41m[m
[32m+[m		[32msize_t length = Buffer::Length(obj);[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mindex = args[3]->Uint32Value();[m[41m[m
[32m+[m		[32mbool checkKeys = args.Length() >= 4 && args[1]->IsBoolean() && args[1]->BooleanValue();[m[41m[m
[32m+[m		[32mbool serializeFunctions = (args.Length() == 5) && args[4]->BooleanValue();[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mBSONSerializer<DataStream> dataSerializer(bson, checkKeys, serializeFunctions, data+index);[m[41m[m
[32m+[m		[32mdataSerializer.SerializeDocument(bson->GetSerializeObject(args[0]));[m[41m[m
[32m+[m		[32mobject_size = dataSerializer.GetSerializeSize();[m[41m[m
[32m+[m[41m[m
[32m+[m		[32mif(object_size + index > length) return NanThrowError("Serious error - overflowed buffer!!");[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m	[32mcatch(char *exception)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mLocal<String> error = NanNew<String>(exception);[m[41m[m
[32m+[m		[32mfree(exception);[m[41m[m
[32m+[m		[32mreturn NanThrowError(error);[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mNanReturnValue(NanNew<Uint32>((uint32_t) (index + object_size - 1)));[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mNAN_METHOD(BSON::BSONDeserializeStream)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mNanScope();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// At least 3 arguments required[m[41m[m
[32m+[m	[32mif(args.Length() < 5) return NanThrowError("Arguments required (Buffer(data), Number(index in data), Number(number of documents to deserialize), Array(results), Number(index in the array), Object(optional))");[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// If the number of argumets equals 3[m[41m[m
[32m+[m	[32mif(args.Length() >= 5)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mif(!Buffer::HasInstance(args[0])) return NanThrowError("First argument must be Buffer instance");[m[41m[m
[32m+[m		[32mif(!args[1]->IsUint32()) return NanThrowError("Second argument must be a positive index number");[m[41m[m
[32m+[m		[32mif(!args[2]->IsUint32()) return NanThrowError("Third argument must be a positive number of documents to deserialize");[m[41m[m
[32m+[m		[32mif(!args[3]->IsArray()) return NanThrowError("Fourth argument must be an array the size of documents to deserialize");[m[41m[m
[32m+[m		[32mif(!args[4]->IsUint32()) return NanThrowError("Sixth argument must be a positive index number");[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// If we have 4 arguments[m[41m[m
[32m+[m	[32mif(args.Length() == 6 && !args[5]->IsObject()) return NanThrowError("Fifth argument must be an object with options");[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Define pointer to data[m[41m[m
[32m+[m	[32mLocal<Object> obj = args[0]->ToObject();[m[41m[m
[32m+[m	[32muint32_t numberOfDocuments = args[2]->Uint32Value();[m[41m[m
[32m+[m	[32muint32_t index = args[1]->Uint32Value();[m[41m[m
[32m+[m	[32muint32_t resultIndex = args[4]->Uint32Value();[m[41m[m
[32m+[m	[32mbool promoteLongs = true;[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Check for the value promoteLongs in the options object[m[41m[m
[32m+[m	[32mif(args.Length() == 6) {[m[41m[m
[32m+[m		[32mLocal<Object> options = args[5]->ToObject();[m[41m[m
[32m+[m[41m[m
[32m+[m		[32m// Check if we have the promoteLong variable[m[41m[m
[32m+[m		[32mif(options->Has(NanNew<String>("promoteLongs"))) {[m[41m[m
[32m+[m			[32mpromoteLongs = options->Get(NanNew<String>("promoteLongs"))->ToBoolean()->Value();[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Unpack the BSON parser instance[m[41m[m
[32m+[m	[32mBSON *bson = ObjectWrap::Unwrap<BSON>(args.This());[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Unpack the buffer variable[m[41m[m
[32m+[m[32m#if NODE_MAJOR_VERSION == 0 && NODE_MINOR_VERSION < 3[m[41m[m
[32m+[m	[32mLocal<Object> buffer = ObjectWrap::Unwrap<Buffer>(obj);[m[41m[m
[32m+[m	[32mchar* data = buffer->data();[m[41m[m
[32m+[m	[32msize_t length = buffer->length();[m[41m[m
[32m+[m[32m#else[m[41m[m
[32m+[m	[32mchar* data = Buffer::Data(obj);[m[41m[m
[32m+[m	[32msize_t length = Buffer::Length(obj);[m[41m[m
[32m+[m[32m#endif[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Fetch the documents[m[41m[m
[32m+[m	[32mLocal<Object> documents = args[3]->ToObject();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mBSONDeserializer deserializer(bson, data+index, length-index);[m[41m[m
[32m+[m	[32mfor(uint32_t i = 0; i < numberOfDocuments; i++)[m[41m[m
[32m+[m	[32m{[m[41m[m
[32m+[m		[32mtry[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m			[32mdocuments->Set(i + resultIndex, deserializer.DeserializeDocument(promoteLongs));[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m		[32mcatch (char* exception)[m[41m[m
[32m+[m		[32m{[m[41m[m
[32m+[m		[32m        Local<String> error = NanNew<String>(exception);[m[41m[m
[32m+[m			[32mfree(exception);[m[41m[m
[32m+[m			[32mreturn NanThrowError(error);[m[41m[m
[32m+[m		[32m}[m[41m[m
[32m+[m	[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Return new index of parsing[m[41m[m
[32m+[m	[32mNanReturnValue(NanNew<Uint32>((uint32_t) (index + deserializer.GetSerializeSize())));[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32m// Exporting function[m[41m[m
[32m+[m[32mextern "C" void init(Handle<Object> target)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mNanScope();[m[41m[m
[32m+[m	[32mBSON::Initialize(target);[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
[32m+[m[32mNODE_MODULE(bson, BSON::Initialize);[m[41m[m
[1mdiff --git a/node_modules/mongodb/node_modules/bson/ext/bson.h b/node_modules/mongodb/node_modules/bson/ext/bson.h[m
[1mindex e53c82f..a7feff7 100644[m
[1m--- a/node_modules/mongodb/node_modules/bson/ext/bson.h[m
[1m+++ b/node_modules/mongodb/node_modules/bson/ext/bson.h[m
[36m@@ -1,278 +1,278 @@[m
[31m-//===========================================================================[m
[31m-[m
[31m-#ifndef BSON_H_[m
[31m-#define BSON_H_[m
[31m-[m
[31m-//===========================================================================[m
[31m-[m
[31m-#ifdef __arm__[m
[31m-#define USE_MISALIGNED_MEMORY_ACCESS 0[m
[31m-#else[m
[31m-#define USE_MISALIGNED_MEMORY_ACCESS 1[m
[31m-#endif[m
[31m-[m
[31m-#include <node.h>[m
[31m-#include <node_object_wrap.h>[m
[31m-#include <v8.h>[m
[31m-#include "nan.h"[m
[31m-[m
[31m-using namespace v8;[m
[31m-using namespace node;[m
[31m-[m
[31m-//===========================================================================[m
[31m-[m
[31m-enum BsonType[m
[31m-{[m
[31m-	BSON_TYPE_NUMBER		= 1,[m
[31m-	BSON_TYPE_STRING		= 2,[m
[31m-	BSON_TYPE_OBJECT		= 3,[m
[31m-	BSON_TYPE_ARRAY			= 4,[m
[31m-	BSON_TYPE_BINARY		= 5,[m
[31m-	BSON_TYPE_UNDEFINED		= 6,[m
[31m-	BSON_TYPE_OID			= 7,[m
[31m-	BSON_TYPE_BOOLEAN		= 8,[m
[31m-	BSON_TYPE_DATE			= 9,[m
[31m-	BSON_TYPE_NULL			= 10,[m
[31m-	BSON_TYPE_REGEXP		= 11,[m
[31m-	BSON_TYPE_CODE			= 13,[m
[31m-	BSON_TYPE_SYMBOL		= 14,[m
[31m-	BSON_TYPE_CODE_W_SCOPE	= 15,[m
[31m-	BSON_TYPE_INT			= 16,[m
[31m-	BSON_TYPE_TIMESTAMP		= 17,[m
[31m-	BSON_TYPE_LONG			= 18,[m
[31m-	BSON_TYPE_MAX_KEY		= 0x7f,[m
[31m-	BSON_TYPE_MIN_KEY		= 0xff[m
[31m-};[m
[31m-[m
[31m-//===========================================================================[m
[31m-[m
[31m-template<typename T> class BSONSerializer;[m
[31m-[m
[31m-class BSON : public ObjectWrap {[m
[31m-public:[m
[31m-	BSON();[m
[31m-	~BSON() {}[m
[31m-[m
[31m-	static void Initialize(Handle<Object> target);[m
[31m-        static NAN_METHOD(BSONDeserializeStream);[m
[31m-[m
[31m-	// JS based objects[m
[31m-	static NAN_METHOD(BSONSerialize);[m
[31m-	static NAN_METHOD(BSONDeserialize);[m
[31m-[m
[31m-        // Calculate size of function[m
[31m-	static NAN_METHOD(CalculateObjectSize);[m
[31m-	static NAN_METHOD(SerializeWithBufferAndIndex);[m
[31m-[m
[31m-	// Constructor used for creating new BSON objects from C++[m
[31m-	static Persistent<FunctionTemplate> constructor_template;[m
[31m-[m
[31m-private:[m
[31m-	static NAN_METHOD(New);[m
[31m-	static Handle<Value> deserialize(BSON *bson, char *data, uint32_t dataLength, uint32_t startIndex, bool is_array_item);[m
[31m-[m
[31m-	// BSON type instantiate functions[m
[31m-	Persistent<Function> longConstructor;[m
[31m-	Persistent<Function> objectIDConstructor;[m
[31m-	Persistent<Function> binaryConstructor;[m
[31m-	Persistent<Function> codeConstructor;[m
[31m-	Persistent<Function> dbrefConstructor;[m
[31m-	Persistent<Function> symbolConstructor;[m
[31m-	Persistent<Function> doubleConstructor;[m
[31m-	Persistent<Function> timestampConstructor;[m
[31m-	Persistent<Function> minKeyConstructor;[m
[31m-	Persistent<Function> maxKeyConstructor;[m
[31m-[m
[31m-	// Equality Objects[m
[31m-	Persistent<String> longString;[m
[31m-	Persistent<String> objectIDString;[m
[31m-	Persistent<String> binaryString;[m
[31m-	Persistent<String> codeString;[m
[31m-	Persistent<String> dbrefString;[m
[31m-	Persistent<String> symbolString;[m
[31m-	Persistent<String> doubleString;[m
[31m-	Persistent<String> timestampString;[m
[31m-	Persistent<String> minKeyString;[m
[31m-	Persistent<String> maxKeyString;[m
[31m-[m
[31m-	// Equality speed up comparison objects[m
[31m-	Persistent<String> _bsontypeString;[m
[31m-	Persistent<String> _longLowString;[m
[31m-	Persistent<String> _longHighString;[m
[31m-	Persistent<String> _objectIDidString;[m
[31m-	Persistent<String> _binaryPositionString;[m
[31m-	Persistent<String> _binarySubTypeString;[m
[31m-	Persistent<String> _binaryBufferString;[m
[31m-	Persistent<String> _doubleValueString;[m
[31m-	Persistent<String> _symbolValueString;[m
[31m-[m
[31m-	Persistent<String> _dbRefRefString;[m
[31m-	Persistent<String> _dbRefIdRefString;[m
[31m-	Persistent<String> _dbRefDbRefString;[m
[31m-	Persistent<String> _dbRefNamespaceString;[m
[31m-	Persistent<String> _dbRefDbString;[m
[31m-	Persistent<String> _dbRefOidString;[m
[31m-[m
[31m-	Persistent<String> _codeCodeString;[m
[31m-	Persistent<String> _codeScopeString;[m
[31m-	Persistent<String> _toBSONString;[m
[31m-[m
[31m-	Local<Object> GetSerializeObject(const Handle<Value>& object);[m
[31m-[m
[31m-	template<typename T> friend class BSONSerializer;[m
[31m-	friend class BSONDeserializer;[m
[31m-};[m
[31m-[m
[31m-//===========================================================================[m
[31m-[m
[31m-class CountStream[m
[31m-{[m
[31m-public:[m
[31m-	CountStream() : count(0) { }[m
[31m-[m
[31m-	void	WriteByte(int value)									{ ++count; }[m
[31m-	void	WriteByte(const Handle<Object>&, const Handle<String>&)	{ ++count; }[m
[31m-	void	WriteBool(const Handle<Value>& value)					{ ++count; }[m
[31m-	void	WriteInt32(int32_t value)								{ count += 4; }[m
[31m-	void	WriteInt32(const Handle<Value>& value)					{ count += 4; }[m
[31m-	void	WriteInt32(const Handle<Object>& object, const Handle<String>& key) { count += 4; }[m
[31m-	void	WriteInt64(int64_t value)								{ count += 8; }[m
[31m-	void	WriteInt64(const Handle<Value>& value)					{ count += 8; }[m
[31m-	void	WriteDouble(double value)								{ count += 8; }[m
[31m-	void	WriteDouble(const Handle<Value>& value)					{ count += 8; }[m
[31m-	void	WriteDouble(const Handle<Object>&, const Handle<String>&) { count += 8; }[m
[31m-	void	WriteUInt32String(uint32_t name)						{ char buffer[32]; count += sprintf(buffer, "%u", name) + 1; }[m
[31m-	void	WriteLengthPrefixedString(const Local<String>& value)	{ count += value->Utf8Length()+5; }[m
[31m-	void	WriteObjectId(const Handle<Object>& object, const Handle<String>& key)				{ count += 12; }[m
[31m-	void	WriteString(const Local<String>& value)					{ count += value->Utf8Length() + 1; }	// This returns the number of bytes exclusive of the NULL terminator[m
[31m-	void	WriteData(const char* data, size_t length)				{ count += length; }[m
[31m-[m
[31m-	void*	BeginWriteType()										{ ++count; return NULL; }[m
[31m-	void	CommitType(void*, BsonType)								{ }[m
[31m-	void*	BeginWriteSize()										{ count += 4; return NULL; }[m
[31m-	void	CommitSize(void*)										{ }[m
[31m-[m
[31m-	size_t GetSerializeSize() const									{ return count; }[m
[31m-[m
[31m-	// Do nothing. CheckKey is implemented for DataStream[m
[31m-	void	CheckKey(const Local<String>&)							{ }[m
[31m-[m
[31m-private:[m
[31m-	size_t	count;[m
[31m-};[m
[31m-[m
[31m-class DataStream[m
[31m-{[m
[31m-public:[m
[31m-	DataStream(char* aDestinationBuffer) : destinationBuffer(aDestinationBuffer), p(aDestinationBuffer) { }[m
[31m-[m
[31m-	void	WriteByte(int value)									{ *p++ = value; }[m
[31m-	void	WriteByte(const Handle<Object>& object, const Handle<String>& key)	{ *p++ = object->Get(key)->Int32Value(); }[m
[31m-#if USE_MISALIGNED_MEMORY_ACCESS[m
[31m-	void	WriteInt32(int32_t value)								{ *reinterpret_cast<int32_t*>(p) = value; p += 4; }[m
[31m-	void	WriteInt64(int64_t value)								{ *reinterpret_cast<int64_t*>(p) = value; p += 8; }[m
[31m-	void	WriteDouble(double value)								{ *reinterpret_cast<double*>(p) = value; p += 8; }[m
[31m-#else[m
[31m-	void	WriteInt32(int32_t value)								{ memcpy(p, &value, 4); p += 4; }[m
[31m-	void	WriteInt64(int64_t value)								{ memcpy(p, &value, 8); p += 8; }[m
[31m-	void	WriteDouble(double value)								{ memcpy(p, &value, 8); p += 8; }[m
[31m-#endif[m
[31m-	void	WriteBool(const Handle<Value>& value)					{ WriteByte(value->BooleanValue() ? 1 : 0); }[m
[31m-	void	WriteInt32(const Handle<Value>& value)					{ WriteInt32(value->Int32Value());			}[m
[31m-	void	WriteInt32(const Handle<Object>& object, const Handle<String>& key) { WriteInt32(object->Get(key)); }[m
[31m-	void	WriteInt64(const Handle<Value>& value)					{ WriteInt64(value->IntegerValue());		}[m
[31m-	void	WriteDouble(const Handle<Value>& value)					{ WriteDouble(value->NumberValue());		}[m
[31m-	void	WriteDouble(const Handle<Object>& object, const Handle<String>& key) { WriteDouble(object->Get(key)); }[m
[31m-	void	WriteUInt32String(uint32_t name)						{ p += sprintf(p, "%u", name) + 1;			}[m
[31m-	void	WriteLengthPrefixedString(const Local<String>& value)	{ WriteInt32(value->Utf8Length()+1); WriteString(value); }[m
[31m-	void	WriteObjectId(const Handle<Object>& object, const Handle<String>& key);[m
[31m-	void	WriteString(const Local<String>& value)					{ p += value->WriteUtf8(p); }		// This returns the number of bytes inclusive of the NULL terminator.[m
[31m-	void	WriteData(const char* data, size_t length)				{ memcpy(p, data, length); p += length; }[m
[31m-[m
[31m-	void*	BeginWriteType()										{ void* returnValue = p; p++; return returnValue; }[m
[31m-	void	CommitType(void* beginPoint, BsonType value)			{ *reinterpret_cast<unsigned char*>(beginPoint) = value; }[m
[31m-	void*	BeginWriteSize()										{ void* returnValue = p; p += 4; return returnValue; }[m
[31m-[m
[31m-#if USE_MISALIGNED_MEMORY_ACCESS[m
[31m-	void	CommitSize(void* beginPoint)							{ *reinterpret_cast<int32_t*>(beginPoint) = (int32_t) (p - (char*) beginPoint); }[m
[31m-#else[m
[31m-	void	CommitSize(void* beginPoint)							{ int32_t value = (int32_t) (p - (char*) beginPoint); memcpy(beginPoint, &value, 4); }[m
[31m-#endif[m
[31m-[m
[31m-	size_t GetSerializeSize() const									{ return p - destinationBuffer; }[m
[31m-[m
[31m-	void	CheckKey(const Local<String>& keyName);[m
[31m-[m
[31m-protected:[m
[31m-	char *const	destinationBuffer;		// base, never changes[m
[31m-	char*		p;						// cursor into buffer[m
[31m-};[m
[31m-[m
[31m-template<typename T> class BSONSerializer : public T[m
[31m-{[m
[31m-private:[m
[31m-	typedef T Inherited;[m
[31m-[m
[31m-public:[m
[31m-	BSONSerializer(BSON* aBson, bool aCheckKeys, bool aSerializeFunctions) : Inherited(), checkKeys(aCheckKeys), serializeFunctions(aSerializeFunctions), bson(aBson) { }[m
[31m-	BSONSerializer(BSON* aBson, bool aCheckKeys, bool aSerializeFunctions, char* parentParam) : Inherited(parentParam), checkKeys(aCheckKeys), serializeFunctions(aSerializeFunctions), bson(aBson) { }[m
[31m-[m
[31m-	void SerializeDocument(const Handle<Value>& value);[m
[31m-	void SerializeArray(const Handle<Value>& value);[m
[32m+[m[32m//===========================================================================[m[41m[m
[32m+[m[41m[m
[32m+[m[32m#ifndef BSON_H_[m[41m[m
[32m+[m[32m#define BSON_H_[m[41m[m
[32m+[m[41m[m
[32m+[m[32m//===========================================================================[m[41m[m
[32m+[m[41m[m
[32m+[m[32m#ifdef __arm__[m[41m[m
[32m+[m[32m#define USE_MISALIGNED_MEMORY_ACCESS 0[m[41m[m
[32m+[m[32m#else[m[41m[m
[32m+[m[32m#define USE_MISALIGNED_MEMORY_ACCESS 1[m[41m[m
[32m+[m[32m#endif[m[41m[m
[32m+[m[41m[m
[32m+[m[32m#include <node.h>[m[41m[m
[32m+[m[32m#include <node_object_wrap.h>[m[41m[m
[32m+[m[32m#include <v8.h>[m[41m[m
[32m+[m[32m#include "nan.h"[m[41m[m
[32m+[m[41m[m
[32m+[m[32musing namespace v8;[m[41m[m
[32m+[m[32musing namespace node;[m[41m[m
[32m+[m[41m[m
[32m+[m[32m//===========================================================================[m[41m[m
[32m+[m[41m[m
[32m+[m[32menum BsonType[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m	[32mBSON_TYPE_NUMBER		= 1,[m[41m[m
[32m+[m	[32mBSON_TYPE_STRING		= 2,[m[41m[m
[32m+[m	[32mBSON_TYPE_OBJECT		= 3,[m[41m[m
[32m+[m	[32mBSON_TYPE_ARRAY			= 4,[m[41m[m
[32m+[m	[32mBSON_TYPE_BINARY		= 5,[m[41m[m
[32m+[m	[32mBSON_TYPE_UNDEFINED		= 6,[m[41m[m
[32m+[m	[32mBSON_TYPE_OID			= 7,[m[41m[m
[32m+[m	[32mBSON_TYPE_BOOLEAN		= 8,[m[41m[m
[32m+[m	[32mBSON_TYPE_DATE			= 9,[m[41m[m
[32m+[m	[32mBSON_TYPE_NULL			= 10,[m[41m[m
[32m+[m	[32mBSON_TYPE_REGEXP		= 11,[m[41m[m
[32m+[m	[32mBSON_TYPE_CODE			= 13,[m[41m[m
[32m+[m	[32mBSON_TYPE_SYMBOL		= 14,[m[41m[m
[32m+[m	[32mBSON_TYPE_CODE_W_SCOPE	= 15,[m[41m[m
[32m+[m	[32mBSON_TYPE_INT			= 16,[m[41m[m
[32m+[m	[32mBSON_TYPE_TIMESTAMP		= 17,[m[41m[m
[32m+[m	[32mBSON_TYPE_LONG			= 18,[m[41m[m
[32m+[m	[32mBSON_TYPE_MAX_KEY		= 0x7f,[m[41m[m
[32m+[m	[32mBSON_TYPE_MIN_KEY		= 0xff[m[41m[m
[32m+[m[32m};[m[41m[m
[32m+[m[41m[m
[32m+[m[32m//===========================================================================[m[41m[m
[32m+[m[41m[m
[32m+[m[32mtemplate<typename T> class BSONSerializer;[m[41m[m
[32m+[m[41m[m
[32m+[m[32mclass BSON : public ObjectWrap {[m[41m[m
[32m+[m[32mpublic:[m[41m[m
[32m+[m	[32mBSON();[m[41m[m
[32m+[m	[32m~BSON() {}[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mstatic void Initialize(Handle<Object> target);[m[41m[m
[32m+[m[32m        static NAN_METHOD(BSONDeserializeStream);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// JS based objects[m[41m[m
[32m+[m	[32mstatic NAN_METHOD(BSONSerialize);[m[41m[m
[32m+[m	[32mstatic NAN_METHOD(BSONDeserialize);[m[41m[m
[32m+[m[41m[m
[32m+[m[32m        // Calculate size of function[m[41m[m
[32m+[m	[32mstatic NAN_METHOD(CalculateObjectSize);[m[41m[m
[32m+[m	[32mstatic NAN_METHOD(SerializeWithBufferAndIndex);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Constructor used for creating new BSON objects from C++[m[41m[m
[32m+[m	[32mstatic Persistent<FunctionTemplate> constructor_template;[m[41m[m
[32m+[m[41m[m
[32m+[m[32mprivate:[m[41m[m
[32m+[m	[32mstatic NAN_METHOD(New);[m[41m[m
[32m+[m	[32mstatic Handle<Value> deserialize(BSON *bson, char *data, uint32_t dataLength, uint32_t startIndex, bool is_array_item);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// BSON type instantiate functions[m[41m[m
[32m+[m	[32mPersistent<Function> longConstructor;[m[41m[m
[32m+[m	[32mPersistent<Function> objectIDConstructor;[m[41m[m
[32m+[m	[32mPersistent<Function> binaryConstructor;[m[41m[m
[32m+[m	[32mPersistent<Function> codeConstructor;[m[41m[m
[32m+[m	[32mPersistent<Function> dbrefConstructor;[m[41m[m
[32m+[m	[32mPersistent<Function> symbolConstructor;[m[41m[m
[32m+[m	[32mPersistent<Function> doubleConstructor;[m[41m[m
[32m+[m	[32mPersistent<Function> timestampConstructor;[m[41m[m
[32m+[m	[32mPersistent<Function> minKeyConstructor;[m[41m[m
[32m+[m	[32mPersistent<Function> maxKeyConstructor;[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Equality Objects[m[41m[m
[32m+[m	[32mPersistent<String> longString;[m[41m[m
[32m+[m	[32mPersistent<String> objectIDString;[m[41m[m
[32m+[m	[32mPersistent<String> binaryString;[m[41m[m
[32m+[m	[32mPersistent<String> codeString;[m[41m[m
[32m+[m	[32mPersistent<String> dbrefString;[m[41m[m
[32m+[m	[32mPersistent<String> symbolString;[m[41m[m
[32m+[m	[32mPersistent<String> doubleString;[m[41m[m
[32m+[m	[32mPersistent<String> timestampString;[m[41m[m
[32m+[m	[32mPersistent<String> minKeyString;[m[41m[m
[32m+[m	[32mPersistent<String> maxKeyString;[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Equality speed up comparison objects[m[41m[m
[32m+[m	[32mPersistent<String> _bsontypeString;[m[41m[m
[32m+[m	[32mPersistent<String> _longLowString;[m[41m[m
[32m+[m	[32mPersistent<String> _longHighString;[m[41m[m
[32m+[m	[32mPersistent<String> _objectIDidString;[m[41m[m
[32m+[m	[32mPersistent<String> _binaryPositionString;[m[41m[m
[32m+[m	[32mPersistent<String> _binarySubTypeString;[m[41m[m
[32m+[m	[32mPersistent<String> _binaryBufferString;[m[41m[m
[32m+[m	[32mPersistent<String> _doubleValueString;[m[41m[m
[32m+[m	[32mPersistent<String> _symbolValueString;[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mPersistent<String> _dbRefRefString;[m[41m[m
[32m+[m	[32mPersistent<String> _dbRefIdRefString;[m[41m[m
[32m+[m	[32mPersistent<String> _dbRefDbRefString;[m[41m[m
[32m+[m	[32mPersistent<String> _dbRefNamespaceString;[m[41m[m
[32m+[m	[32mPersistent<String> _dbRefDbString;[m[41m[m
[32m+[m	[32mPersistent<String> _dbRefOidString;[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mPersistent<String> _codeCodeString;[m[41m[m
[32m+[m	[32mPersistent<String> _codeScopeString;[m[41m[m
[32m+[m	[32mPersistent<String> _toBSONString;[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mLocal<Object> GetSerializeObject(const Handle<Value>& object);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mtemplate<typename T> friend class BSONSerializer;[m[41m[m
[32m+[m	[32mfriend class BSONDeserializer;[m[41m[m
[32m+[m[32m};[m[41m[m
[32m+[m[41m[m
[32m+[m[32m//===========================================================================[m[41m[m
[32m+[m[41m[m
[32m+[m[32mclass CountStream[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m[32mpublic:[m[41m[m
[32m+[m	[32mCountStream() : count(0) { }[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mvoid	WriteByte(int value)									{ ++count; }[m[41m[m
[32m+[m	[32mvoid	WriteByte(const Handle<Object>&, const Handle<String>&)	{ ++count; }[m[41m[m
[32m+[m	[32mvoid	WriteBool(const Handle<Value>& value)					{ ++count; }[m[41m[m
[32m+[m	[32mvoid	WriteInt32(int32_t value)								{ count += 4; }[m[41m[m
[32m+[m	[32mvoid	WriteInt32(const Handle<Value>& value)					{ count += 4; }[m[41m[m
[32m+[m	[32mvoid	WriteInt32(const Handle<Object>& object, const Handle<String>& key) { count += 4; }[m[41m[m
[32m+[m	[32mvoid	WriteInt64(int64_t value)								{ count += 8; }[m[41m[m
[32m+[m	[32mvoid	WriteInt64(const Handle<Value>& value)					{ count += 8; }[m[41m[m
[32m+[m	[32mvoid	WriteDouble(double value)								{ count += 8; }[m[41m[m
[32m+[m	[32mvoid	WriteDouble(const Handle<Value>& value)					{ count += 8; }[m[41m[m
[32m+[m	[32mvoid	WriteDouble(const Handle<Object>&, const Handle<String>&) { count += 8; }[m[41m[m
[32m+[m	[32mvoid	WriteUInt32String(uint32_t name)						{ char buffer[32]; count += sprintf(buffer, "%u", name) + 1; }[m[41m[m
[32m+[m	[32mvoid	WriteLengthPrefixedString(const Local<String>& value)	{ count += value->Utf8Length()+5; }[m[41m[m
[32m+[m	[32mvoid	WriteObjectId(const Handle<Object>& object, const Handle<String>& key)				{ count += 12; }[m[41m[m
[32m+[m	[32mvoid	WriteString(const Local<String>& value)					{ count += value->Utf8Length() + 1; }	// This returns the number of bytes exclusive of the NULL terminator[m[41m[m
[32m+[m	[32mvoid	WriteData(const char* data, size_t length)				{ count += length; }[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mvoid*	BeginWriteType()										{ ++count; return NULL; }[m[41m[m
[32m+[m	[32mvoid	CommitType(void*, BsonType)								{ }[m[41m[m
[32m+[m	[32mvoid*	BeginWriteSize()										{ count += 4; return NULL; }[m[41m[m
[32m+[m	[32mvoid	CommitSize(void*)										{ }[m[41m[m
[32m+[m[41m[m
[32m+[m	[32msize_t GetSerializeSize() const									{ return count; }[m[41m[m
[32m+[m[41m[m
[32m+[m	[32m// Do nothing. CheckKey is implemented for DataStream[m[41m[m
[32m+[m	[32mvoid	CheckKey(const Local<String>&)							{ }[m[41m[m
[32m+[m[41m[m
[32m+[m[32mprivate:[m[41m[m
[32m+[m	[32msize_t	count;[m[41m[m
[32m+[m[32m};[m[41m[m
[32m+[m[41m[m
[32m+[m[32mclass DataStream[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m[32mpublic:[m[41m[m
[32m+[m	[32mDataStream(char* aDestinationBuffer) : destinationBuffer(aDestinationBuffer), p(aDestinationBuffer) { }[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mvoid	WriteByte(int value)									{ *p++ = value; }[m[41m[m
[32m+[m	[32mvoid	WriteByte(const Handle<Object>& object, const Handle<String>& key)	{ *p++ = object->Get(key)->Int32Value(); }[m[41m[m
[32m+[m[32m#if USE_MISALIGNED_MEMORY_ACCESS[m[41m[m
[32m+[m	[32mvoid	WriteInt32(int32_t value)								{ *reinterpret_cast<int32_t*>(p) = value; p += 4; }[m[41m[m
[32m+[m	[32mvoid	WriteInt64(int64_t value)								{ *reinterpret_cast<int64_t*>(p) = value; p += 8; }[m[41m[m
[32m+[m	[32mvoid	WriteDouble(double value)								{ *reinterpret_cast<double*>(p) = value; p += 8; }[m[41m[m
[32m+[m[32m#else[m[41m[m
[32m+[m	[32mvoid	WriteInt32(int32_t value)								{ memcpy(p, &value, 4); p += 4; }[m[41m[m
[32m+[m	[32mvoid	WriteInt64(int64_t value)								{ memcpy(p, &value, 8); p += 8; }[m[41m[m
[32m+[m	[32mvoid	WriteDouble(double value)								{ memcpy(p, &value, 8); p += 8; }[m[41m[m
[32m+[m[32m#endif[m[41m[m
[32m+[m	[32mvoid	WriteBool(const Handle<Value>& value)					{ WriteByte(value->BooleanValue() ? 1 : 0); }[m[41m[m
[32m+[m	[32mvoid	WriteInt32(const Handle<Value>& value)					{ WriteInt32(value->Int32Value());			}[m[41m[m
[32m+[m	[32mvoid	WriteInt32(const Handle<Object>& object, const Handle<String>& key) { WriteInt32(object->Get(key)); }[m[41m[m
[32m+[m	[32mvoid	WriteInt64(const Handle<Value>& value)					{ WriteInt64(value->IntegerValue());		}[m[41m[m
[32m+[m	[32mvoid	WriteDouble(const Handle<Value>& value)					{ WriteDouble(value->NumberValue());		}[m[41m[m
[32m+[m	[32mvoid	WriteDouble(const Handle<Object>& object, const Handle<String>& key) { WriteDouble(object->Get(key)); }[m[41m[m
[32m+[m	[32mvoid	WriteUInt32String(uint32_t name)						{ p += sprintf(p, "%u", name) + 1;			}[m[41m[m
[32m+[m	[32mvoid	WriteLengthPrefixedString(const Local<String>& value)	{ WriteInt32(value->Utf8Length()+1); WriteString(value); }[m[41m[m
[32m+[m	[32mvoid	WriteObjectId(const Handle<Object>& object, const Handle<String>& key);[m[41m[m
[32m+[m	[32mvoid	WriteString(const Local<String>& value)					{ p += value->WriteUtf8(p); }		// This returns the number of bytes inclusive of the NULL terminator.[m[41m[m
[32m+[m	[32mvoid	WriteData(const char* data, size_t length)				{ memcpy(p, data, length); p += length; }[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mvoid*	BeginWriteType()										{ void* returnValue = p; p++; return returnValue; }[m[41m[m
[32m+[m	[32mvoid	CommitType(void* beginPoint, BsonType value)			{ *reinterpret_cast<unsigned char*>(beginPoint) = value; }[m[41m[m
[32m+[m	[32mvoid*	BeginWriteSize()										{ void* returnValue = p; p += 4; return returnValue; }[m[41m[m
[32m+[m[41m[m
[32m+[m[32m#if USE_MISALIGNED_MEMORY_ACCESS[m[41m[m
[32m+[m	[32mvoid	CommitSize(void* beginPoint)							{ *reinterpret_cast<int32_t*>(beginPoint) = (int32_t) (p - (char*) beginPoint); }[m[41m[m
[32m+[m[32m#else[m[41m[m
[32m+[m	[32mvoid	CommitSize(void* beginPoint)							{ int32_t value = (int32_t) (p - (char*) beginPoint); memcpy(beginPoint, &value, 4); }[m[41m[m
[32m+[m[32m#endif[m[41m[m
[32m+[m[41m[m
[32m+[m	[32msize_t GetSerializeSize() const									{ return p - destinationBuffer; }[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mvoid	CheckKey(const Local<String>& keyName);[m[41m[m
[32m+[m[41m[m
[32m+[m[32mprotected:[m[41m[m
[32m+[m	[32mchar *const	destinationBuffer;		// base, never changes[m[41m[m
[32m+[m	[32mchar*		p;						// cursor into buffer[m[41m[m
[32m+[m[32m};[m[41m[m
[32m+[m[41m[m
[32m+[m[32mtemplate<typename T> class BSONSerializer : public T[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m[32mprivate:[m[41m[m
[32m+[m	[32mtypedef T Inherited;[m[41m[m
[32m+[m[41m[m
[32m+[m[32mpublic:[m[41m[m
[32m+[m	[32mBSONSerializer(BSON* aBson, bool aCheckKeys, bool aSerializeFunctions) : Inherited(), checkKeys(aCheckKeys), serializeFunctions(aSerializeFunctions), bson(aBson) { }[m[41m[m
[32m+[m	[32mBSONSerializer(BSON* aBson, bool aCheckKeys, bool aSerializeFunctions, char* parentParam) : Inherited(parentParam), checkKeys(aCheckKeys), serializeFunctions(aSerializeFunctions), bson(aBson) { }[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mvoid SerializeDocument(const Handle<Value>& value);[m[41m[m
[32m+[m	[32mvoid SerializeArray(const Handle<Value>& value);[m[41m[m
 	void SerializeValue(void* typeLocation, const Handle<Value> value);[m
[31m-[m
[31m-private:[m
[31m-	bool		checkKeys;[m
[31m-	bool		serializeFunctions;[m
[31m-	BSON*		bson;[m
[31m-};[m
[31m-[m
[31m-//===========================================================================[m
[31m-[m
[31m-class BSONDeserializer[m
[31m-{[m
[31m-public:[m
[31m-	BSONDeserializer(BSON* aBson, char* data, size_t length);[m
[31m-	BSONDeserializer(BSONDeserializer& parentSerializer, size_t length);[m
[31m-[m
[31m-	Handle<Value> DeserializeDocument(bool promoteLongs);[m
[31m-[m
[31m-	bool			HasMoreData() const { return p < pEnd; }[m
[31m-	Handle<Value>	ReadCString();[m
[31m-	uint32_t		ReadIntegerString();[m
[31m-	int32_t			ReadRegexOptions();[m
[31m-	Local<String>	ReadString();[m
[31m-	Local<String>	ReadObjectId();[m
[31m-[m
[31m-	unsigned char	ReadByte()			{ return *reinterpret_cast<unsigned char*>(p++); }[m
[31m-#if USE_MISALIGNED_MEMORY_ACCESS[m
[31m-	int32_t			ReadInt32()			{ int32_t returnValue = *reinterpret_cast<int32_t*>(p); p += 4; return returnValue; }[m
[31m-	uint32_t		ReadUInt32()		{ uint32_t returnValue = *reinterpret_cast<uint32_t*>(p); p += 4; return returnValue; }[m
[31m-	int64_t			ReadInt64()			{ int64_t returnValue = *reinterpret_cast<int64_t*>(p); p += 8; return returnValue; }[m
[31m-	double			ReadDouble()		{ double returnValue = *reinterpret_cast<double*>(p); p += 8; return returnValue; }[m
[31m-#else[m
[31m-	int32_t			ReadInt32()			{ int32_t returnValue; memcpy(&returnValue, p, 4); p += 4; return returnValue; }[m
[31m-	uint32_t		ReadUInt32()		{ uint32_t returnValue; memcpy(&returnValue, p, 4); p += 4; return returnValue; }[m
[31m-	int64_t			ReadInt64()			{ int64_t returnValue; memcpy(&returnValue, p, 8); p += 8; return returnValue; }[m
[31m-	double			ReadDouble()		{ double returnValue; memcpy(&returnValue, p, 8); p += 8; return returnValue; }[m
[31m-#endif[m
[31m-[m
[31m-	size_t			GetSerializeSize() const { return p - pStart; }[m
[31m-[m
[31m-private:[m
[31m-	Handle<Value> DeserializeArray(bool promoteLongs);[m
[31m-	Handle<Value> DeserializeValue(BsonType type, bool promoteLongs);[m
[31m-	Handle<Value> DeserializeDocumentInternal(bool promoteLongs);[m
[31m-	Handle<Value> DeserializeArrayInternal(bool promoteLongs);[m
[31m-[m
[31m-	BSON*		bson;[m
[31m-	char* const pStart;[m
[31m-	char*		p;[m
[31m-	char* const	pEnd;[m
[31m-};[m
[31m-[m
[31m-//===========================================================================[m
[31m-[m
[31m-#endif  // BSON_H_[m
[31m-[m
[31m-//===========================================================================[m
[32m+[m[41m[m
[32m+[m[32mprivate:[m[41m[m
[32m+[m	[32mbool		checkKeys;[m[41m[m
[32m+[m	[32mbool		serializeFunctions;[m[41m[m
[32m+[m	[32mBSON*		bson;[m[41m[m
[32m+[m[32m};[m[41m[m
[32m+[m[41m[m
[32m+[m[32m//===========================================================================[m[41m[m
[32m+[m[41m[m
[32m+[m[32mclass BSONDeserializer[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m[32mpublic:[m[41m[m
[32m+[m	[32mBSONDeserializer(BSON* aBson, char* data, size_t length);[m[41m[m
[32m+[m	[32mBSONDeserializer(BSONDeserializer& parentSerializer, size_t length);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mHandle<Value> DeserializeDocument(bool promoteLongs);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mbool			HasMoreData() const { return p < pEnd; }[m[41m[m
[32m+[m	[32mHandle<Value>	ReadCString();[m[41m[m
[32m+[m	[32muint32_t		ReadIntegerString();[m[41m[m
[32m+[m	[32mint32_t			ReadRegexOptions();[m[41m[m
[32m+[m	[32mLocal<String>	ReadString();[m[41m[m
[32m+[m	[32mLocal<String>	ReadObjectId();[m[41m[m
[32m+[m[41m[m
[32m+[m	[32munsigned char	ReadByte()			{ return *reinterpret_cast<unsigned char*>(p++); }[m[41m[m
[32m+[m[32m#if USE_MISALIGNED_MEMORY_ACCESS[m[41m[m
[32m+[m	[32mint32_t			ReadInt32()			{ int32_t returnValue = *reinterpret_cast<int32_t*>(p); p += 4; return returnValue; }[m[41m[m
[32m+[m	[32muint32_t		ReadUInt32()		{ uint32_t returnValue = *reinterpret_cast<uint32_t*>(p); p += 4; return returnValue; }[m[41m[m
[32m+[m	[32mint64_t			ReadInt64()			{ int64_t returnValue = *reinterpret_cast<int64_t*>(p); p += 8; return returnValue; }[m[41m[m
[32m+[m	[32mdouble			ReadDouble()		{ double returnValue = *reinterpret_cast<double*>(p); p += 8; return returnValue; }[m[41m[m
[32m+[m[32m#else[m[41m[m
[32m+[m	[32mint32_t			ReadInt32()			{ int32_t returnValue; memcpy(&returnValue, p, 4); p += 4; return returnValue; }[m[41m[m
[32m+[m	[32muint32_t		ReadUInt32()		{ uint32_t returnValue; memcpy(&returnValue, p, 4); p += 4; return returnValue; }[m[41m[m
[32m+[m	[32mint64_t			ReadInt64()			{ int64_t returnValue; memcpy(&returnValue, p, 8); p += 8; return returnValue; }[m[41m[m
[32m+[m	[32mdouble			ReadDouble()		{ double returnValue; memcpy(&returnValue, p, 8); p += 8; return returnValue; }[m[41m[m
[32m+[m[32m#endif[m[41m[m
[32m+[m[41m[m
[32m+[m	[32msize_t			GetSerializeSize() const { return p - pStart; }[m[41m[m
[32m+[m[41m[m
[32m+[m[32mprivate:[m[41m[m
[32m+[m	[32mHandle<Value> DeserializeArray(bool promoteLongs);[m[41m[m
[32m+[m	[32mHandle<Value> DeserializeValue(BsonType type, bool promoteLongs);[m[41m[m
[32m+[m	[32mHandle<Value> DeserializeDocumentInternal(bool promoteLongs);[m[41m[m
[32m+[m	[32mHandle<Value> DeserializeArrayInternal(bool promoteLongs);[m[41m[m
[32m+[m[41m[m
[32m+[m	[32mBSON*		bson;[m[41m[m
[32m+[m	[32mchar* const pStart;[m[41m[m
[32m+[m	[32mchar*		p;[m[41m[m
[32m+[m	[32mchar* const	pEnd;[m[41m[m
[32m+[m[32m};[m[41m[m
[32m+[m[41m[m
[32m+[m[32m//===========================================================================[m[41m[m
[32m+[m[41m[m
[32m+[m[32m#endif  // BSON_H_[m[41m[m
[32m+[m[41m[m
[32m+[m[32m//===========================================================================[m[41m[m
[1mdiff --git a/node_modules/mongodb/node_modules/bson/package.json b/node_modules/mongodb/node_modules/bson/package.json[m
[1mindex 18e2258..0fac269 100644[m
[1m--- a/node_modules/mongodb/node_modules/bson/package.json[m
[1m+++ b/node_modules/mongodb/node_modules/bson/package.json[m
[36m@@ -1,83 +1,64 @@[m
 {[m
[31m-  "_args": [[m
[31m-    [[m
[31m-      "bson@~0.2",[m
[31m-      "C:\\Users\\Silken\\node\\IDE-A\\node_modules\\mongodb"[m
[31m-    ][m
[31m-  ],[m
[31m-  "_from": "bson@>=0.2.0 <0.3.0",[m
[31m-  "_id": "bson@0.2.22",[m
[31m-  "_inCache": true,[m
[31m-  "_location": "/mongodb/bson",[m
[31m-  "_nodeVersion": "2.3.3",[m
[31m-  "_npmUser": {[m
[31m-    "email": "christkv@gmail.com",[m
[31m-    "name": "christkv"[m
[31m-  },[m
[31m-  "_npmVersion": "2.11.3",[m
[31m-  "_phantomChildren": {},[m
[31m-  "_requested": {[m
[31m-    "name": "bson",[m
[31m-    "raw": "bson@~0.2",[m
[31m-    "rawSpec": "~0.2",[m
[31m-    "scope": null,[m
[31m-    "spec": ">=0.2.0 <0.3.0",[m
[31m-    "type": "range"[m
[31m-  },[m
[31m-  "_requiredBy": [[m
[31m-    "/mongodb"[m
[32m+[m[32m  "name": "bson",[m
[32m+[m[32m  "description": "A bson parser for node.js and the browser",[m
[32m+[m[32m  "keywords": [[m
[32m+[m[32m    "mongodb",[m
[32m+[m[32m    "bson",[m
[32m+[m[32m    "parser"[m
   ],[m
[31m-  "_resolved": "https://registry.npmjs.org/bson/-/bson-0.2.22.tgz",[m
[31m-  "_shasum": "fcda103f26d0c074d5a52d50927db80fd02b4b39",[m
[31m-  "_shrinkwrap": null,[m
[31m-  "_spec": "bson@~0.2",[m
[31m-  "_where": "C:\\Users\\Silken\\node\\IDE-A\\node_modules\\mongodb",[m
[32m+[m[32m  "version": "0.2.22",[m
   "author": {[m
[31m-    "email": "christkv@gmail.com",[m
[31m-    "name": "Christian Amor Kvalheim"[m
[32m+[m[32m    "name": "Christian Amor Kvalheim",[m
[32m+[m[32m    "email": "christkv@gmail.com"[m
[32m+[m[32m  },[m
[32m+[m[32m  "contributors": [],[m
[32m+[m[32m  "repository": {[m
[32m+[m[32m    "type": "git",[m
[32m+[m[32m    "url": "git://github.com/mongodb/js-bson.git"[m
   },[m
[31m-  "browser": "lib/bson/bson.js",[m
   "bugs": {[m
     "url": "https://github.com/mongodb/js-bson/issues"[m
   },[m
[31m-  "config": {[m
[31m-    "native": false[m
[31m-  },[m
[31m-  "contributors": [],[m
   "dependencies": {[m
     "nan": "~1.8"[m
   },[m
[31m-  "description": "A bson parser for node.js and the browser",[m
   "devDependencies": {[m
[31m-    "gleak": "0.2.3",[m
     "nodeunit": "0.9.0",[m
[32m+[m[32m    "gleak": "0.2.3",[m
     "one": "2.X.X"[m
   },[m
[32m+[m[32m  "config": {[m
[32m+[m[32m    "native": false[m
[32m+[m[32m  },[m
[32m+[m[32m  "main": "./lib/bson/index",[m
   "directories": {[m
     "lib": "./lib/bson"[m
   },[m
[31m-  "dist": {[m
[31m-    "shasum": "fcda103f26d0c074d5a52d50927db80fd02b4b39",[m
[31m-    "tarball": "http://registry.npmjs.org/bson/-/bson-0.2.22.tgz"[m
[31m-  },[m
   "engines": {[m
     "node": ">=0.6.19"[m
   },[m
[31m-  "gitHead": "34dd32f6a8dc71943be7129c60826b6e0d005a71",[m
[31m-  "homepage": "https://github.com/mongodb/js-bson",[m
[31m-  "installable": true,[m
[31m-  "keywords": [[m
[31m-    "bson",[m
[31m-    "mongodb",[m
[31m-    "parser"[m
[31m-  ],[m
[32m+[m[32m  "scripts": {[m
[32m+[m[32m    "install": "(node-gyp rebuild 2> builderror.log) || (exit 0)",[m
[32m+[m[32m    "test": "nodeunit ./test/node && TEST_NATIVE=TRUE nodeunit ./test/node"[m
[32m+[m[32m  },[m
[32m+[m[32m  "browser": "lib/bson/bson.js",[m
   "licenses": [[m
     {[m
       "type": "Apache License, Version 2.0",[m
       "url": "http://www.apache.org/licenses/LICENSE-2.0"[m
     }[m
   ],[m
[31m-  "main": "./lib/bson/index",[m
[32m+[m[32m  "gitHead": "34dd32f6a8dc71943be7129c60826b6e0d005a71",[m
[32m+[m[32m  "homepage": "https://github.com/mongodb/js-bson",[m
[32m+[m[32m  "_id": "bson@0.2.22",[m
[32m+[m[32m  "_shasum": "fcda103f26d0c074d5a52d50927db80fd02b4b39",[m
[32m+[m[32m  "_from": "bson@>=0.2.0 <0.3.0",[m
[32m+[m[32m  "_npmVersion": "2.11.3",[m
[32m+[m[32m  "_nodeVersion": "2.3.3",[m
[32m+[m[32m  "_npmUser": {[m
[32m+[m[32m    "name": "christkv",[m
[32m+[m[32m    "email": "christkv@gmail.com"[m
[32m+[m[32m  },[m
   "maintainers": [[m
     {[m
       "name": "octave",[m
[36m@@ -88,15 +69,10 @@[m
       "email": "christkv@gmail.com"[m
     }[m
   ],[m
[31m-  "name": "bson",[m
[31m-  "optionalDependencies": {},[m
[31m-  "repository": {[m
[31m-    "type": "git",[m
[31m-    "url": "git://github.com/mongodb/js-bson.git"[m
[31m-  },[m
[31m-  "scripts": {[m
[31m-    "install": "(node-gyp rebuild 2> builderror.log) || (exit 0)",[m
[31m-    "test": "nodeunit ./test/node && TEST_NATIVE=TRUE nodeunit ./test/node"[m
[32m+[m[32m  "dist": {[m
[32m+[m[32m    "shasum": "fcda103f26d0c074d5a52d50927db80fd02b4b39",[m
[32m+[m[32m    "tarball": "http://registry.npmjs.org/bson/-/bson-0.2.22.tgz"[m
   },[m
[31m-  "version": "0.2.22"[m
[32m+[m[32m  "_resolved": "https://registry.npmjs.org/bson/-/bson-0.2.22.tgz",[m
[32m+[m[32m  "readme": "ERROR: No README data found!"[m
 }[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/.npmignore b/node_modules/mongodb/node_modules/readable-stream/.npmignore[m
[1mdeleted file mode 100644[m
[1mindex 38344f8..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/.npmignore[m
[1m+++ /dev/null[m
[36m@@ -1,5 +0,0 @@[m
[31m-build/[m
[31m-test/[m
[31m-examples/[m
[31m-fs.js[m
[31m-zlib.js[m
\ No newline at end of file[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/.travis.yml b/node_modules/mongodb/node_modules/readable-stream/.travis.yml[m
[1mdeleted file mode 100644[m
[1mindex cfe1c94..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/.travis.yml[m
[1m+++ /dev/null[m
[36m@@ -1,50 +0,0 @@[m
[31m-sudo: false[m
[31m-language: node_js[m
[31m-before_install:[m
[31m-  - npm install -g npm@2[m
[31m-  - npm install -g npm[m
[31m-notifications:[m
[31m-  email: false[m
[31m-matrix:[m
[31m-  include:[m
[31m-  - node_js: '0.8'[m
[31m-    env: TASK=test[m
[31m-  - node_js: '0.10'[m
[31m-    env: TASK=test[m
[31m-  - node_js: '0.11'[m
[31m-    env: TASK=test[m
[31m-  - node_js: '0.12'[m
[31m-    env: TASK=test[m
[31m-  - node_js: 1[m
[31m-    env: TASK=test[m
[31m-  - node_js: 2[m
[31m-    env: TASK=test[m
[31m-  - node_js: 3[m
[31m-    env: TASK=test[m
[31m-  - node_js: 4[m
[31m-    env: TASK=test[m
[31m-  - node_js: 5[m
[31m-    env: TASK=test[m
[31m-  - node_js: node[m
[31m-    env: TASK=test[m
[31m-  - node_js: node[m
[31m-    env: TASK=browser BROWSER_NAME=opera BROWSER_VERSION="11..latest"[m
[31m-  - node_js: node[m
[31m-    env: TASK=browser BROWSER_NAME=ie BROWSER_VERSION="9..latest"[m
[31m-  - node_js: node[m
[31m-    env: TASK=browser BROWSER_NAME=chrome BROWSER_VERSION="41..beta"[m
[31m-  - node_js: node[m
[31m-    env: TASK=browser BROWSER_NAME=firefox BROWSER_VERSION="36..latest"[m
[31m-  - node_js: node[m
[31m-    env: TASK=browser BROWSER_NAME=ipad BROWSER_VERSION="['6.1', '7.1', '8.2']"[m
[31m-  - node_js: node[m
[31m-    env: TASK=browser BROWSER_NAME=iphone BROWSER_VERSION="['6.1', '7.1', '8.2']"[m
[31m-  - node_js: node[m
[31m-    env: TASK=browser BROWSER_NAME=safari BROWSER_VERSION="5..latest"[m
[31m-  - node_js: node[m
[31m-    env: TASK=browser BROWSER_NAME=android BROWSER_VERSION="4.0..latest"[m
[31m-script: "npm run $TASK"[m
[31m-env:[m
[31m-  global:[m
[31m-  - secure: rE2Vvo7vnjabYNULNyLFxOyt98BoJexDqsiOnfiD6kLYYsiQGfr/sbZkPMOFm9qfQG7pjqx+zZWZjGSswhTt+626C0t/njXqug7Yps4c3dFblzGfreQHp7wNX5TFsvrxd6dAowVasMp61sJcRnB2w8cUzoe3RAYUDHyiHktwqMc=[m
[31m-  - secure: g9YINaKAdMatsJ28G9jCGbSaguXCyxSTy+pBO6Ch0Cf57ZLOTka3HqDj8p3nV28LUIHZ3ut5WO43CeYKwt4AUtLpBS3a0dndHdY6D83uY6b2qh5hXlrcbeQTq2cvw2y95F7hm4D1kwrgZ7ViqaKggRcEupAL69YbJnxeUDKWEdI=[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/.zuul.yml b/node_modules/mongodb/node_modules/readable-stream/.zuul.yml[m
[1mdeleted file mode 100644[m
[1mindex 96d9cfb..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/.zuul.yml[m
[1m+++ /dev/null[m
[36m@@ -1 +0,0 @@[m
[31m-ui: tape[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/LICENSE b/node_modules/mongodb/node_modules/readable-stream/LICENSE[m
[1mdeleted file mode 100644[m
[1mindex e3d4e69..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/LICENSE[m
[1m+++ /dev/null[m
[36m@@ -1,18 +0,0 @@[m
[31m-Copyright Joyent, Inc. and other Node contributors. All rights reserved.[m
[31m-Permission is hereby granted, free of charge, to any person obtaining a copy[m
[31m-of this software and associated documentation files (the "Software"), to[m
[31m-deal in the Software without restriction, including without limitation the[m
[31m-rights to use, copy, modify, merge, publish, distribute, sublicense, and/or[m
[31m-sell copies of the Software, and to permit persons to whom the Software is[m
[31m-furnished to do so, subject to the following conditions:[m
[31m-[m
[31m-The above copyright notice and this permission notice shall be included in[m
[31m-all copies or substantial portions of the Software.[m
[31m-[m
[31m-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR[m
[31m-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,[m
[31m-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE[m
[31m-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER[m
[31m-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING[m
[31m-FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS[m
[31m-IN THE SOFTWARE.[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/README.md b/node_modules/mongodb/node_modules/readable-stream/README.md[m
[1mdeleted file mode 100644[m
[1mindex f9fb520..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/README.md[m
[1m+++ /dev/null[m
[36m@@ -1,36 +0,0 @@[m
[31m-# readable-stream[m
[31m-[m
[31m-***Node-core streams for userland*** [![Build Status](https://travis-ci.org/nodejs/readable-stream.svg?branch=master)](https://travis-ci.org/nodejs/readable-stream)[m
[31m-[m
[31m-[m
[31m-[![NPM](https://nodei.co/npm/readable-stream.png?downloads=true&downloadRank=true)](https://nodei.co/npm/readable-stream/)[m
[31m-[![NPM](https://nodei.co/npm-dl/readable-stream.png?&months=6&height=3)](https://nodei.co/npm/readable-stream/)[m
[31m-[m
[31m-[m
[31m-[![Sauce Test Status](https://saucelabs.com/browser-matrix/readable-stream.svg)](https://saucelabs.com/u/readable-stream)[m
[31m-[m
[31m-```bash[m
[31m-npm install --save readable-stream[m
[31m-```[m
[31m-[m
[31m-***Node-core streams for userland***[m
[31m-[m
[31m-This package is a mirror of the Streams2 and Streams3 implementations in[m
[31m-Node-core, including [documentation](doc/stream.markdown).[m
[31m-[m
[31m-If you want to guarantee a stable streams base, regardless of what version of[m
[31m-Node you, or the users of your libraries are using, use **readable-stream** *only* and avoid the *"stream"* module in Node-core, for background see [this blogpost](http://r.va.gg/2014/06/why-i-dont-use-nodes-core-stream-module.html).[m
[31m-[m
[31m-As of version 2.0.0 **readable-stream** uses semantic versioning.  [m
[31m-[m
[31m-# Streams WG Team Members[m
[31m-[m
[31m-* **Chris Dickinson** ([@chrisdickinson](https://github.com/chrisdickinson)) &lt;christopher.s.dickinson@gmail.com&gt;[m
[31m-  - Release GPG key: 9554F04D7259F04124DE6B476D5A82AC7E37093B[m
[31m-* **Calvin Metcalf** ([@calvinmetcalf](https://github.com/calvinmetcalf)) &lt;calvin.metcalf@gmail.com&gt;[m
[31m-  - Release GPG key: F3EF5F62A87FC27A22E643F714CE4FF5015AA242[m
[31m-* **Rod Vagg** ([@rvagg](https://github.com/rvagg)) &lt;rod@vagg.org&gt;[m
[31m-  - Release GPG key: DD8F2338BAE7501E3DD5AC78C273792F7D83545D[m
[31m-* **Sam Newman** ([@sonewman](https://github.com/sonewman)) &lt;newmansam@outlook.com&gt;[m
[31m-* **Mathias Buus** ([@mafintosh](https://github.com/mafintosh)) &lt;mathiasbuus@gmail.com&gt;[m
[31m-* **Domenic Denicola** ([@domenic](https://github.com/domenic)) &lt;d@domenic.me&gt;[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/doc/stream.markdown b/node_modules/mongodb/node_modules/readable-stream/doc/stream.markdown[m
[1mdeleted file mode 100644[m
[1mindex f84543a..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/doc/stream.markdown[m
[1m+++ /dev/null[m
[36m@@ -1,1696 +0,0 @@[m
[31m-# Stream[m
[31m-[m
[31m-    Stability: 2 - Stable[m
[31m-[m
[31m-A stream is an abstract interface implemented by various objects in[m
[31m-Node.js.  For example a [request to an HTTP[m
[31m-server](https://iojs.org/dist/v5.0.0/doc/api/http.html#http_http_incomingmessage) is a stream, as is[m
[31m-[stdout][]. Streams are readable, writable, or both. All streams are[m
[31m-instances of [EventEmitter][][m
[31m-[m
[31m-You can load the Stream base classes by doing `require('stream')`.[m
[31m-There are base classes provided for [Readable][] streams, [Writable][][m
[31m-streams, [Duplex][] streams, and [Transform][] streams.[m
[31m-[m
[31m-This document is split up into 3 sections.  The first explains the[m
[31m-parts of the API that you need to be aware of to use streams in your[m
[31m-programs.  If you never implement a streaming API yourself, you can[m
[31m-stop there.[m
[31m-[m
[31m-The second section explains the parts of the API that you need to use[m
[31m-if you implement your own custom streams yourself.  The API is[m
[31m-designed to make this easy for you to do.[m
[31m-[m
[31m-The third section goes into more depth about how streams work,[m
[31m-including some of the internal mechanisms and functions that you[m
[31m-should probably not modify unless you definitely know what you are[m
[31m-doing.[m
[31m-[m
[31m-[m
[31m-## API for Stream Consumers[m
[31m-[m
[31m-<!--type=misc-->[m
[31m-[m
[31m-Streams can be either [Readable][], [Writable][], or both ([Duplex][]).[m
[31m-[m
[31m-All streams are EventEmitters, but they also have other custom methods[m
[31m-and properties depending on whether they are Readable, Writable, or[m
[31m-Duplex.[m
[31m-[m
[31m-If a stream is both Readable and Writable, then it implements all of[m
[31m-the methods and events below.  So, a [Duplex][] or [Transform][] stream is[m
[31m-fully described by this API, though their implementation may be[m
[31m-somewhat different.[m
[31m-[m
[31m-It is not necessary to implement Stream interfaces in order to consume[m
[31m-streams in your programs.  If you **are** implementing streaming[m
[31m-interfaces in your own program, please also refer to[m
[31m-[API for Stream Implementors][] below.[m
[31m-[m
[31m-Almost all Node.js programs, no matter how simple, use Streams in some[m
[31m-way. Here is an example of using Streams in an Node.js program:[m
[31m-[m
[31m-```javascript[m
[31m-var http = require('http');[m
[31m-[m
[31m-var server = http.createServer(function (req, res) {[m
[31m-  // req is an http.IncomingMessage, which is a Readable Stream[m
[31m-  // res is an http.ServerResponse, which is a Writable Stream[m
[31m-[m
[31m-  var body = '';[m
[31m-  // we want to get the data as utf8 strings[m
[31m-  // If you don't set an encoding, then you'll get Buffer objects[m
[31m-  req.setEncoding('utf8');[m
[31m-[m
[31m-  // Readable streams emit 'data' events once a listener is added[m
[31m-  req.on('data', function (chunk) {[m
[31m-    body += chunk;[m
[31m-  });[m
[31m-[m
[31m-  // the end event tells you that you have entire body[m
[31m-  req.on('end', function () {[m
[31m-    try {[m
[31m-      var data = JSON.parse(body);[m
[31m-    } catch (er) {[m
[31m-      // uh oh!  bad json![m
[31m-      res.statusCode = 400;[m
[31m-      return res.end('error: ' + er.message);[m
[31m-    }[m
[31m-[m
[31m-    // write back something interesting to the user:[m
[31m-    res.write(typeof data);[m
[31m-    res.end();[m
[31m-  });[m
[31m-});[m
[31m-[m
[31m-server.listen(1337);[m
[31m-[m
[31m-// $ curl localhost:1337 -d '{}'[m
[31m-// object[m
[31m-// $ curl localhost:1337 -d '"foo"'[m
[31m-// string[m
[31m-// $ curl localhost:1337 -d 'not json'[m
[31m-// error: Unexpected token o[m
[31m-```[m
[31m-[m
[31m-### Class: stream.Readable[m
[31m-[m
[31m-<!--type=class-->[m
[31m-[m
[31m-The Readable stream interface is the abstraction for a *source* of[m
[31m-data that you are reading from.  In other words, data comes *out* of a[m
[31m-Readable stream.[m
[31m-[m
[31m-A Readable stream will not start emitting data until you indicate that[m
[31m-you are ready to receive it.[m
[31m-[m
[31m-Readable streams have two "modes": a **flowing mode** and a **paused[m
[31m-mode**.  When in flowing mode, data is read from the underlying system[m
[31m-and provided to your program as fast as possible.  In paused mode, you[m
[31m-must explicitly call `stream.read()` to get chunks of data out.[m
[31m-Streams start out in paused mode.[m
[31m-[m
[31m-**Note**: If no data event handlers are attached, and there are no[m
[31m-[`pipe()`][] destinations, and the stream is switched into flowing[m
[31m-mode, then data will be lost.[m
[31m-[m
[31m-You can switch to flowing mode by doing any of the following:[m
[31m-[m
[31m-* Adding a [`'data'` event][] handler to listen for data.[m
[31m-* Calling the [`resume()`][] method to explicitly open the flow.[m
[31m-* Calling the [`pipe()`][] method to send the data to a [Writable][].[m
[31m-[m
[31m-You can switch back to paused mode by doing either of the following:[m
[31m-[m
[31m-* If there are no pipe destinations, by calling the [`pause()`][][m
[31m-  method.[m
[31m-* If there are pipe destinations, by removing any [`'data'` event][][m
[31m-  handlers, and removing all pipe destinations by calling the[m
[31m-  [`unpipe()`][] method.[m
[31m-[m
[31m-Note that, for backwards compatibility reasons, removing `'data'`[m
[31m-event handlers will **not** automatically pause the stream.  Also, if[m
[31m-there are piped destinations, then calling `pause()` will not[m
[31m-guarantee that the stream will *remain* paused once those[m
[31m-destinations drain and ask for more data.[m
[31m-[m
[31m-Examples of readable streams include:[m
[31m-[m
[31m-* [http responses, on the client](https://iojs.org/dist/v5.0.0/doc/api/http.html#http_http_incomingmessage)[m
[31m-* [http requests, on the server](https://iojs.org/dist/v5.0.0/doc/api/http.html#http_http_incomingmessage)[m
[31m-* [fs read streams](https://iojs.org/dist/v5.0.0/doc/api/fs.html#fs_class_fs_readstream)[m
[31m-* [zlib streams][][m
[31m-* [crypto streams][][m
[31m-* [tcp sockets][][m
[31m-* [child process stdout and stderr][][m
[31m-* [process.stdin][][m
[31m-[m
[31m-#### Event: 'readable'[m
[31m-[m
[31m-When a chunk of data can be read from the stream, it will emit a[m
[31m-`'readable'` event.[m
[31m-[m
[31m-In some cases, listening for a `'readable'` event will cause some data[m
[31m-to be read into the internal buffer from the underlying system, if it[m
[31m-hadn't already.[m
[31m-[m
[31m-```javascript[m
[31m-var readable = getReadableStreamSomehow();[m
[31m-readable.on('readable', function() {[m
[31m-  // there is some data to read now[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-Once the internal buffer is drained, a `readable` event will fire[m
[31m-again when more data is available.[m
[31m-[m
[31m-The `readable` event is not emitted in the "flowing" mode with the[m
[31m-sole exception of the last one, on end-of-stream.[m
[31m-[m
[31m-The 'readable' event indicates that the stream has new information:[m
[31m-either new data is available or the end of the stream has been reached.[m
[31m-In the former case, `.read()` will return that data. In the latter case,[m
[31m-`.read()` will return null. For instance, in the following example, `foo.txt`[m
[31m-is an empty file:[m
[31m-[m
[31m-```javascript[m
[31m-var fs = require('fs');[m
[31m-var rr = fs.createReadStream('foo.txt');[m
[31m-rr.on('readable', function() {[m
[31m-  console.log('readable:', rr.read());[m
[31m-});[m
[31m-rr.on('end', function() {[m
[31m-  console.log('end');[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-The output of running this script is:[m
[31m-[m
[31m-```[m
[31m-bash-3.2$ node test.js[m
[31m-readable: null[m
[31m-end[m
[31m-```[m
[31m-[m
[31m-#### Event: 'data'[m
[31m-[m
[31m-* `chunk` {Buffer | String} The chunk of data.[m
[31m-[m
[31m-Attaching a `data` event listener to a stream that has not been[m
[31m-explicitly paused will switch the stream into flowing mode. Data will[m
[31m-then be passed as soon as it is available.[m
[31m-[m
[31m-If you just want to get all the data out of the stream as fast as[m
[31m-possible, this is the best way to do so.[m
[31m-[m
[31m-```javascript[m
[31m-var readable = getReadableStreamSomehow();[m
[31m-readable.on('data', function(chunk) {[m
[31m-  console.log('got %d bytes of data', chunk.length);[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-#### Event: 'end'[m
[31m-[m
[31m-This event fires when there will be no more data to read.[m
[31m-[m
[31m-Note that the `end` event **will not fire** unless the data is[m
[31m-completely consumed.  This can be done by switching into flowing mode,[m
[31m-or by calling `read()` repeatedly until you get to the end.[m
[31m-[m
[31m-```javascript[m
[31m-var readable = getReadableStreamSomehow();[m
[31m-readable.on('data', function(chunk) {[m
[31m-  console.log('got %d bytes of data', chunk.length);[m
[31m-});[m
[31m-readable.on('end', function() {[m
[31m-  console.log('there will be no more data.');[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-#### Event: 'close'[m
[31m-[m
[31m-Emitted when the stream and any of its underlying resources (a file[m
[31m-descriptor, for example) have been closed. The event indicates that[m
[31m-no more events will be emitted, and no further computation will occur.[m
[31m-[m
[31m-Not all streams will emit the 'close' event.[m
[31m-[m
[31m-#### Event: 'error'[m
[31m-[m
[31m-* {Error Object}[m
[31m-[m
[31m-Emitted if there was an error receiving data.[m
[31m-[m
[31m-#### readable.read([size])[m
[31m-[m
[31m-* `size` {Number} Optional argument to specify how much data to read.[m
[31m-* Return {String | Buffer | null}[m
[31m-[m
[31m-The `read()` method pulls some data out of the internal buffer and[m
[31m-returns it.  If there is no data available, then it will return[m
[31m-`null`.[m
[31m-[m
[31m-If you pass in a `size` argument, then it will return that many[m
[31m-bytes.  If `size` bytes are not available, then it will return `null`,[m
[31m-unless we've ended, in which case it will return the data remaining[m
[31m-in the buffer.[m
[31m-[m
[31m-If you do not specify a `size` argument, then it will return all the[m
[31m-data in the internal buffer.[m
[31m-[m
[31m-This method should only be called in paused mode.  In flowing mode,[m
[31m-this method is called automatically until the internal buffer is[m
[31m-drained.[m
[31m-[m
[31m-```javascript[m
[31m-var readable = getReadableStreamSomehow();[m
[31m-readable.on('readable', function() {[m
[31m-  var chunk;[m
[31m-  while (null !== (chunk = readable.read())) {[m
[31m-    console.log('got %d bytes of data', chunk.length);[m
[31m-  }[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-If this method returns a data chunk, then it will also trigger the[m
[31m-emission of a [`'data'` event][].[m
[31m-[m
[31m-Note that calling `readable.read([size])` after the `end` event has been[m
[31m-triggered will return `null`. No runtime error will be raised.[m
[31m-[m
[31m-#### readable.setEncoding(encoding)[m
[31m-[m
[31m-* `encoding` {String} The encoding to use.[m
[31m-* Return: `this`[m
[31m-[m
[31m-Call this function to cause the stream to return strings of the[m
[31m-specified encoding instead of Buffer objects.  For example, if you do[m
[31m-`readable.setEncoding('utf8')`, then the output data will be[m
[31m-interpreted as UTF-8 data, and returned as strings.  If you do[m
[31m-`readable.setEncoding('hex')`, then the data will be encoded in[m
[31m-hexadecimal string format.[m
[31m-[m
[31m-This properly handles multi-byte characters that would otherwise be[m
[31m-potentially mangled if you simply pulled the Buffers directly and[m
[31m-called `buf.toString(encoding)` on them.  If you want to read the data[m
[31m-as strings, always use this method.[m
[31m-[m
[31m-```javascript[m
[31m-var readable = getReadableStreamSomehow();[m
[31m-readable.setEncoding('utf8');[m
[31m-readable.on('data', function(chunk) {[m
[31m-  assert.equal(typeof chunk, 'string');[m
[31m-  console.log('got %d characters of string data', chunk.length);[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-#### readable.resume()[m
[31m-[m
[31m-* Return: `this`[m
[31m-[m
[31m-This method will cause the readable stream to resume emitting `data`[m
[31m-events.[m
[31m-[m
[31m-This method will switch the stream into flowing mode.  If you do *not*[m
[31m-want to consume the data from a stream, but you *do* want to get to[m
[31m-its `end` event, you can call [`readable.resume()`][] to open the flow of[m
[31m-data.[m
[31m-[m
[31m-```javascript[m
[31m-var readable = getReadableStreamSomehow();[m
[31m-readable.resume();[m
[31m-readable.on('end', function() {[m
[31m-  console.log('got to the end, but did not read anything');[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-#### readable.pause()[m
[31m-[m
[31m-* Return: `this`[m
[31m-[m
[31m-This method will cause a stream in flowing mode to stop emitting[m
[31m-`data` events, switching out of flowing mode.  Any data that becomes[m
[31m-available will remain in the internal buffer.[m
[31m-[m
[31m-```javascript[m
[31m-var readable = getReadableStreamSomehow();[m
[31m-readable.on('data', function(chunk) {[m
[31m-  console.log('got %d bytes of data', chunk.length);[m
[31m-  readable.pause();[m
[31m-  console.log('there will be no more data for 1 second');[m
[31m-  setTimeout(function() {[m
[31m-    console.log('now data will start flowing again');[m
[31m-    readable.resume();[m
[31m-  }, 1000);[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-#### readable.isPaused()[m
[31m-[m
[31m-* Return: `Boolean`[m
[31m-[m
[31m-This method returns whether or not the `readable` has been **explicitly**[m
[31m-paused by client code (using `readable.pause()` without a corresponding[m
[31m-`readable.resume()`).[m
[31m-[m
[31m-```javascript[m
[31m-var readable = new stream.Readable[m
[31m-[m
[31m-readable.isPaused() // === false[m
[31m-readable.pause()[m
[31m-readable.isPaused() // === true[m
[31m-readable.resume()[m
[31m-readable.isPaused() // === false[m
[31m-```[m
[31m-[m
[31m-#### readable.pipe(destination[, options])[m
[31m-[m
[31m-* `destination` {[Writable][] Stream} The destination for writing data[m
[31m-* `options` {Object} Pipe options[m
[31m-  * `end` {Boolean} End the writer when the reader ends. Default = `true`[m
[31m-[m
[31m-This method pulls all the data out of a readable stream, and writes it[m
[31m-to the supplied destination, automatically managing the flow so that[m
[31m-the destination is not overwhelmed by a fast readable stream.[m
[31m-[m
[31m-Multiple destinations can be piped to safely.[m
[31m-[m
[31m-```javascript[m
[31m-var readable = getReadableStreamSomehow();[m
[31m-var writable = fs.createWriteStream('file.txt');[m
[31m-// All the data from readable goes into 'file.txt'[m
[31m-readable.pipe(writable);[m
[31m-```[m
[31m-[m
[31m-This function returns the destination stream, so you can set up pipe[m
[31m-chains like so:[m
[31m-[m
[31m-```javascript[m
[31m-var r = fs.createReadStream('file.txt');[m
[31m-var z = zlib.createGzip();[m
[31m-var w = fs.createWriteStream('file.txt.gz');[m
[31m-r.pipe(z).pipe(w);[m
[31m-```[m
[31m-[m
[31m-For example, emulating the Unix `cat` command:[m
[31m-[m
[31m-```javascript[m
[31m-process.stdin.pipe(process.stdout);[m
[31m-```[m
[31m-[m
[31m-By default [`end()`][] is called on the destination when the source stream[m
[31m-emits `end`, so that `destination` is no longer writable. Pass `{ end:[m
[31m-false }` as `options` to keep the destination stream open.[m
[31m-[m
[31m-This keeps `writer` open so that "Goodbye" can be written at the[m
[31m-end.[m
[31m-[m
[31m-```javascript[m
[31m-reader.pipe(writer, { end: false });[m
[31m-reader.on('end', function() {[m
[31m-  writer.end('Goodbye\n');[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-Note that `process.stderr` and `process.stdout` are never closed until[m
[31m-the process exits, regardless of the specified options.[m
[31m-[m
[31m-#### readable.unpipe([destination])[m
[31m-[m
[31m-* `destination` {[Writable][] Stream} Optional specific stream to unpipe[m
[31m-[m
[31m-This method will remove the hooks set up for a previous `pipe()` call.[m
[31m-[m
[31m-If the destination is not specified, then all pipes are removed.[m
[31m-[m
[31m-If the destination is specified, but no pipe is set up for it, then[m
[31m-this is a no-op.[m
[31m-[m
[31m-```javascript[m
[31m-var readable = getReadableStreamSomehow();[m
[31m-var writable = fs.createWriteStream('file.txt');[m
[31m-// All the data from readable goes into 'file.txt',[m
[31m-// but only for the first second[m
[31m-readable.pipe(writable);[m
[31m-setTimeout(function() {[m
[31m-  console.log('stop writing to file.txt');[m
[31m-  readable.unpipe(writable);[m
[31m-  console.log('manually close the file stream');[m
[31m-  writable.end();[m
[31m-}, 1000);[m
[31m-```[m
[31m-[m
[31m-#### readable.unshift(chunk)[m
[31m-[m
[31m-* `chunk` {Buffer | String} Chunk of data to unshift onto the read queue[m
[31m-[m
[31m-This is useful in certain cases where a stream is being consumed by a[m
[31m-parser, which needs to "un-consume" some data that it has[m
[31m-optimistically pulled out of the source, so that the stream can be[m
[31m-passed on to some other party.[m
[31m-[m
[31m-Note that `stream.unshift(chunk)` cannot be called after the `end` event[m
[31m-has been triggered; a runtime error will be raised.[m
[31m-[m
[31m-If you find that you must often call `stream.unshift(chunk)` in your[m
[31m-programs, consider implementing a [Transform][] stream instead.  (See API[m
[31m-for Stream Implementors, below.)[m
[31m-[m
[31m-```javascript[m
[31m-// Pull off a header delimited by \n\n[m
[31m-// use unshift() if we get too much[m
[31m-// Call the callback with (error, header, stream)[m
[31m-var StringDecoder = require('string_decoder').StringDecoder;[m
[31m-function parseHeader(stream, callback) {[m
[31m-  stream.on('error', callback);[m
[31m-  stream.on('readable', onReadable);[m
[31m-  var decoder = new StringDecoder('utf8');[m
[31m-  var header = '';[m
[31m-  function onReadable() {[m
[31m-    var chunk;[m
[31m-    while (null !== (chunk = stream.read())) {[m
[31m-      var str = decoder.write(chunk);[m
[31m-      if (str.match(/\n\n/)) {[m
[31m-        // found the header boundary[m
[31m-        var split = str.split(/\n\n/);[m
[31m-        header += split.shift();[m
[31m-        var remaining = split.join('\n\n');[m
[31m-        var buf = new Buffer(remaining, 'utf8');[m
[31m-        if (buf.length)[m
[31m-          stream.unshift(buf);[m
[31m-        stream.removeListener('error', callback);[m
[31m-        stream.removeListener('readable', onReadable);[m
[31m-        // now the body of the message can be read from the stream.[m
[31m-        callback(null, header, stream);[m
[31m-      } else {[m
[31m-        // still reading the header.[m
[31m-        header += str;[m
[31m-      }[m
[31m-    }[m
[31m-  }[m
[31m-}[m
[31m-```[m
[31m-Note that, unlike `stream.push(chunk)`, `stream.unshift(chunk)` will not[m
[31m-end the reading process by resetting the internal reading state of the[m
[31m-stream. This can cause unexpected results if `unshift` is called during a[m
[31m-read (i.e. from within a `_read` implementation on a custom stream). Following[m
[31m-the call to `unshift` with an immediate `stream.push('')` will reset the[m
[31m-reading state appropriately, however it is best to simply avoid calling[m
[31m-`unshift` while in the process of performing a read.[m
[31m-[m
[31m-#### readable.wrap(stream)[m
[31m-[m
[31m-* `stream` {Stream} An "old style" readable stream[m
[31m-[m
[31m-Versions of Node.js prior to v0.10 had streams that did not implement the[m
[31m-entire Streams API as it is today.  (See "Compatibility" below for[m
[31m-more information.)[m
[31m-[m
[31m-If you are using an older Node.js library that emits `'data'` events and[m
[31m-has a [`pause()`][] method that is advisory only, then you can use the[m
[31m-`wrap()` method to create a [Readable][] stream that uses the old stream[m
[31m-as its data source.[m
[31m-[m
[31m-You will very rarely ever need to call this function, but it exists[m
[31m-as a convenience for interacting with old Node.js programs and libraries.[m
[31m-[m
[31m-For example:[m
[31m-[m
[31m-```javascript[m
[31m-var OldReader = require('./old-api-module.js').OldReader;[m
[31m-var oreader = new OldReader;[m
[31m-var Readable = require('stream').Readable;[m
[31m-var myReader = new Readable().wrap(oreader);[m
[31m-[m
[31m-myReader.on('readable', function() {[m
[31m-  myReader.read(); // etc.[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-[m
[31m-### Class: stream.Writable[m
[31m-[m
[31m-<!--type=class-->[m
[31m-[m
[31m-The Writable stream interface is an abstraction for a *destination*[m
[31m-that you are writing data *to*.[m
[31m-[m
[31m-Examples of writable streams include:[m
[31m-[m
[31m-* [http requests, on the client](https://iojs.org/dist/v5.0.0/doc/api/http.html#http_class_http_clientrequest)[m
[31m-* [http responses, on the server](https://iojs.org/dist/v5.0.0/doc/api/http.html#http_class_http_serverresponse)[m
[31m-* [fs write streams](https://iojs.org/dist/v5.0.0/doc/api/fs.html#fs_class_fs_writestream)[m
[31m-* [zlib streams][][m
[31m-* [crypto streams][][m
[31m-* [tcp sockets][][m
[31m-* [child process stdin](https://iojs.org/dist/v5.0.0/doc/api/child_process.html#child_process_child_stdin)[m
[31m-* [process.stdout][], [process.stderr][][m
[31m-[m
[31m-#### writable.write(chunk[, encoding][, callback])[m
[31m-[m
[31m-* `chunk` {String | Buffer} The data to write[m
[31m-* `encoding` {String} The encoding, if `chunk` is a String[m
[31m-* `callback` {Function} Callback for when this chunk of data is flushed[m
[31m-* Returns: {Boolean} True if the data was handled completely.[m
[31m-[m
[31m-This method writes some data to the underlying system, and calls the[m
[31m-supplied callback once the data has been fully handled.[m
[31m-[m
[31m-The return value indicates if you should continue writing right now.[m
[31m-If the data had to be buffered internally, then it will return[m
[31m-`false`.  Otherwise, it will return `true`.[m
[31m-[m
[31m-This return value is strictly advisory.  You MAY continue to write,[m
[31m-even if it returns `false`.  However, writes will be buffered in[m
[31m-memory, so it is best not to do this excessively.  Instead, wait for[m
[31m-the `drain` event before writing more data.[m
[31m-[m
[31m-#### Event: 'drain'[m
[31m-[m
[31m-If a [`writable.write(chunk)`][] call returns false, then the `drain`[m
[31m-event will indicate when it is appropriate to begin writing more data[m
[31m-to the stream.[m
[31m-[m
[31m-```javascript[m
[31m-// Write the data to the supplied writable stream one million times.[m
[31m-// Be attentive to back-pressure.[m
[31m-function writeOneMillionTimes(writer, data, encoding, callback) {[m
[31m-  var i = 1000000;[m
[31m-  write();[m
[31m-  function write() {[m
[31m-    var ok = true;[m
[31m-    do {[m
[31m-      i -= 1;[m
[31m-      if (i === 0) {[m
[31m-        // last time![m
[31m-        writer.write(data, encoding, callback);[m
[31m-      } else {[m
[31m-        // see if we should continue, or wait[m
[31m-        // don't pass the callback, because we're not done yet.[m
[31m-        ok = writer.write(data, encoding);[m
[31m-      }[m
[31m-    } while (i > 0 && ok);[m
[31m-    if (i > 0) {[m
[31m-      // had to stop early![m
[31m-      // write some more once it drains[m
[31m-      writer.once('drain', write);[m
[31m-    }[m
[31m-  }[m
[31m-}[m
[31m-```[m
[31m-[m
[31m-#### writable.cork()[m
[31m-[m
[31m-Forces buffering of all writes.[m
[31m-[m
[31m-Buffered data will be flushed either at `.uncork()` or at `.end()` call.[m
[31m-[m
[31m-#### writable.uncork()[m
[31m-[m
[31m-Flush all data, buffered since `.cork()` call.[m
[31m-[m
[31m-#### writable.setDefaultEncoding(encoding)[m
[31m-[m
[31m-* `encoding` {String} The new default encoding[m
[31m-[m
[31m-Sets the default encoding for a writable stream.[m
[31m-[m
[31m-#### writable.end([chunk][, encoding][, callback])[m
[31m-[m
[31m-* `chunk` {String | Buffer} Optional data to write[m
[31m-* `encoding` {String} The encoding, if `chunk` is a String[m
[31m-* `callback` {Function} Optional callback for when the stream is finished[m
[31m-[m
[31m-Call this method when no more data will be written to the stream.  If[m
[31m-supplied, the callback is attached as a listener on the `finish` event.[m
[31m-[m
[31m-Calling [`write()`][] after calling [`end()`][] will raise an error.[m
[31m-[m
[31m-```javascript[m
[31m-// write 'hello, ' and then end with 'world!'[m
[31m-var file = fs.createWriteStream('example.txt');[m
[31m-file.write('hello, ');[m
[31m-file.end('world!');[m
[31m-// writing more now is not allowed![m
[31m-```[m
[31m-[m
[31m-#### Event: 'finish'[m
[31m-[m
[31m-When the [`end()`][] method has been called, and all data has been flushed[m
[31m-to the underlying system, this event is emitted.[m
[31m-[m
[31m-```javascript[m
[31m-var writer = getWritableStreamSomehow();[m
[31m-for (var i = 0; i < 100; i ++) {[m
[31m-  writer.write('hello, #' + i + '!\n');[m
[31m-}[m
[31m-writer.end('this is the end\n');[m
[31m-writer.on('finish', function() {[m
[31m-  console.error('all writes are now complete.');[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-#### Event: 'pipe'[m
[31m-[m
[31m-* `src` {[Readable][] Stream} source stream that is piping to this writable[m
[31m-[m
[31m-This is emitted whenever the `pipe()` method is called on a readable[m
[31m-stream, adding this writable to its set of destinations.[m
[31m-[m
[31m-```javascript[m
[31m-var writer = getWritableStreamSomehow();[m
[31m-var reader = getReadableStreamSomehow();[m
[31m-writer.on('pipe', function(src) {[m
[31m-  console.error('something is piping into the writer');[m
[31m-  assert.equal(src, reader);[m
[31m-});[m
[31m-reader.pipe(writer);[m
[31m-```[m
[31m-[m
[31m-#### Event: 'unpipe'[m
[31m-[m
[31m-* `src` {[Readable][] Stream} The source stream that [unpiped][] this writable[m
[31m-[m
[31m-This is emitted whenever the [`unpipe()`][] method is called on a[m
[31m-readable stream, removing this writable from its set of destinations.[m
[31m-[m
[31m-```javascript[m
[31m-var writer = getWritableStreamSomehow();[m
[31m-var reader = getReadableStreamSomehow();[m
[31m-writer.on('unpipe', function(src) {[m
[31m-  console.error('something has stopped piping into the writer');[m
[31m-  assert.equal(src, reader);[m
[31m-});[m
[31m-reader.pipe(writer);[m
[31m-reader.unpipe(writer);[m
[31m-```[m
[31m-[m
[31m-#### Event: 'error'[m
[31m-[m
[31m-* {Error object}[m
[31m-[m
[31m-Emitted if there was an error when writing or piping data.[m
[31m-[m
[31m-### Class: stream.Duplex[m
[31m-[m
[31m-Duplex streams are streams that implement both the [Readable][] and[m
[31m-[Writable][] interfaces.  See above for usage.[m
[31m-[m
[31m-Examples of Duplex streams include:[m
[31m-[m
[31m-* [tcp sockets][][m
[31m-* [zlib streams][][m
[31m-* [crypto streams][][m
[31m-[m
[31m-[m
[31m-### Class: stream.Transform[m
[31m-[m
[31m-Transform streams are [Duplex][] streams where the output is in some way[m
[31m-computed from the input.  They implement both the [Readable][] and[m
[31m-[Writable][] interfaces.  See above for usage.[m
[31m-[m
[31m-Examples of Transform streams include:[m
[31m-[m
[31m-* [zlib streams][][m
[31m-* [crypto streams][][m
[31m-[m
[31m-[m
[31m-## API for Stream Implementors[m
[31m-[m
[31m-<!--type=misc-->[m
[31m-[m
[31m-To implement any sort of stream, the pattern is the same:[m
[31m-[m
[31m-1. Extend the appropriate parent class in your own subclass.  (The[m
[31m-   [`util.inherits`][] method is particularly helpful for this.)[m
[31m-2. Call the appropriate parent class constructor in your constructor,[m
[31m-   to be sure that the internal mechanisms are set up properly.[m
[31m-2. Implement one or more specific methods, as detailed below.[m
[31m-[m
[31m-The class to extend and the method(s) to implement depend on the sort[m
[31m-of stream class you are writing:[m
[31m-[m
[31m-<table>[m
[31m-  <thead>[m
[31m-    <tr>[m
[31m-      <th>[m
[31m-        <p>Use-case</p>[m
[31m-      </th>[m
[31m-      <th>[m
[31m-        <p>Class</p>[m
[31m-      </th>[m
[31m-      <th>[m
[31m-        <p>Method(s) to implement</p>[m
[31m-      </th>[m
[31m-    </tr>[m
[31m-  </thead>[m
[31m-  <tr>[m
[31m-    <td>[m
[31m-      <p>Reading only</p>[m
[31m-    </td>[m
[31m-    <td>[m
[31m-      <p>[Readable](#stream_class_stream_readable_1)</p>[m
[31m-    </td>[m
[31m-    <td>[m
[31m-      <p><code>[_read][]</code></p>[m
[31m-    </td>[m
[31m-  </tr>[m
[31m-  <tr>[m
[31m-    <td>[m
[31m-      <p>Writing only</p>[m
[31m-    </td>[m
[31m-    <td>[m
[31m-      <p>[Writable](#stream_class_stream_writable_1)</p>[m
[31m-    </td>[m
[31m-    <td>[m
[31m-      <p><code>[_write][]</code>, <code>_writev</code></p>[m
[31m-    </td>[m
[31m-  </tr>[m
[31m-  <tr>[m
[31m-    <td>[m
[31m-      <p>Reading and writing</p>[m
[31m-    </td>[m
[31m-    <td>[m
[31m-      <p>[Duplex](#stream_class_stream_duplex_1)</p>[m
[31m-    </td>[m
[31m-    <td>[m
[31m-      <p><code>[_read][]</code>, <code>[_write][]</code>, <code>_writev</code></p>[m
[31m-    </td>[m
[31m-  </tr>[m
[31m-  <tr>[m
[31m-    <td>[m
[31m-      <p>Operate on written data, then read the result</p>[m
[31m-    </td>[m
[31m-    <td>[m
[31m-      <p>[Transform](#stream_class_stream_transform_1)</p>[m
[31m-    </td>[m
[31m-    <td>[m
[31m-      <p><code>_transform</code>, <code>_flush</code></p>[m
[31m-    </td>[m
[31m-  </tr>[m
[31m-</table>[m
[31m-[m
[31m-In your implementation code, it is very important to never call the[m
[31m-methods described in [API for Stream Consumers][] above.  Otherwise, you[m
[31m-can potentially cause adverse side effects in programs that consume[m
[31m-your streaming interfaces.[m
[31m-[m
[31m-### Class: stream.Readable[m
[31m-[m
[31m-<!--type=class-->[m
[31m-[m
[31m-`stream.Readable` is an abstract class designed to be extended with an[m
[31m-underlying implementation of the [`_read(size)`][] method.[m
[31m-[m
[31m-Please see above under [API for Stream Consumers][] for how to consume[m
[31m-streams in your programs.  What follows is an explanation of how to[m
[31m-implement Readable streams in your programs.[m
[31m-[m
[31m-#### Example: A Counting Stream[m
[31m-[m
[31m-<!--type=example-->[m
[31m-[m
[31m-This is a basic example of a Readable stream.  It emits the numerals[m
[31m-from 1 to 1,000,000 in ascending order, and then ends.[m
[31m-[m
[31m-```javascript[m
[31m-var Readable = require('stream').Readable;[m
[31m-var util = require('util');[m
[31m-util.inherits(Counter, Readable);[m
[31m-[m
[31m-function Counter(opt) {[m
[31m-  Readable.call(this, opt);[m
[31m-  this._max = 1000000;[m
[31m-  this._index = 1;[m
[31m-}[m
[31m-[m
[31m-Counter.prototype._read = function() {[m
[31m-  var i = this._index++;[m
[31m-  if (i > this._max)[m
[31m-    this.push(null);[m
[31m-  else {[m
[31m-    var str = '' + i;[m
[31m-    var buf = new Buffer(str, 'ascii');[m
[31m-    this.push(buf);[m
[31m-  }[m
[31m-};[m
[31m-```[m
[31m-[m
[31m-#### Example: SimpleProtocol v1 (Sub-optimal)[m
[31m-[m
[31m-This is similar to the `parseHeader` function described above, but[m
[31m-implemented as a custom stream.  Also, note that this implementation[m
[31m-does not convert the incoming data to a string.[m
[31m-[m
[31m-However, this would be better implemented as a [Transform][] stream.  See[m
[31m-below for a better implementation.[m
[31m-[m
[31m-```javascript[m
[31m-// A parser for a simple data protocol.[m
[31m-// The "header" is a JSON object, followed by 2 \n characters, and[m
[31m-// then a message body.[m
[31m-//[m
[31m-// NOTE: This can be done more simply as a Transform stream![m
[31m-// Using Readable directly for this is sub-optimal.  See the[m
[31m-// alternative example below under the Transform section.[m
[31m-[m
[31m-var Readable = require('stream').Readable;[m
[31m-var util = require('util');[m
[31m-[m
[31m-util.inherits(SimpleProtocol, Readable);[m
[31m-[m
[31m-function SimpleProtocol(source, options) {[m
[31m-  if (!(this instanceof SimpleProtocol))[m
[31m-    return new SimpleProtocol(source, options);[m
[31m-[m
[31m-  Readable.call(this, options);[m
[31m-  this._inBody = false;[m
[31m-  this._sawFirstCr = false;[m
[31m-[m
[31m-  // source is a readable stream, such as a socket or file[m
[31m-  this._source = source;[m
[31m-[m
[31m-  var self = this;[m
[31m-  source.on('end', function() {[m
[31m-    self.push(null);[m
[31m-  });[m
[31m-[m
[31m-  // give it a kick whenever the source is readable[m
[31m-  // read(0) will not consume any bytes[m
[31m-  source.on('readable', function() {[m
[31m-    self.read(0);[m
[31m-  });[m
[31m-[m
[31m-  this._rawHeader = [];[m
[31m-  this.header = null;[m
[31m-}[m
[31m-[m
[31m-SimpleProtocol.prototype._read = function(n) {[m
[31m-  if (!this._inBody) {[m
[31m-    var chunk = this._source.read();[m
[31m-[m
[31m-    // if the source doesn't have data, we don't have data yet.[m
[31m-    if (chunk === null)[m
[31m-      return this.push('');[m
[31m-[m
[31m-    // check if the chunk has a \n\n[m
[31m-    var split = -1;[m
[31m-    for (var i = 0; i < chunk.length; i++) {[m
[31m-      if (chunk[i] === 10) { // '\n'[m
[31m-        if (this._sawFirstCr) {[m
[31m-          split = i;[m
[31m-          break;[m
[31m-        } else {[m
[31m-          this._sawFirstCr = true;[m
[31m-        }[m
[31m-      } else {[m
[31m-        this._sawFirstCr = false;[m
[31m-      }[m
[31m-    }[m
[31m-[m
[31m-    if (split === -1) {[m
[31m-      // still waiting for the \n\n[m
[31m-      // stash the chunk, and try again.[m
[31m-      this._rawHeader.push(chunk);[m
[31m-      this.push('');[m
[31m-    } else {[m
[31m-      this._inBody = true;[m
[31m-      var h = chunk.slice(0, split);[m
[31m-      this._rawHeader.push(h);[m
[31m-      var header = Buffer.concat(this._rawHeader).toString();[m
[31m-      try {[m
[31m-        this.header = JSON.parse(header);[m
[31m-      } catch (er) {[m
[31m-        this.emit('error', new Error('invalid simple protocol data'));[m
[31m-        return;[m
[31m-      }[m
[31m-      // now, because we got some extra data, unshift the rest[m
[31m-      // back into the read queue so that our consumer will see it.[m
[31m-      var b = chunk.slice(split);[m
[31m-      this.unshift(b);[m
[31m-      // calling unshift by itself does not reset the reading state[m
[31m-      // of the stream; since we're inside _read, doing an additional[m
[31m-      // push('') will reset the state appropriately.[m
[31m-      this.push('');[m
[31m-[m
[31m-      // and let them know that we are done parsing the header.[m
[31m-      this.emit('header', this.header);[m
[31m-    }[m
[31m-  } else {[m
[31m-    // from there on, just provide the data to our consumer.[m
[31m-    // careful not to push(null), since that would indicate EOF.[m
[31m-    var chunk = this._source.read();[m
[31m-    if (chunk) this.push(chunk);[m
[31m-  }[m
[31m-};[m
[31m-[m
[31m-// Usage:[m
[31m-// var parser = new SimpleProtocol(source);[m
[31m-// Now parser is a readable stream that will emit 'header'[m
[31m-// with the parsed header data.[m
[31m-```[m
[31m-[m
[31m-[m
[31m-#### new stream.Readable([options])[m
[31m-[m
[31m-* `options` {Object}[m
[31m-  * `highWaterMark` {Number} The maximum number of bytes to store in[m
[31m-    the internal buffer before ceasing to read from the underlying[m
[31m-    resource.  Default=16kb, or 16 for `objectMode` streams[m
[31m-  * `encoding` {String} If specified, then buffers will be decoded to[m
[31m-    strings using the specified encoding.  Default=null[m
[31m-  * `objectMode` {Boolean} Whether this stream should behave[m
[31m-    as a stream of objects. Meaning that stream.read(n) returns[m
[31m-    a single value instead of a Buffer of size n.  Default=false[m
[31m-[m
[31m-In classes that extend the Readable class, make sure to call the[m
[31m-Readable constructor so that the buffering settings can be properly[m
[31m-initialized.[m
[31m-[m
[31m-#### readable.\_read(size)[m
[31m-[m
[31m-* `size` {Number} Number of bytes to read asynchronously[m
[31m-[m
[31m-Note: **Implement this method, but do NOT call it directly.**[m
[31m-[m
[31m-This method is prefixed with an underscore because it is internal to the[m
[31m-class that defines it and should only be called by the internal Readable[m
[31m-class methods. All Readable stream implementations must provide a _read[m
[31m-method to fetch data from the underlying resource.[m
[31m-[m
[31m-When _read is called, if data is available from the resource, `_read` should[m
[31m-start pushing that data into the read queue by calling `this.push(dataChunk)`.[m
[31m-`_read` should continue reading from the resource and pushing data until push[m
[31m-returns false, at which point it should stop reading from the resource. Only[m
[31m-when _read is called again after it has stopped should it start reading[m
[31m-more data from the resource and pushing that data onto the queue.[m
[31m-[m
[31m-Note: once the `_read()` method is called, it will not be called again until[m
[31m-the `push` method is called.[m
[31m-[m
[31m-The `size` argument is advisory.  Implementations where a "read" is a[m
[31m-single call that returns data can use this to know how much data to[m
[31m-fetch.  Implementations where that is not relevant, such as TCP or[m
[31m-TLS, may ignore this argument, and simply provide data whenever it[m
[31m-becomes available.  There is no need, for example to "wait" until[m
[31m-`size` bytes are available before calling [`stream.push(chunk)`][].[m
[31m-[m
[31m-#### readable.push(chunk[, encoding])[m
[31m-[m
[31m-* `chunk` {Buffer | null | String} Chunk of data to push into the read queue[m
[31m-* `encoding` {String} Encoding of String chunks.  Must be a valid[m
[31m-  Buffer encoding, such as `'utf8'` or `'ascii'`[m
[31m-* return {Boolean} Whether or not more pushes should be performed[m
[31m-[m
[31m-Note: **This method should be called by Readable implementors, NOT[m
[31m-by consumers of Readable streams.**[m
[31m-[m
[31m-If a value other than null is passed, The `push()` method adds a chunk of data[m
[31m-into the queue for subsequent stream processors to consume. If `null` is[m
[31m-passed, it signals the end of the stream (EOF), after which no more data[m
[31m-can be written.[m
[31m-[m
[31m-The data added with `push` can be pulled out by calling the `read()` method[m
[31m-when the `'readable'`event fires.[m
[31m-[m
[31m-This API is designed to be as flexible as possible.  For example,[m
[31m-you may be wrapping a lower-level source which has some sort of[m
[31m-pause/resume mechanism, and a data callback.  In those cases, you[m
[31m-could wrap the low-level source object by doing something like this:[m
[31m-[m
[31m-```javascript[m
[31m-// source is an object with readStop() and readStart() methods,[m
[31m-// and an `ondata` member that gets called when it has data, and[m
[31m-// an `onend` member that gets called when the data is over.[m
[31m-[m
[31m-util.inherits(SourceWrapper, Readable);[m
[31m-[m
[31m-function SourceWrapper(options) {[m
[31m-  Readable.call(this, options);[m
[31m-[m
[31m-  this._source = getLowlevelSourceObject();[m
[31m-  var self = this;[m
[31m-[m
[31m-  // Every time there's data, we push it into the internal buffer.[m
[31m-  this._source.ondata = function(chunk) {[m
[31m-    // if push() returns false, then we need to stop reading from source[m
[31m-    if (!self.push(chunk))[m
[31m-      self._source.readStop();[m
[31m-  };[m
[31m-[m
[31m-  // When the source ends, we push the EOF-signaling `null` chunk[m
[31m-  this._source.onend = function() {[m
[31m-    self.push(null);[m
[31m-  };[m
[31m-}[m
[31m-[m
[31m-// _read will be called when the stream wants to pull more data in[m
[31m-// the advisory size argument is ignored in this case.[m
[31m-SourceWrapper.prototype._read = function(size) {[m
[31m-  this._source.readStart();[m
[31m-};[m
[31m-```[m
[31m-[m
[31m-[m
[31m-### Class: stream.Writable[m
[31m-[m
[31m-<!--type=class-->[m
[31m-[m
[31m-`stream.Writable` is an abstract class designed to be extended with an[m
[31m-underlying implementation of the [`_write(chunk, encoding, callback)`][] method.[m
[31m-[m
[31m-Please see above under [API for Stream Consumers][] for how to consume[m
[31m-writable streams in your programs.  What follows is an explanation of[m
[31m-how to implement Writable streams in your programs.[m
[31m-[m
[31m-#### new stream.Writable([options])[m
[31m-[m
[31m-* `options` {Object}[m
[31m-  * `highWaterMark` {Number} Buffer level when [`write()`][] starts[m
[31m-    returning false. Default=16kb, or 16 for `objectMode` streams[m
[31m-  * `decodeStrings` {Boolean} Whether or not to decode strings into[m
[31m-    Buffers before passing them to [`_write()`][].  Default=true[m
[31m-  * `objectMode` {Boolean} Whether or not the `write(anyObj)` is[m
[31m-    a valid operation. If set you can write arbitrary data instead[m
[31m-    of only `Buffer` / `String` data.  Default=false[m
[31m-[m
[31m-In classes that extend the Writable class, make sure to call the[m
[31m-constructor so that the buffering settings can be properly[m
[31m-initialized.[m
[31m-[m
[31m-#### writable.\_write(chunk, encoding, callback)[m
[31m-[m
[31m-* `chunk` {Buffer | String} The chunk to be written. Will **always**[m
[31m-  be a buffer unless the `decodeStrings` option was set to `false`.[m
[31m-* `encoding` {String} If the chunk is a string, then this is the[m
[31m-  encoding type. If chunk is a buffer, then this is the special[m
[31m-  value - 'buffer', ignore it in this case.[m
[31m-* `callback` {Function} Call this function (optionally with an error[m
[31m-  argument) when you are done processing the supplied chunk.[m
[31m-[m
[31m-All Writable stream implementations must provide a [`_write()`][][m
[31m-method to send data to the underlying resource.[m
[31m-[m
[31m-Note: **This function MUST NOT be called directly.**  It should be[m
[31m-implemented by child classes, and called by the internal Writable[m
[31m-class methods only.[m
[31m-[m
[31m-Call the callback using the standard `callback(error)` pattern to[m
[31m-signal that the write completed successfully or with an error.[m
[31m-[m
[31m-If the `decodeStrings` flag is set in the constructor options, then[m
[31m-`chunk` may be a string rather than a Buffer, and `encoding` will[m
[31m-indicate the sort of string that it is.  This is to support[m
[31m-implementations that have an optimized handling for certain string[m
[31m-data encodings.  If you do not explicitly set the `decodeStrings`[m
[31m-option to `false`, then you can safely ignore the `encoding` argument,[m
[31m-and assume that `chunk` will always be a Buffer.[m
[31m-[m
[31m-This method is prefixed with an underscore because it is internal to[m
[31m-the class that defines it, and should not be called directly by user[m
[31m-programs.  However, you **are** expected to override this method in[m
[31m-your own extension classes.[m
[31m-[m
[31m-#### writable.\_writev(chunks, callback)[m
[31m-[m
[31m-* `chunks` {Array} The chunks to be written.  Each chunk has following[m
[31m-  format: `{ chunk: ..., encoding: ... }`.[m
[31m-* `callback` {Function} Call this function (optionally with an error[m
[31m-  argument) when you are done processing the supplied chunks.[m
[31m-[m
[31m-Note: **This function MUST NOT be called directly.**  It may be[m
[31m-implemented by child classes, and called by the internal Writable[m
[31m-class methods only.[m
[31m-[m
[31m-This function is completely optional to implement. In most cases it is[m
[31m-unnecessary.  If implemented, it will be called with all the chunks[m
[31m-that are buffered in the write queue.[m
[31m-[m
[31m-[m
[31m-### Class: stream.Duplex[m
[31m-[m
[31m-<!--type=class-->[m
[31m-[m
[31m-A "duplex" stream is one that is both Readable and Writable, such as a[m
[31m-TCP socket connection.[m
[31m-[m
[31m-Note that `stream.Duplex` is an abstract class designed to be extended[m
[31m-with an underlying implementation of the `_read(size)` and[m
[31m-[`_write(chunk, encoding, callback)`][] methods as you would with a[m
[31m-Readable or Writable stream class.[m
[31m-[m
[31m-Since JavaScript doesn't have multiple prototypal inheritance, this[m
[31m-class prototypally inherits from Readable, and then parasitically from[m
[31m-Writable.  It is thus up to the user to implement both the lowlevel[m
[31m-`_read(n)` method as well as the lowlevel[m
[31m-[`_write(chunk, encoding, callback)`][] method on extension duplex classes.[m
[31m-[m
[31m-#### new stream.Duplex(options)[m
[31m-[m
[31m-* `options` {Object} Passed to both Writable and Readable[m
[31m-  constructors. Also has the following fields:[m
[31m-  * `allowHalfOpen` {Boolean} Default=true.  If set to `false`, then[m
[31m-    the stream will automatically end the readable side when the[m
[31m-    writable side ends and vice versa.[m
[31m-  * `readableObjectMode` {Boolean} Default=false. Sets `objectMode`[m
[31m-    for readable side of the stream. Has no effect if `objectMode`[m
[31m-    is `true`.[m
[31m-  * `writableObjectMode` {Boolean} Default=false. Sets `objectMode`[m
[31m-    for writable side of the stream. Has no effect if `objectMode`[m
[31m-    is `true`.[m
[31m-[m
[31m-In classes that extend the Duplex class, make sure to call the[m
[31m-constructor so that the buffering settings can be properly[m
[31m-initialized.[m
[31m-[m
[31m-[m
[31m-### Class: stream.Transform[m
[31m-[m
[31m-A "transform" stream is a duplex stream where the output is causally[m
[31m-connected in some way to the input, such as a [zlib][] stream or a[m
[31m-[crypto][] stream.[m
[31m-[m
[31m-There is no requirement that the output be the same size as the input,[m
[31m-the same number of chunks, or arrive at the same time.  For example, a[m
[31m-Hash stream will only ever have a single chunk of output which is[m
[31m-provided when the input is ended.  A zlib stream will produce output[m
[31m-that is either much smaller or much larger than its input.[m
[31m-[m
[31m-Rather than implement the [`_read()`][] and [`_write()`][] methods, Transform[m
[31m-classes must implement the `_transform()` method, and may optionally[m
[31m-also implement the `_flush()` method.  (See below.)[m
[31m-[m
[31m-#### new stream.Transform([options])[m
[31m-[m
[31m-* `options` {Object} Passed to both Writable and Readable[m
[31m-  constructors.[m
[31m-[m
[31m-In classes that extend the Transform class, make sure to call the[m
[31m-constructor so that the buffering settings can be properly[m
[31m-initialized.[m
[31m-[m
[31m-#### transform.\_transform(chunk, encoding, callback)[m
[31m-[m
[31m-* `chunk` {Buffer | String} The chunk to be transformed. Will **always**[m
[31m-  be a buffer unless the `decodeStrings` option was set to `false`.[m
[31m-* `encoding` {String} If the chunk is a string, then this is the[m
[31m-  encoding type. If chunk is a buffer, then this is the special[m
[31m-  value - 'buffer', ignore it in this case.[m
[31m-* `callback` {Function} Call this function (optionally with an error[m
[31m-  argument and data) when you are done processing the supplied chunk.[m
[31m-[m
[31m-Note: **This function MUST NOT be called directly.**  It should be[m
[31m-implemented by child classes, and called by the internal Transform[m
[31m-class methods only.[m
[31m-[m
[31m-All Transform stream implementations must provide a `_transform`[m
[31m-method to accept input and produce output.[m
[31m-[m
[31m-`_transform` should do whatever has to be done in this specific[m
[31m-Transform class, to handle the bytes being written, and pass them off[m
[31m-to the readable portion of the interface.  Do asynchronous I/O,[m
[31m-process things, and so on.[m
[31m-[m
[31m-Call `transform.push(outputChunk)` 0 or more times to generate output[m
[31m-from this input chunk, depending on how much data you want to output[m
[31m-as a result of this chunk.[m
[31m-[m
[31m-Call the callback function only when the current chunk is completely[m
[31m-consumed.  Note that there may or may not be output as a result of any[m
[31m-particular input chunk. If you supply a second argument to the callback[m
[31m-it will be passed to the push method. In other words the following are[m
[31m-equivalent:[m
[31m-[m
[31m-```javascript[m
[31m-transform.prototype._transform = function (data, encoding, callback) {[m
[31m-  this.push(data);[m
[31m-  callback();[m
[31m-};[m
[31m-[m
[31m-transform.prototype._transform = function (data, encoding, callback) {[m
[31m-  callback(null, data);[m
[31m-};[m
[31m-```[m
[31m-[m
[31m-This method is prefixed with an underscore because it is internal to[m
[31m-the class that defines it, and should not be called directly by user[m
[31m-programs.  However, you **are** expected to override this method in[m
[31m-your own extension classes.[m
[31m-[m
[31m-#### transform.\_flush(callback)[m
[31m-[m
[31m-* `callback` {Function} Call this function (optionally with an error[m
[31m-  argument) when you are done flushing any remaining data.[m
[31m-[m
[31m-Note: **This function MUST NOT be called directly.**  It MAY be implemented[m
[31m-by child classes, and if so, will be called by the internal Transform[m
[31m-class methods only.[m
[31m-[m
[31m-In some cases, your transform operation may need to emit a bit more[m
[31m-data at the end of the stream.  For example, a `Zlib` compression[m
[31m-stream will store up some internal state so that it can optimally[m
[31m-compress the output.  At the end, however, it needs to do the best it[m
[31m-can with what is left, so that the data will be complete.[m
[31m-[m
[31m-In those cases, you can implement a `_flush` method, which will be[m
[31m-called at the very end, after all the written data is consumed, but[m
[31m-before emitting `end` to signal the end of the readable side.  Just[m
[31m-like with `_transform`, call `transform.push(chunk)` zero or more[m
[31m-times, as appropriate, and call `callback` when the flush operation is[m
[31m-complete.[m
[31m-[m
[31m-This method is prefixed with an underscore because it is internal to[m
[31m-the class that defines it, and should not be called directly by user[m
[31m-programs.  However, you **are** expected to override this method in[m
[31m-your own extension classes.[m
[31m-[m
[31m-#### Events: 'finish' and 'end'[m
[31m-[m
[31m-The [`finish`][] and [`end`][] events are from the parent Writable[m
[31m-and Readable classes respectively. The `finish` event is fired after[m
[31m-`.end()` is called and all chunks have been processed by `_transform`,[m
[31m-`end` is fired after all data has been output which is after the callback[m
[31m-in `_flush` has been called.[m
[31m-[m
[31m-#### Example: `SimpleProtocol` parser v2[m
[31m-[m
[31m-The example above of a simple protocol parser can be implemented[m
[31m-simply by using the higher level [Transform][] stream class, similar to[m
[31m-the `parseHeader` and `SimpleProtocol v1` examples above.[m
[31m-[m
[31m-In this example, rather than providing the input as an argument, it[m
[31m-would be piped into the parser, which is a more idiomatic Node.js stream[m
[31m-approach.[m
[31m-[m
[31m-```javascript[m
[31m-var util = require('util');[m
[31m-var Transform = require('stream').Transform;[m
[31m-util.inherits(SimpleProtocol, Transform);[m
[31m-[m
[31m-function SimpleProtocol(options) {[m
[31m-  if (!(this instanceof SimpleProtocol))[m
[31m-    return new SimpleProtocol(options);[m
[31m-[m
[31m-  Transform.call(this, options);[m
[31m-  this._inBody = false;[m
[31m-  this._sawFirstCr = false;[m
[31m-  this._rawHeader = [];[m
[31m-  this.header = null;[m
[31m-}[m
[31m-[m
[31m-SimpleProtocol.prototype._transform = function(chunk, encoding, done) {[m
[31m-  if (!this._inBody) {[m
[31m-    // check if the chunk has a \n\n[m
[31m-    var split = -1;[m
[31m-    for (var i = 0; i < chunk.length; i++) {[m
[31m-      if (chunk[i] === 10) { // '\n'[m
[31m-        if (this._sawFirstCr) {[m
[31m-          split = i;[m
[31m-          break;[m
[31m-        } else {[m
[31m-          this._sawFirstCr = true;[m
[31m-        }[m
[31m-      } else {[m
[31m-        this._sawFirstCr = false;[m
[31m-      }[m
[31m-    }[m
[31m-[m
[31m-    if (split === -1) {[m
[31m-      // still waiting for the \n\n[m
[31m-      // stash the chunk, and try again.[m
[31m-      this._rawHeader.push(chunk);[m
[31m-    } else {[m
[31m-      this._inBody = true;[m
[31m-      var h = chunk.slice(0, split);[m
[31m-      this._rawHeader.push(h);[m
[31m-      var header = Buffer.concat(this._rawHeader).toString();[m
[31m-      try {[m
[31m-        this.header = JSON.parse(header);[m
[31m-      } catch (er) {[m
[31m-        this.emit('error', new Error('invalid simple protocol data'));[m
[31m-        return;[m
[31m-      }[m
[31m-      // and let them know that we are done parsing the header.[m
[31m-      this.emit('header', this.header);[m
[31m-[m
[31m-      // now, because we got some extra data, emit this first.[m
[31m-      this.push(chunk.slice(split));[m
[31m-    }[m
[31m-  } else {[m
[31m-    // from there on, just provide the data to our consumer as-is.[m
[31m-    this.push(chunk);[m
[31m-  }[m
[31m-  done();[m
[31m-};[m
[31m-[m
[31m-// Usage:[m
[31m-// var parser = new SimpleProtocol();[m
[31m-// source.pipe(parser)[m
[31m-// Now parser is a readable stream that will emit 'header'[m
[31m-// with the parsed header data.[m
[31m-```[m
[31m-[m
[31m-[m
[31m-### Class: stream.PassThrough[m
[31m-[m
[31m-This is a trivial implementation of a [Transform][] stream that simply[m
[31m-passes the input bytes across to the output.  Its purpose is mainly[m
[31m-for examples and testing, but there are occasionally use cases where[m
[31m-it can come in handy as a building block for novel sorts of streams.[m
[31m-[m
[31m-[m
[31m-## Simplified Constructor API[m
[31m-[m
[31m-<!--type=misc-->[m
[31m-[m
[31m-In simple cases there is now the added benefit of being able to construct a stream without inheritance.[m
[31m-[m
[31m-This can be done by passing the appropriate methods as constructor options:[m
[31m-[m
[31m-Examples:[m
[31m-[m
[31m-### Readable[m
[31m-```javascript[m
[31m-var readable = new stream.Readable({[m
[31m-  read: function(n) {[m
[31m-    // sets this._read under the hood[m
[31m-  }[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-### Writable[m
[31m-```javascript[m
[31m-var writable = new stream.Writable({[m
[31m-  write: function(chunk, encoding, next) {[m
[31m-    // sets this._write under the hood[m
[31m-  }[m
[31m-});[m
[31m-[m
[31m-// or[m
[31m-[m
[31m-var writable = new stream.Writable({[m
[31m-  writev: function(chunks, next) {[m
[31m-    // sets this._writev under the hood[m
[31m-  }[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-### Duplex[m
[31m-```javascript[m
[31m-var duplex = new stream.Duplex({[m
[31m-  read: function(n) {[m
[31m-    // sets this._read under the hood[m
[31m-  },[m
[31m-  write: function(chunk, encoding, next) {[m
[31m-    // sets this._write under the hood[m
[31m-  }[m
[31m-});[m
[31m-[m
[31m-// or[m
[31m-[m
[31m-var duplex = new stream.Duplex({[m
[31m-  read: function(n) {[m
[31m-    // sets this._read under the hood[m
[31m-  },[m
[31m-  writev: function(chunks, next) {[m
[31m-    // sets this._writev under the hood[m
[31m-  }[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-### Transform[m
[31m-```javascript[m
[31m-var transform = new stream.Transform({[m
[31m-  transform: function(chunk, encoding, next) {[m
[31m-    // sets this._transform under the hood[m
[31m-  },[m
[31m-  flush: function(done) {[m
[31m-    // sets this._flush under the hood[m
[31m-  }[m
[31m-});[m
[31m-```[m
[31m-[m
[31m-## Streams: Under the Hood[m
[31m-[m
[31m-<!--type=misc-->[m
[31m-[m
[31m-### Buffering[m
[31m-[m
[31m-<!--type=misc-->[m
[31m-[m
[31m-Both Writable and Readable streams will buffer data on an internal[m
[31m-object which can be retrieved from `_writableState.getBuffer()` or [m
[31m-`_readableState.buffer`, respectively.[m
[31m-[m
[31m-The amount of data that will potentially be buffered depends on the[m
[31m-`highWaterMark` option which is passed into the constructor.[m
[31m-[m
[31m-Buffering in Readable streams happens when the implementation calls[m
[31m-[`stream.push(chunk)`][].  If the consumer of the Stream does not call[m
[31m-`stream.read()`, then the data will sit in the internal queue until it[m
[31m-is consumed.[m
[31m-[m
[31m-Buffering in Writable streams happens when the user calls[m
[31m-[`stream.write(chunk)`][] repeatedly, even when `write()` returns `false`.[m
[31m-[m
[31m-The purpose of streams, especially with the `pipe()` method, is to[m
[31m-limit the buffering of data to acceptable levels, so that sources and[m
[31m-destinations of varying speed will not overwhelm the available memory.[m
[31m-[m
[31m-### `stream.read(0)`[m
[31m-[m
[31m-There are some cases where you want to trigger a refresh of the[m
[31m-underlying readable stream mechanisms, without actually consuming any[m
[31m-data.  In that case, you can call `stream.read(0)`, which will always[m
[31m-return null.[m
[31m-[m
[31m-If the internal read buffer is below the `highWaterMark`, and the[m
[31m-stream is not currently reading, then calling `read(0)` will trigger[m
[31m-a low-level `_read` call.[m
[31m-[m
[31m-There is almost never a need to do this. However, you will see some[m
[31m-cases in Node.js's internals where this is done, particularly in the[m
[31m-Readable stream class internals.[m
[31m-[m
[31m-### `stream.push('')`[m
[31m-[m
[31m-Pushing a zero-byte string or Buffer (when not in [Object mode][]) has an[m
[31m-interesting side effect.  Because it *is* a call to[m
[31m-[`stream.push()`][], it will end the `reading` process.  However, it[m
[31m-does *not* add any data to the readable buffer, so there's nothing for[m
[31m-a user to consume.[m
[31m-[m
[31m-Very rarely, there are cases where you have no data to provide now,[m
[31m-but the consumer of your stream (or, perhaps, another bit of your own[m
[31m-code) will know when to check again, by calling `stream.read(0)`.  In[m
[31m-those cases, you *may* call `stream.push('')`.[m
[31m-[m
[31m-So far, the only use case for this functionality is in the[m
[31m-[tls.CryptoStream][] class, which is deprecated in Node.js/io.js v1.0.  If you[m
[31m-find that you have to use `stream.push('')`, please consider another[m
[31m-approach, because it almost certainly indicates that something is[m
[31m-horribly wrong.[m
[31m-[m
[31m-### Compatibility with Older Node.js Versions[m
[31m-[m
[31m-<!--type=misc-->[m
[31m-[m
[31m-In versions of Node.js prior to v0.10, the Readable stream interface was[m
[31m-simpler, but also less powerful and less useful.[m
[31m-[m
[31m-* Rather than waiting for you to call the `read()` method, `'data'`[m
[31m-  events would start emitting immediately.  If you needed to do some[m
[31m-  I/O to decide how to handle data, then you had to store the chunks[m
[31m-  in some kind of buffer so that they would not be lost.[m
[31m-* The [`pause()`][] method was advisory, rather than guaranteed.  This[m
[31m-  meant that you still had to be prepared to receive `'data'` events[m
[31m-  even when the stream was in a paused state.[m
[31m-[m
[31m-In Node.js v0.10, the Readable class described below was added.[m
[31m-For backwards compatibility with older Node.js programs, Readable streams[m
[31m-switch into "flowing mode" when a `'data'` event handler is added, or[m
[31m-when the [`resume()`][] method is called.  The effect is that, even if[m
[31m-you are not using the new `read()` method and `'readable'` event, you[m
[31m-no longer have to worry about losing `'data'` chunks.[m
[31m-[m
[31m-Most programs will continue to function normally.  However, this[m
[31m-introduces an edge case in the following conditions:[m
[31m-[m
[31m-* No [`'data'` event][] handler is added.[m
[31m-* The [`resume()`][] method is never called.[m
[31m-* The stream is not piped to any writable destination.[m
[31m-[m
[31m-For example, consider the following code:[m
[31m-[m
[31m-```javascript[m
[31m-// WARNING!  BROKEN![m
[31m-net.createServer(function(socket) {[m
[31m-[m
[31m-  // we add an 'end' method, but never consume the data[m
[31m-  socket.on('end', function() {[m
[31m-    // It will never get here.[m
[31m-    socket.end('I got your message (but didnt read it)\n');[m
[31m-  });[m
[31m-[m
[31m-}).listen(1337);[m
[31m-```[m
[31m-[m
[31m-In versions of Node.js prior to v0.10, the incoming message data would be[m
[31m-simply discarded.  However, in Node.js v0.10 and beyond,[m
[31m-the socket will remain paused forever.[m
[31m-[m
[31m-The workaround in this situation is to call the `resume()` method to[m
[31m-start the flow of data:[m
[31m-[m
[31m-```javascript[m
[31m-// Workaround[m
[31m-net.createServer(function(socket) {[m
[31m-[m
[31m-  socket.on('end', function() {[m
[31m-    socket.end('I got your message (but didnt read it)\n');[m
[31m-  });[m
[31m-[m
[31m-  // start the flow of data, discarding it.[m
[31m-  socket.resume();[m
[31m-[m
[31m-}).listen(1337);[m
[31m-```[m
[31m-[m
[31m-In addition to new Readable streams switching into flowing mode,[m
[31m-pre-v0.10 style streams can be wrapped in a Readable class using the[m
[31m-`wrap()` method.[m
[31m-[m
[31m-[m
[31m-### Object Mode[m
[31m-[m
[31m-<!--type=misc-->[m
[31m-[m
[31m-Normally, Streams operate on Strings and Buffers exclusively.[m
[31m-[m
[31m-Streams that are in **object mode** can emit generic JavaScript values[m
[31m-other than Buffers and Strings.[m
[31m-[m
[31m-A Readable stream in object mode will always return a single item from[m
[31m-a call to `stream.read(size)`, regardless of what the size argument[m
[31m-is.[m
[31m-[m
[31m-A Writable stream in object mode will always ignore the `encoding`[m
[31m-argument to `stream.write(data, encoding)`.[m
[31m-[m
[31m-The special value `null` still retains its special value for object[m
[31m-mode streams.  That is, for object mode readable streams, `null` as a[m
[31m-return value from `stream.read()` indicates that there is no more[m
[31m-data, and [`stream.push(null)`][] will signal the end of stream data[m
[31m-(`EOF`).[m
[31m-[m
[31m-No streams in Node.js core are object mode streams.  This pattern is only[m
[31m-used by userland streaming libraries.[m
[31m-[m
[31m-You should set `objectMode` in your stream child class constructor on[m
[31m-the options object.  Setting `objectMode` mid-stream is not safe.[m
[31m-[m
[31m-For Duplex streams `objectMode` can be set exclusively for readable or[m
[31m-writable side with `readableObjectMode` and `writableObjectMode`[m
[31m-respectively. These options can be used to implement parsers and[m
[31m-serializers with Transform streams.[m
[31m-[m
[31m-```javascript[m
[31m-var util = require('util');[m
[31m-var StringDecoder = require('string_decoder').StringDecoder;[m
[31m-var Transform = require('stream').Transform;[m
[31m-util.inherits(JSONParseStream, Transform);[m
[31m-[m
[31m-// Gets \n-delimited JSON string data, and emits the parsed objects[m
[31m-function JSONParseStream() {[m
[31m-  if (!(this instanceof JSONParseStream))[m
[31m-    return new JSONParseStream();[m
[31m-[m
[31m-  Transform.call(this, { readableObjectMode : true });[m
[31m-[m
[31m-  this._buffer = '';[m
[31m-  this._decoder = new StringDecoder('utf8');[m
[31m-}[m
[31m-[m
[31m-JSONParseStream.prototype._transform = function(chunk, encoding, cb) {[m
[31m-  this._buffer += this._decoder.write(chunk);[m
[31m-  // split on newlines[m
[31m-  var lines = this._buffer.split(/\r?\n/);[m
[31m-  // keep the last partial line buffered[m
[31m-  this._buffer = lines.pop();[m
[31m-  for (var l = 0; l < lines.length; l++) {[m
[31m-    var line = lines[l];[m
[31m-    try {[m
[31m-      var obj = JSON.parse(line);[m
[31m-    } catch (er) {[m
[31m-      this.emit('error', er);[m
[31m-      return;[m
[31m-    }[m
[31m-    // push the parsed object out to the readable consumer[m
[31m-    this.push(obj);[m
[31m-  }[m
[31m-  cb();[m
[31m-};[m
[31m-[m
[31m-JSONParseStream.prototype._flush = function(cb) {[m
[31m-  // Just handle any leftover[m
[31m-  var rem = this._buffer.trim();[m
[31m-  if (rem) {[m
[31m-    try {[m
[31m-      var obj = JSON.parse(rem);[m
[31m-    } catch (er) {[m
[31m-      this.emit('error', er);[m
[31m-      return;[m
[31m-    }[m
[31m-    // push the parsed object out to the readable consumer[m
[31m-    this.push(obj);[m
[31m-  }[m
[31m-  cb();[m
[31m-};[m
[31m-```[m
[31m-[m
[31m-[m
[31m-[EventEmitter]: https://iojs.org/dist/v5.0.0/doc/api/events.html#events_class_events_eventemitter[m
[31m-[Object mode]: #stream_object_mode[m
[31m-[`stream.push(chunk)`]: #stream_readable_push_chunk_encoding[m
[31m-[`stream.push(null)`]: #stream_readable_push_chunk_encoding[m
[31m-[`stream.push()`]: #stream_readable_push_chunk_encoding[m
[31m-[`unpipe()`]: #stream_readable_unpipe_destination[m
[31m-[unpiped]: #stream_readable_unpipe_destination[m
[31m-[tcp sockets]: https://iojs.org/dist/v5.0.0/doc/api/net.html#net_class_net_socket[m
[31m-[zlib streams]: zlib.html[m
[31m-[zlib]: zlib.html[m
[31m-[crypto streams]: crypto.html[m
[31m-[crypto]: crypto.html[m
[31m-[tls.CryptoStream]: https://iojs.org/dist/v5.0.0/doc/api/tls.html#tls_class_cryptostream[m
[31m-[process.stdin]: https://iojs.org/dist/v5.0.0/doc/api/process.html#process_process_stdin[m
[31m-[stdout]: https://iojs.org/dist/v5.0.0/doc/api/process.html#process_process_stdout[m
[31m-[process.stdout]: https://iojs.org/dist/v5.0.0/doc/api/process.html#process_process_stdout[m
[31m-[process.stderr]: https://iojs.org/dist/v5.0.0/doc/api/process.html#process_process_stderr[m
[31m-[child process stdout and stderr]: https://iojs.org/dist/v5.0.0/doc/api/child_process.html#child_process_child_stdout[m
[31m-[API for Stream Consumers]: #stream_api_for_stream_consumers[m
[31m-[API for Stream Implementors]: #stream_api_for_stream_implementors[m
[31m-[Readable]: #stream_class_stream_readable[m
[31m-[Writable]: #stream_class_stream_writable[m
[31m-[Duplex]: #stream_class_stream_duplex[m
[31m-[Transform]: #stream_class_stream_transform[m
[31m-[`end`]: #stream_event_end[m
[31m-[`finish`]: #stream_event_finish[m
[31m-[`_read(size)`]: #stream_readable_read_size_1[m
[31m-[`_read()`]: #stream_readable_read_size_1[m
[31m-[_read]: #stream_readable_read_size_1[m
[31m-[`writable.write(chunk)`]: #stream_writable_write_chunk_encoding_callback[m
[31m-[`write(chunk, encoding, callback)`]: #stream_writable_write_chunk_encoding_callback[m
[31m-[`write()`]: #stream_writable_write_chunk_encoding_callback[m
[31m-[`stream.write(chunk)`]: #stream_writable_write_chunk_encoding_callback[m
[31m-[`_write(chunk, encoding, callback)`]: #stream_writable_write_chunk_encoding_callback_1[m
[31m-[`_write()`]: #stream_writable_write_chunk_encoding_callback_1[m
[31m-[_write]: #stream_writable_write_chunk_encoding_callback_1[m
[31m-[`util.inherits`]: https://iojs.org/dist/v5.0.0/doc/api/util.html#util_util_inherits_constructor_superconstructor[m
[31m-[`end()`]: #stream_writable_end_chunk_encoding_callback[m
[31m-[`'data'` event]: #stream_event_data[m
[31m-[`resume()`]: #stream_readable_resume[m
[31m-[`readable.resume()`]: #stream_readable_resume[m
[31m-[`pause()`]: #stream_readable_pause[m
[31m-[`unpipe()`]: #stream_readable_unpipe_destination[m
[31m-[`pipe()`]: #stream_readable_pipe_destination_options[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/doc/wg-meetings/2015-01-30.md b/node_modules/mongodb/node_modules/readable-stream/doc/wg-meetings/2015-01-30.md[m
[1mdeleted file mode 100644[m
[1mindex 83275f1..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/doc/wg-meetings/2015-01-30.md[m
[1m+++ /dev/null[m
[36m@@ -1,60 +0,0 @@[m
[31m-# streams WG Meeting 2015-01-30[m
[31m-[m
[31m-## Links[m
[31m-[m
[31m-* **Google Hangouts Video**: http://www.youtube.com/watch?v=I9nDOSGfwZg[m
[31m-* **GitHub Issue**: https://github.com/iojs/readable-stream/issues/106[m
[31m-* **Original Minutes Google Doc**: https://docs.google.com/document/d/17aTgLnjMXIrfjgNaTUnHQO7m3xgzHR2VXBTmi03Qii4/[m
[31m-[m
[31m-## Agenda[m
[31m-[m
[31m-Extracted from https://github.com/iojs/readable-stream/labels/wg-agenda prior to meeting.[m
[31m-[m
[31m-* adopt a charter [#105](https://github.com/iojs/readable-stream/issues/105)[m
[31m-* release and versioning strategy [#101](https://github.com/iojs/readable-stream/issues/101)[m
[31m-* simpler stream creation [#102](https://github.com/iojs/readable-stream/issues/102)[m
[31m-* proposal: deprecate implicit flowing of streams [#99](https://github.com/iojs/readable-stream/issues/99)[m
[31m-[m
[31m-## Minutes[m
[31m-[m
[31m-### adopt a charter[m
[31m-[m
[31m-* group: +1's all around[m
[31m-[m
[31m-### What versioning scheme should be adopted?[m
[31m-* group: +1âs 3.0.0[m
[31m-* domenic+group: pulling in patches from other sources where appropriate[m
[31m-* mikeal: version independently, suggesting versions for io.js[m
[31m-* mikeal+domenic: work with TC to notify in advance of changes[m
[31m-simpler stream creation[m
[31m-[m
[31m-### streamline creation of streams[m
[31m-* sam: streamline creation of streams[m
[31m-* domenic: nice simple solution posted[m
[31m-  but, we lose the opportunity to change the model[m
[31m-  may not be backwards incompatible (double check keys)[m
[31m-[m
[31m-  **action item:** domenic will check[m
[31m-[m
[31m-### remove implicit flowing of streams on(âdataâ)[m
[31m-* add isFlowing / isPaused[m
[31m-* mikeal: worrying that weâre documenting polyfill methods â confuses users[m
[31m-* domenic: more reflective API is probably good, with warning labels for users[m
[31m-* new section for mad scientists (reflective stream access)[m
[31m-* calvin: name the âthird stateâ[m
[31m-* mikeal: maybe borrow the name from whatwg?[m
[31m-* domenic: weâre missing the âthird stateâ[m
[31m-* consensus: kind of difficult to name the third state[m
[31m-* mikeal: figure out differences in states / compat[m
[31m-* mathias: always flow on data â eliminates third state[m
[31m-  * explore what it breaks[m
[31m-[m
[31m-**action items:**[m
[31m-* ask isaac for ability to list packages by what public io.js APIs they use (esp. Stream)[m
[31m-* ask rod/build for infrastructure[m
[31m-* **chris**: explore the âflow on dataâ approach[m
[31m-* add isPaused/isFlowing[m
[31m-* add new docs section[m
[31m-* move isPaused to that section[m
[31m-[m
[31m-[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/duplex.js b/node_modules/mongodb/node_modules/readable-stream/duplex.js[m
[1mdeleted file mode 100644[m
[1mindex ca807af..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/duplex.js[m
[1m+++ /dev/null[m
[36m@@ -1 +0,0 @@[m
[31m-module.exports = require("./lib/_stream_duplex.js")[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/lib/_stream_duplex.js b/node_modules/mongodb/node_modules/readable-stream/lib/_stream_duplex.js[m
[1mdeleted file mode 100644[m
[1mindex 69558af..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/lib/_stream_duplex.js[m
[1m+++ /dev/null[m
[36m@@ -1,82 +0,0 @@[m
[31m-// a duplex stream is just a stream that is both readable and writable.[m
[31m-// Since JS doesn't have multiple prototypal inheritance, this class[m
[31m-// prototypally inherits from Readable, and then parasitically from[m
[31m-// Writable.[m
[31m-[m
[31m-'use strict';[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var objectKeys = Object.keys || function (obj) {[m
[31m-  var keys = [];[m
[31m-  for (var key in obj) keys.push(key);[m
[31m-  return keys;[m
[31m-}[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-[m
[31m-module.exports = Duplex;[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var processNextTick = require('process-nextick-args');[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var util = require('core-util-is');[m
[31m-util.inherits = require('inherits');[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-var Readable = require('./_stream_readable');[m
[31m-var Writable = require('./_stream_writable');[m
[31m-[m
[31m-util.inherits(Duplex, Readable);[m
[31m-[m
[31m-var keys = objectKeys(Writable.prototype);[m
[31m-for (var v = 0; v < keys.length; v++) {[m
[31m-  var method = keys[v];[m
[31m-  if (!Duplex.prototype[method])[m
[31m-    Duplex.prototype[method] = Writable.prototype[method];[m
[31m-}[m
[31m-[m
[31m-function Duplex(options) {[m
[31m-  if (!(this instanceof Duplex))[m
[31m-    return new Duplex(options);[m
[31m-[m
[31m-  Readable.call(this, options);[m
[31m-  Writable.call(this, options);[m
[31m-[m
[31m-  if (options && options.readable === false)[m
[31m-    this.readable = false;[m
[31m-[m
[31m-  if (options && options.writable === false)[m
[31m-    this.writable = false;[m
[31m-[m
[31m-  this.allowHalfOpen = true;[m
[31m-  if (options && options.allowHalfOpen === false)[m
[31m-    this.allowHalfOpen = false;[m
[31m-[m
[31m-  this.once('end', onend);[m
[31m-}[m
[31m-[m
[31m-// the no-half-open enforcer[m
[31m-function onend() {[m
[31m-  // if we allow half-open state, or if the writable side ended,[m
[31m-  // then we're ok.[m
[31m-  if (this.allowHalfOpen || this._writableState.ended)[m
[31m-    return;[m
[31m-[m
[31m-  // no more data can be written.[m
[31m-  // But allow more writes to happen in this tick.[m
[31m-  processNextTick(onEndNT, this);[m
[31m-}[m
[31m-[m
[31m-function onEndNT(self) {[m
[31m-  self.end();[m
[31m-}[m
[31m-[m
[31m-function forEach (xs, f) {[m
[31m-  for (var i = 0, l = xs.length; i < l; i++) {[m
[31m-    f(xs[i], i);[m
[31m-  }[m
[31m-}[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/lib/_stream_passthrough.js b/node_modules/mongodb/node_modules/readable-stream/lib/_stream_passthrough.js[m
[1mdeleted file mode 100644[m
[1mindex bddfdd0..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/lib/_stream_passthrough.js[m
[1m+++ /dev/null[m
[36m@@ -1,27 +0,0 @@[m
[31m-// a passthrough stream.[m
[31m-// basically just the most minimal sort of Transform stream.[m
[31m-// Every written chunk gets output as-is.[m
[31m-[m
[31m-'use strict';[m
[31m-[m
[31m-module.exports = PassThrough;[m
[31m-[m
[31m-var Transform = require('./_stream_transform');[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var util = require('core-util-is');[m
[31m-util.inherits = require('inherits');[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-util.inherits(PassThrough, Transform);[m
[31m-[m
[31m-function PassThrough(options) {[m
[31m-  if (!(this instanceof PassThrough))[m
[31m-    return new PassThrough(options);[m
[31m-[m
[31m-  Transform.call(this, options);[m
[31m-}[m
[31m-[m
[31m-PassThrough.prototype._transform = function(chunk, encoding, cb) {[m
[31m-  cb(null, chunk);[m
[31m-};[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/lib/_stream_readable.js b/node_modules/mongodb/node_modules/readable-stream/lib/_stream_readable.js[m
[1mdeleted file mode 100644[m
[1mindex 90068ea..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/lib/_stream_readable.js[m
[1m+++ /dev/null[m
[36m@@ -1,973 +0,0 @@[m
[31m-'use strict';[m
[31m-[m
[31m-module.exports = Readable;[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var processNextTick = require('process-nextick-args');[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var isArray = require('isarray');[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var Buffer = require('buffer').Buffer;[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-Readable.ReadableState = ReadableState;[m
[31m-[m
[31m-var EE = require('events');[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var EElistenerCount = function(emitter, type) {[m
[31m-  return emitter.listeners(type).length;[m
[31m-};[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var Stream;[m
[31m-(function (){try{[m
[31m-  Stream = require('st' + 'ream');[m
[31m-}catch(_){}finally{[m
[31m-  if (!Stream)[m
[31m-    Stream = require('events').EventEmitter;[m
[31m-}}())[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-var Buffer = require('buffer').Buffer;[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var util = require('core-util-is');[m
[31m-util.inherits = require('inherits');[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var debugUtil = require('util');[m
[31m-var debug;[m
[31m-if (debugUtil && debugUtil.debuglog) {[m
[31m-  debug = debugUtil.debuglog('stream');[m
[31m-} else {[m
[31m-  debug = function () {};[m
[31m-}[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-var StringDecoder;[m
[31m-[m
[31m-util.inherits(Readable, Stream);[m
[31m-[m
[31m-function ReadableState(options, stream) {[m
[31m-  var Duplex = require('./_stream_duplex');[m
[31m-[m
[31m-  options = options || {};[m
[31m-[m
[31m-  // object stream flag. Used to make read(n) ignore n and to[m
[31m-  // make all the buffer merging and length checks go away[m
[31m-  this.objectMode = !!options.objectMode;[m
[31m-[m
[31m-  if (stream instanceof Duplex)[m
[31m-    this.objectMode = this.objectMode || !!options.readableObjectMode;[m
[31m-[m
[31m-  // the point at which it stops calling _read() to fill the buffer[m
[31m-  // Note: 0 is a valid value, means "don't call _read preemptively ever"[m
[31m-  var hwm = options.highWaterMark;[m
[31m-  var defaultHwm = this.objectMode ? 16 : 16 * 1024;[m
[31m-  this.highWaterMark = (hwm || hwm === 0) ? hwm : defaultHwm;[m
[31m-[m
[31m-  // cast to ints.[m
[31m-  this.highWaterMark = ~~this.highWaterMark;[m
[31m-[m
[31m-  this.buffer = [];[m
[31m-  this.length = 0;[m
[31m-  this.pipes = null;[m
[31m-  this.pipesCount = 0;[m
[31m-  this.flowing = null;[m
[31m-  this.ended = false;[m
[31m-  this.endEmitted = false;[m
[31m-  this.reading = false;[m
[31m-[m
[31m-  // a flag to be able to tell if the onwrite cb is called immediately,[m
[31m-  // or on a later tick.  We set this to true at first, because any[m
[31m-  // actions that shouldn't happen until "later" should generally also[m
[31m-  // not happen before the first write call.[m
[31m-  this.sync = true;[m
[31m-[m
[31m-  // whenever we return null, then we set a flag to say[m
[31m-  // that we're awaiting a 'readable' event emission.[m
[31m-  this.needReadable = false;[m
[31m-  this.emittedReadable = false;[m
[31m-  this.readableListening = false;[m
[31m-[m
[31m-  // Crypto is kind of old and crusty.  Historically, its default string[m
[31m-  // encoding is 'binary' so we have to make this configurable.[m
[31m-  // Everything else in the universe uses 'utf8', though.[m
[31m-  this.defaultEncoding = options.defaultEncoding || 'utf8';[m
[31m-[m
[31m-  // when piping, we only care about 'readable' events that happen[m
[31m-  // after read()ing all the bytes and not getting any pushback.[m
[31m-  this.ranOut = false;[m
[31m-[m
[31m-  // the number of writers that are awaiting a drain event in .pipe()s[m
[31m-  this.awaitDrain = 0;[m
[31m-[m
[31m-  // if true, a maybeReadMore has been scheduled[m
[31m-  this.readingMore = false;[m
[31m-[m
[31m-  this.decoder = null;[m
[31m-  this.encoding = null;[m
[31m-  if (options.encoding) {[m
[31m-    if (!StringDecoder)[m
[31m-      StringDecoder = require('string_decoder/').StringDecoder;[m
[31m-    this.decoder = new StringDecoder(options.encoding);[m
[31m-    this.encoding = options.encoding;[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-function Readable(options) {[m
[31m-  var Duplex = require('./_stream_duplex');[m
[31m-[m
[31m-  if (!(this instanceof Readable))[m
[31m-    return new Readable(options);[m
[31m-[m
[31m-  this._readableState = new ReadableState(options, this);[m
[31m-[m
[31m-  // legacy[m
[31m-  this.readable = true;[m
[31m-[m
[31m-  if (options && typeof options.read === 'function')[m
[31m-    this._read = options.read;[m
[31m-[m
[31m-  Stream.call(this);[m
[31m-}[m
[31m-[m
[31m-// Manually shove something into the read() buffer.[m
[31m-// This returns true if the highWaterMark has not been hit yet,[m
[31m-// similar to how Writable.write() returns true if you should[m
[31m-// write() some more.[m
[31m-Readable.prototype.push = function(chunk, encoding) {[m
[31m-  var state = this._readableState;[m
[31m-[m
[31m-  if (!state.objectMode && typeof chunk === 'string') {[m
[31m-    encoding = encoding || state.defaultEncoding;[m
[31m-    if (encoding !== state.encoding) {[m
[31m-      chunk = new Buffer(chunk, encoding);[m
[31m-      encoding = '';[m
[31m-    }[m
[31m-  }[m
[31m-[m
[31m-  return readableAddChunk(this, state, chunk, encoding, false);[m
[31m-};[m
[31m-[m
[31m-// Unshift should *always* be something directly out of read()[m
[31m-Readable.prototype.unshift = function(chunk) {[m
[31m-  var state = this._readableState;[m
[31m-  return readableAddChunk(this, state, chunk, '', true);[m
[31m-};[m
[31m-[m
[31m-Readable.prototype.isPaused = function() {[m
[31m-  return this._readableState.flowing === false;[m
[31m-};[m
[31m-[m
[31m-function readableAddChunk(stream, state, chunk, encoding, addToFront) {[m
[31m-  var er = chunkInvalid(state, chunk);[m
[31m-  if (er) {[m
[31m-    stream.emit('error', er);[m
[31m-  } else if (chunk === null) {[m
[31m-    state.reading = false;[m
[31m-    onEofChunk(stream, state);[m
[31m-  } else if (state.objectMode || chunk && chunk.length > 0) {[m
[31m-    if (state.ended && !addToFront) {[m
[31m-      var e = new Error('stream.push() after EOF');[m
[31m-      stream.emit('error', e);[m
[31m-    } else if (state.endEmitted && addToFront) {[m
[31m-      var e = new Error('stream.unshift() after end event');[m
[31m-      stream.emit('error', e);[m
[31m-    } else {[m
[31m-      if (state.decoder && !addToFront && !encoding)[m
[31m-        chunk = state.decoder.write(chunk);[m
[31m-[m
[31m-      if (!addToFront)[m
[31m-        state.reading = false;[m
[31m-[m
[31m-      // if we want the data now, just emit it.[m
[31m-      if (state.flowing && state.length === 0 && !state.sync) {[m
[31m-        stream.emit('data', chunk);[m
[31m-        stream.read(0);[m
[31m-      } else {[m
[31m-        // update the buffer info.[m
[31m-        state.length += state.objectMode ? 1 : chunk.length;[m
[31m-        if (addToFront)[m
[31m-          state.buffer.unshift(chunk);[m
[31m-        else[m
[31m-          state.buffer.push(chunk);[m
[31m-[m
[31m-        if (state.needReadable)[m
[31m-          emitReadable(stream);[m
[31m-      }[m
[31m-[m
[31m-      maybeReadMore(stream, state);[m
[31m-    }[m
[31m-  } else if (!addToFront) {[m
[31m-    state.reading = false;[m
[31m-  }[m
[31m-[m
[31m-  return needMoreData(state);[m
[31m-}[m
[31m-[m
[31m-[m
[31m-// if it's past the high water mark, we can push in some more.[m
[31m-// Also, if we have no data yet, we can stand some[m
[31m-// more bytes.  This is to work around cases where hwm=0,[m
[31m-// such as the repl.  Also, if the push() triggered a[m
[31m-// readable event, and the user called read(largeNumber) such that[m
[31m-// needReadable was set, then we ought to push more, so that another[m
[31m-// 'readable' event will be triggered.[m
[31m-function needMoreData(state) {[m
[31m-  return !state.ended &&[m
[31m-         (state.needReadable ||[m
[31m-          state.length < state.highWaterMark ||[m
[31m-          state.length === 0);[m
[31m-}[m
[31m-[m
[31m-// backwards compatibility.[m
[31m-Readable.prototype.setEncoding = function(enc) {[m
[31m-  if (!StringDecoder)[m
[31m-    StringDecoder = require('string_decoder/').StringDecoder;[m
[31m-  this._readableState.decoder = new StringDecoder(enc);[m
[31m-  this._readableState.encoding = enc;[m
[31m-  return this;[m
[31m-};[m
[31m-[m
[31m-// Don't raise the hwm > 8MB[m
[31m-var MAX_HWM = 0x800000;[m
[31m-function computeNewHighWaterMark(n) {[m
[31m-  if (n >= MAX_HWM) {[m
[31m-    n = MAX_HWM;[m
[31m-  } else {[m
[31m-    // Get the next highest power of 2[m
[31m-    n--;[m
[31m-    n |= n >>> 1;[m
[31m-    n |= n >>> 2;[m
[31m-    n |= n >>> 4;[m
[31m-    n |= n >>> 8;[m
[31m-    n |= n >>> 16;[m
[31m-    n++;[m
[31m-  }[m
[31m-  return n;[m
[31m-}[m
[31m-[m
[31m-function howMuchToRead(n, state) {[m
[31m-  if (state.length === 0 && state.ended)[m
[31m-    return 0;[m
[31m-[m
[31m-  if (state.objectMode)[m
[31m-    return n === 0 ? 0 : 1;[m
[31m-[m
[31m-  if (n === null || isNaN(n)) {[m
[31m-    // only flow one buffer at a time[m
[31m-    if (state.flowing && state.buffer.length)[m
[31m-      return state.buffer[0].length;[m
[31m-    else[m
[31m-      return state.length;[m
[31m-  }[m
[31m-[m
[31m-  if (n <= 0)[m
[31m-    return 0;[m
[31m-[m
[31m-  // If we're asking for more than the target buffer level,[m
[31m-  // then raise the water mark.  Bump up to the next highest[m
[31m-  // power of 2, to prevent increasing it excessively in tiny[m
[31m-  // amounts.[m
[31m-  if (n > state.highWaterMark)[m
[31m-    state.highWaterMark = computeNewHighWaterMark(n);[m
[31m-[m
[31m-  // don't have that much.  return null, unless we've ended.[m
[31m-  if (n > state.length) {[m
[31m-    if (!state.ended) {[m
[31m-      state.needReadable = true;[m
[31m-      return 0;[m
[31m-    } else {[m
[31m-      return state.length;[m
[31m-    }[m
[31m-  }[m
[31m-[m
[31m-  return n;[m
[31m-}[m
[31m-[m
[31m-// you can override either this method, or the async _read(n) below.[m
[31m-Readable.prototype.read = function(n) {[m
[31m-  debug('read', n);[m
[31m-  var state = this._readableState;[m
[31m-  var nOrig = n;[m
[31m-[m
[31m-  if (typeof n !== 'number' || n > 0)[m
[31m-    state.emittedReadable = false;[m
[31m-[m
[31m-  // if we're doing read(0) to trigger a readable event, but we[m
[31m-  // already have a bunch of data in the buffer, then just trigger[m
[31m-  // the 'readable' event and move on.[m
[31m-  if (n === 0 &&[m
[31m-      state.needReadable &&[m
[31m-      (state.length >= state.highWaterMark || state.ended)) {[m
[31m-    debug('read: emitReadable', state.length, state.ended);[m
[31m-    if (state.length === 0 && state.ended)[m
[31m-      endReadable(this);[m
[31m-    else[m
[31m-      emitReadable(this);[m
[31m-    return null;[m
[31m-  }[m
[31m-[m
[31m-  n = howMuchToRead(n, state);[m
[31m-[m
[31m-  // if we've ended, and we're now clear, then finish it up.[m
[31m-  if (n === 0 && state.ended) {[m
[31m-    if (state.length === 0)[m
[31m-      endReadable(this);[m
[31m-    return null;[m
[31m-  }[m
[31m-[m
[31m-  // All the actual chunk generation logic needs to be[m
[31m-  // *below* the call to _read.  The reason is that in certain[m
[31m-  // synthetic stream cases, such as passthrough streams, _read[m
[31m-  // may be a completely synchronous operation which may change[m
[31m-  // the state of the read buffer, providing enough data when[m
[31m-  // before there was *not* enough.[m
[31m-  //[m
[31m-  // So, the steps are:[m
[31m-  // 1. Figure out what the state of things will be after we do[m
[31m-  // a read from the buffer.[m
[31m-  //[m
[31m-  // 2. If that resulting state will trigger a _read, then call _read.[m
[31m-  // Note that this may be asynchronous, or synchronous.  Yes, it is[m
[31m-  // deeply ugly to write APIs this way, but that still doesn't mean[m
[31m-  // that the Readable class should behave improperly, as streams are[m
[31m-  // designed to be sync/async agnostic.[m
[31m-  // Take note if the _read call is sync or async (ie, if the read call[m
[31m-  // has returned yet), so that we know whether or not it's safe to emit[m
[31m-  // 'readable' etc.[m
[31m-  //[m
[31m-  // 3. Actually pull the requested chunks out of the buffer and return.[m
[31m-[m
[31m-  // if we need a readable event, then we need to do some reading.[m
[31m-  var doRead = state.needReadable;[m
[31m-  debug('need readable', doRead);[m
[31m-[m
[31m-  // if we currently have less than the highWaterMark, then also read some[m
[31m-  if (state.length === 0 || state.length - n < state.highWaterMark) {[m
[31m-    doRead = true;[m
[31m-    debug('length less than watermark', doRead);[m
[31m-  }[m
[31m-[m
[31m-  // however, if we've ended, then there's no point, and if we're already[m
[31m-  // reading, then it's unnecessary.[m
[31m-  if (state.ended || state.reading) {[m
[31m-    doRead = false;[m
[31m-    debug('reading or ended', doRead);[m
[31m-  }[m
[31m-[m
[31m-  if (doRead) {[m
[31m-    debug('do read');[m
[31m-    state.reading = true;[m
[31m-    state.sync = true;[m
[31m-    // if the length is currently zero, then we *need* a readable event.[m
[31m-    if (state.length === 0)[m
[31m-      state.needReadable = true;[m
[31m-    // call internal read method[m
[31m-    this._read(state.highWaterMark);[m
[31m-    state.sync = false;[m
[31m-  }[m
[31m-[m
[31m-  // If _read pushed data synchronously, then `reading` will be false,[m
[31m-  // and we need to re-evaluate how much data we can return to the user.[m
[31m-  if (doRead && !state.reading)[m
[31m-    n = howMuchToRead(nOrig, state);[m
[31m-[m
[31m-  var ret;[m
[31m-  if (n > 0)[m
[31m-    ret = fromList(n, state);[m
[31m-  else[m
[31m-    ret = null;[m
[31m-[m
[31m-  if (ret === null) {[m
[31m-    state.needReadable = true;[m
[31m-    n = 0;[m
[31m-  }[m
[31m-[m
[31m-  state.length -= n;[m
[31m-[m
[31m-  // If we have nothing in the buffer, then we want to know[m
[31m-  // as soon as we *do* get something into the buffer.[m
[31m-  if (state.length === 0 && !state.ended)[m
[31m-    state.needReadable = true;[m
[31m-[m
[31m-  // If we tried to read() past the EOF, then emit end on the next tick.[m
[31m-  if (nOrig !== n && state.ended && state.length === 0)[m
[31m-    endReadable(this);[m
[31m-[m
[31m-  if (ret !== null)[m
[31m-    this.emit('data', ret);[m
[31m-[m
[31m-  return ret;[m
[31m-};[m
[31m-[m
[31m-function chunkInvalid(state, chunk) {[m
[31m-  var er = null;[m
[31m-  if (!(Buffer.isBuffer(chunk)) &&[m
[31m-      typeof chunk !== 'string' &&[m
[31m-      chunk !== null &&[m
[31m-      chunk !== undefined &&[m
[31m-      !state.objectMode) {[m
[31m-    er = new TypeError('Invalid non-string/buffer chunk');[m
[31m-  }[m
[31m-  return er;[m
[31m-}[m
[31m-[m
[31m-[m
[31m-function onEofChunk(stream, state) {[m
[31m-  if (state.ended) return;[m
[31m-  if (state.decoder) {[m
[31m-    var chunk = state.decoder.end();[m
[31m-    if (chunk && chunk.length) {[m
[31m-      state.buffer.push(chunk);[m
[31m-      state.length += state.objectMode ? 1 : chunk.length;[m
[31m-    }[m
[31m-  }[m
[31m-  state.ended = true;[m
[31m-[m
[31m-  // emit 'readable' now to make sure it gets picked up.[m
[31m-  emitReadable(stream);[m
[31m-}[m
[31m-[m
[31m-// Don't emit readable right away in sync mode, because this can trigger[m
[31m-// another read() call => stack overflow.  This way, it might trigger[m
[31m-// a nextTick recursion warning, but that's not so bad.[m
[31m-function emitReadable(stream) {[m
[31m-  var state = stream._readableState;[m
[31m-  state.needReadable = false;[m
[31m-  if (!state.emittedReadable) {[m
[31m-    debug('emitReadable', state.flowing);[m
[31m-    state.emittedReadable = true;[m
[31m-    if (state.sync)[m
[31m-      processNextTick(emitReadable_, stream);[m
[31m-    else[m
[31m-      emitReadable_(stream);[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-function emitReadable_(stream) {[m
[31m-  debug('emit readable');[m
[31m-  stream.emit('readable');[m
[31m-  flow(stream);[m
[31m-}[m
[31m-[m
[31m-[m
[31m-// at this point, the user has presumably seen the 'readable' event,[m
[31m-// and called read() to consume some data.  that may have triggered[m
[31m-// in turn another _read(n) call, in which case reading = true if[m
[31m-// it's in progress.[m
[31m-// However, if we're not ended, or reading, and the length < hwm,[m
[31m-// then go ahead and try to read some more preemptively.[m
[31m-function maybeReadMore(stream, state) {[m
[31m-  if (!state.readingMore) {[m
[31m-    state.readingMore = true;[m
[31m-    processNextTick(maybeReadMore_, stream, state);[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-function maybeReadMore_(stream, state) {[m
[31m-  var len = state.length;[m
[31m-  while (!state.reading && !state.flowing && !state.ended &&[m
[31m-         state.length < state.highWaterMark) {[m
[31m-    debug('maybeReadMore read 0');[m
[31m-    stream.read(0);[m
[31m-    if (len === state.length)[m
[31m-      // didn't get any data, stop spinning.[m
[31m-      break;[m
[31m-    else[m
[31m-      len = state.length;[m
[31m-  }[m
[31m-  state.readingMore = false;[m
[31m-}[m
[31m-[m
[31m-// abstract method.  to be overridden in specific implementation classes.[m
[31m-// call cb(er, data) where data is <= n in length.[m
[31m-// for virtual (non-string, non-buffer) streams, "length" is somewhat[m
[31m-// arbitrary, and perhaps not very meaningful.[m
[31m-Readable.prototype._read = function(n) {[m
[31m-  this.emit('error', new Error('not implemented'));[m
[31m-};[m
[31m-[m
[31m-Readable.prototype.pipe = function(dest, pipeOpts) {[m
[31m-  var src = this;[m
[31m-  var state = this._readableState;[m
[31m-[m
[31m-  switch (state.pipesCount) {[m
[31m-    case 0:[m
[31m-      state.pipes = dest;[m
[31m-      break;[m
[31m-    case 1:[m
[31m-      state.pipes = [state.pipes, dest];[m
[31m-      break;[m
[31m-    default:[m
[31m-      state.pipes.push(dest);[m
[31m-      break;[m
[31m-  }[m
[31m-  state.pipesCount += 1;[m
[31m-  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);[m
[31m-[m
[31m-  var doEnd = (!pipeOpts || pipeOpts.end !== false) &&[m
[31m-              dest !== process.stdout &&[m
[31m-              dest !== process.stderr;[m
[31m-[m
[31m-  var endFn = doEnd ? onend : cleanup;[m
[31m-  if (state.endEmitted)[m
[31m-    processNextTick(endFn);[m
[31m-  else[m
[31m-    src.once('end', endFn);[m
[31m-[m
[31m-  dest.on('unpipe', onunpipe);[m
[31m-  function onunpipe(readable) {[m
[31m-    debug('onunpipe');[m
[31m-    if (readable === src) {[m
[31m-      cleanup();[m
[31m-    }[m
[31m-  }[m
[31m-[m
[31m-  function onend() {[m
[31m-    debug('onend');[m
[31m-    dest.end();[m
[31m-  }[m
[31m-[m
[31m-  // when the dest drains, it reduces the awaitDrain counter[m
[31m-  // on the source.  This would be more elegant with a .once()[m
[31m-  // handler in flow(), but adding and removing repeatedly is[m
[31m-  // too slow.[m
[31m-  var ondrain = pipeOnDrain(src);[m
[31m-  dest.on('drain', ondrain);[m
[31m-[m
[31m-  var cleanedUp = false;[m
[31m-  function cleanup() {[m
[31m-    debug('cleanup');[m
[31m-    // cleanup event handlers once the pipe is broken[m
[31m-    dest.removeListener('close', onclose);[m
[31m-    dest.removeListener('finish', onfinish);[m
[31m-    dest.removeListener('drain', ondrain);[m
[31m-    dest.removeListener('error', onerror);[m
[31m-    dest.removeListener('unpipe', onunpipe);[m
[31m-    src.removeListener('end', onend);[m
[31m-    src.removeListener('end', cleanup);[m
[31m-    src.removeListener('data', ondata);[m
[31m-[m
[31m-    cleanedUp = true;[m
[31m-[m
[31m-    // if the reader is waiting for a drain event from this[m
[31m-    // specific writer, then it would cause it to never start[m
[31m-    // flowing again.[m
[31m-    // So, if this is awaiting a drain, then we just call it now.[m
[31m-    // If we don't know, then assume that we are waiting for one.[m
[31m-    if (state.awaitDrain &&[m
[31m-        (!dest._writableState || dest._writableState.needDrain))[m
[31m-      ondrain();[m
[31m-  }[m
[31m-[m
[31m-  src.on('data', ondata);[m
[31m-  function ondata(chunk) {[m
[31m-    debug('ondata');[m
[31m-    var ret = dest.write(chunk);[m
[31m-    if (false === ret) {[m
[31m-      // If the user unpiped during `dest.write()`, it is possible[m
[31m-      // to get stuck in a permanently paused state if that write[m
[31m-      // also returned false.[m
[31m-      if (state.pipesCount === 1 &&[m
[31m-          state.pipes[0] === dest &&[m
[31m-          src.listenerCount('data') === 1 &&[m
[31m-          !cleanedUp) {[m
[31m-        debug('false write response, pause', src._readableState.awaitDrain);[m
[31m-        src._readableState.awaitDrain++;[m
[31m-      }[m
[31m-      src.pause();[m
[31m-    }[m
[31m-  }[m
[31m-[m
[31m-  // if the dest has an error, then stop piping into it.[m
[31m-  // however, don't suppress the throwing behavior for this.[m
[31m-  function onerror(er) {[m
[31m-    debug('onerror', er);[m
[31m-    unpipe();[m
[31m-    dest.removeListener('error', onerror);[m
[31m-    if (EElistenerCount(dest, 'error') === 0)[m
[31m-      dest.emit('error', er);[m
[31m-  }[m
[31m-  // This is a brutally ugly hack to make sure that our error handler[m
[31m-  // is attached before any userland ones.  NEVER DO THIS.[m
[31m-  if (!dest._events || !dest._events.error)[m
[31m-    dest.on('error', onerror);[m
[31m-  else if (isArray(dest._events.error))[m
[31m-    dest._events.error.unshift(onerror);[m
[31m-  else[m
[31m-    dest._events.error = [onerror, dest._events.error];[m
[31m-[m
[31m-[m
[31m-  // Both close and finish should trigger unpipe, but only once.[m
[31m-  function onclose() {[m
[31m-    dest.removeListener('finish', onfinish);[m
[31m-    unpipe();[m
[31m-  }[m
[31m-  dest.once('close', onclose);[m
[31m-  function onfinish() {[m
[31m-    debug('onfinish');[m
[31m-    dest.removeListener('close', onclose);[m
[31m-    unpipe();[m
[31m-  }[m
[31m-  dest.once('finish', onfinish);[m
[31m-[m
[31m-  function unpipe() {[m
[31m-    debug('unpipe');[m
[31m-    src.unpipe(dest);[m
[31m-  }[m
[31m-[m
[31m-  // tell the dest that it's being piped to[m
[31m-  dest.emit('pipe', src);[m
[31m-[m
[31m-  // start the flow if it hasn't been started already.[m
[31m-  if (!state.flowing) {[m
[31m-    debug('pipe resume');[m
[31m-    src.resume();[m
[31m-  }[m
[31m-[m
[31m-  return dest;[m
[31m-};[m
[31m-[m
[31m-function pipeOnDrain(src) {[m
[31m-  return function() {[m
[31m-    var state = src._readableState;[m
[31m-    debug('pipeOnDrain', state.awaitDrain);[m
[31m-    if (state.awaitDrain)[m
[31m-      state.awaitDrain--;[m
[31m-    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {[m
[31m-      state.flowing = true;[m
[31m-      flow(src);[m
[31m-    }[m
[31m-  };[m
[31m-}[m
[31m-[m
[31m-[m
[31m-Readable.prototype.unpipe = function(dest) {[m
[31m-  var state = this._readableState;[m
[31m-[m
[31m-  // if we're not piping anywhere, then do nothing.[m
[31m-  if (state.pipesCount === 0)[m
[31m-    return this;[m
[31m-[m
[31m-  // just one destination.  most common case.[m
[31m-  if (state.pipesCount === 1) {[m
[31m-    // passed in one, but it's not the right one.[m
[31m-    if (dest && dest !== state.pipes)[m
[31m-      return this;[m
[31m-[m
[31m-    if (!dest)[m
[31m-      dest = state.pipes;[m
[31m-[m
[31m-    // got a match.[m
[31m-    state.pipes = null;[m
[31m-    state.pipesCount = 0;[m
[31m-    state.flowing = false;[m
[31m-    if (dest)[m
[31m-      dest.emit('unpipe', this);[m
[31m-    return this;[m
[31m-  }[m
[31m-[m
[31m-  // slow case. multiple pipe destinations.[m
[31m-[m
[31m-  if (!dest) {[m
[31m-    // remove all.[m
[31m-    var dests = state.pipes;[m
[31m-    var len = state.pipesCount;[m
[31m-    state.pipes = null;[m
[31m-    state.pipesCount = 0;[m
[31m-    state.flowing = false;[m
[31m-[m
[31m-    for (var i = 0; i < len; i++)[m
[31m-      dests[i].emit('unpipe', this);[m
[31m-    return this;[m
[31m-  }[m
[31m-[m
[31m-  // try to find the right one.[m
[31m-  var i = indexOf(state.pipes, dest);[m
[31m-  if (i === -1)[m
[31m-    return this;[m
[31m-[m
[31m-  state.pipes.splice(i, 1);[m
[31m-  state.pipesCount -= 1;[m
[31m-  if (state.pipesCount === 1)[m
[31m-    state.pipes = state.pipes[0];[m
[31m-[m
[31m-  dest.emit('unpipe', this);[m
[31m-[m
[31m-  return this;[m
[31m-};[m
[31m-[m
[31m-// set up data events if they are asked for[m
[31m-// Ensure readable listeners eventually get something[m
[31m-Readable.prototype.on = function(ev, fn) {[m
[31m-  var res = Stream.prototype.on.call(this, ev, fn);[m
[31m-[m
[31m-  // If listening to data, and it has not explicitly been paused,[m
[31m-  // then call resume to start the flow of data on the next tick.[m
[31m-  if (ev === 'data' && false !== this._readableState.flowing) {[m
[31m-    this.resume();[m
[31m-  }[m
[31m-[m
[31m-  if (ev === 'readable' && this.readable) {[m
[31m-    var state = this._readableState;[m
[31m-    if (!state.readableListening) {[m
[31m-      state.readableListening = true;[m
[31m-      state.emittedReadable = false;[m
[31m-      state.needReadable = true;[m
[31m-      if (!state.reading) {[m
[31m-        processNextTick(nReadingNextTick, this);[m
[31m-      } else if (state.length) {[m
[31m-        emitReadable(this, state);[m
[31m-      }[m
[31m-    }[m
[31m-  }[m
[31m-[m
[31m-  return res;[m
[31m-};[m
[31m-Readable.prototype.addListener = Readable.prototype.on;[m
[31m-[m
[31m-function nReadingNextTick(self) {[m
[31m-  debug('readable nexttick read 0');[m
[31m-  self.read(0);[m
[31m-}[m
[31m-[m
[31m-// pause() and resume() are remnants of the legacy readable stream API[m
[31m-// If the user uses them, then switch into old mode.[m
[31m-Readable.prototype.resume = function() {[m
[31m-  var state = this._readableState;[m
[31m-  if (!state.flowing) {[m
[31m-    debug('resume');[m
[31m-    state.flowing = true;[m
[31m-    resume(this, state);[m
[31m-  }[m
[31m-  return this;[m
[31m-};[m
[31m-[m
[31m-function resume(stream, state) {[m
[31m-  if (!state.resumeScheduled) {[m
[31m-    state.resumeScheduled = true;[m
[31m-    processNextTick(resume_, stream, state);[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-function resume_(stream, state) {[m
[31m-  if (!state.reading) {[m
[31m-    debug('resume read 0');[m
[31m-    stream.read(0);[m
[31m-  }[m
[31m-[m
[31m-  state.resumeScheduled = false;[m
[31m-  stream.emit('resume');[m
[31m-  flow(stream);[m
[31m-  if (state.flowing && !state.reading)[m
[31m-    stream.read(0);[m
[31m-}[m
[31m-[m
[31m-Readable.prototype.pause = function() {[m
[31m-  debug('call pause flowing=%j', this._readableState.flowing);[m
[31m-  if (false !== this._readableState.flowing) {[m
[31m-    debug('pause');[m
[31m-    this._readableState.flowing = false;[m
[31m-    this.emit('pause');[m
[31m-  }[m
[31m-  return this;[m
[31m-};[m
[31m-[m
[31m-function flow(stream) {[m
[31m-  var state = stream._readableState;[m
[31m-  debug('flow', state.flowing);[m
[31m-  if (state.flowing) {[m
[31m-    do {[m
[31m-      var chunk = stream.read();[m
[31m-    } while (null !== chunk && state.flowing);[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-// wrap an old-style stream as the async data source.[m
[31m-// This is *not* part of the readable stream interface.[m
[31m-// It is an ugly unfortunate mess of history.[m
[31m-Readable.prototype.wrap = function(stream) {[m
[31m-  var state = this._readableState;[m
[31m-  var paused = false;[m
[31m-[m
[31m-  var self = this;[m
[31m-  stream.on('end', function() {[m
[31m-    debug('wrapped end');[m
[31m-    if (state.decoder && !state.ended) {[m
[31m-      var chunk = state.decoder.end();[m
[31m-      if (chunk && chunk.length)[m
[31m-        self.push(chunk);[m
[31m-    }[m
[31m-[m
[31m-    self.push(null);[m
[31m-  });[m
[31m-[m
[31m-  stream.on('data', function(chunk) {[m
[31m-    debug('wrapped data');[m
[31m-    if (state.decoder)[m
[31m-      chunk = state.decoder.write(chunk);[m
[31m-[m
[31m-    // don't skip over falsy values in objectMode[m
[31m-    if (state.objectMode && (chunk === null || chunk === undefined))[m
[31m-      return;[m
[31m-    else if (!state.objectMode && (!chunk || !chunk.length))[m
[31m-      return;[m
[31m-[m
[31m-    var ret = self.push(chunk);[m
[31m-    if (!ret) {[m
[31m-      paused = true;[m
[31m-      stream.pause();[m
[31m-    }[m
[31m-  });[m
[31m-[m
[31m-  // proxy all the other methods.[m
[31m-  // important when wrapping filters and duplexes.[m
[31m-  for (var i in stream) {[m
[31m-    if (this[i] === undefined && typeof stream[i] === 'function') {[m
[31m-      this[i] = function(method) { return function() {[m
[31m-        return stream[method].apply(stream, arguments);[m
[31m-      }; }(i);[m
[31m-    }[m
[31m-  }[m
[31m-[m
[31m-  // proxy certain important events.[m
[31m-  var events = ['error', 'close', 'destroy', 'pause', 'resume'];[m
[31m-  forEach(events, function(ev) {[m
[31m-    stream.on(ev, self.emit.bind(self, ev));[m
[31m-  });[m
[31m-[m
[31m-  // when we try to consume some more bytes, simply unpause the[m
[31m-  // underlying stream.[m
[31m-  self._read = function(n) {[m
[31m-    debug('wrapped _read', n);[m
[31m-    if (paused) {[m
[31m-      paused = false;[m
[31m-      stream.resume();[m
[31m-    }[m
[31m-  };[m
[31m-[m
[31m-  return self;[m
[31m-};[m
[31m-[m
[31m-[m
[31m-// exposed for testing purposes only.[m
[31m-Readable._fromList = fromList;[m
[31m-[m
[31m-// Pluck off n bytes from an array of buffers.[m
[31m-// Length is the combined lengths of all the buffers in the list.[m
[31m-function fromList(n, state) {[m
[31m-  var list = state.buffer;[m
[31m-  var length = state.length;[m
[31m-  var stringMode = !!state.decoder;[m
[31m-  var objectMode = !!state.objectMode;[m
[31m-  var ret;[m
[31m-[m
[31m-  // nothing in the list, definitely empty.[m
[31m-  if (list.length === 0)[m
[31m-    return null;[m
[31m-[m
[31m-  if (length === 0)[m
[31m-    ret = null;[m
[31m-  else if (objectMode)[m
[31m-    ret = list.shift();[m
[31m-  else if (!n || n >= length) {[m
[31m-    // read it all, truncate the array.[m
[31m-    if (stringMode)[m
[31m-      ret = list.join('');[m
[31m-    else if (list.length === 1)[m
[31m-      ret = list[0];[m
[31m-    else[m
[31m-      ret = Buffer.concat(list, length);[m
[31m-    list.length = 0;[m
[31m-  } else {[m
[31m-    // read just some of it.[m
[31m-    if (n < list[0].length) {[m
[31m-      // just take a part of the first list item.[m
[31m-      // slice is the same for buffers and strings.[m
[31m-      var buf = list[0];[m
[31m-      ret = buf.slice(0, n);[m
[31m-      list[0] = buf.slice(n);[m
[31m-    } else if (n === list[0].length) {[m
[31m-      // first list is a perfect match[m
[31m-      ret = list.shift();[m
[31m-    } else {[m
[31m-      // complex case.[m
[31m-      // we have enough to cover it, but it spans past the first buffer.[m
[31m-      if (stringMode)[m
[31m-        ret = '';[m
[31m-      else[m
[31m-        ret = new Buffer(n);[m
[31m-[m
[31m-      var c = 0;[m
[31m-      for (var i = 0, l = list.length; i < l && c < n; i++) {[m
[31m-        var buf = list[0];[m
[31m-        var cpy = Math.min(n - c, buf.length);[m
[31m-[m
[31m-        if (stringMode)[m
[31m-          ret += buf.slice(0, cpy);[m
[31m-        else[m
[31m-          buf.copy(ret, c, 0, cpy);[m
[31m-[m
[31m-        if (cpy < buf.length)[m
[31m-          list[0] = buf.slice(cpy);[m
[31m-        else[m
[31m-          list.shift();[m
[31m-[m
[31m-        c += cpy;[m
[31m-      }[m
[31m-    }[m
[31m-  }[m
[31m-[m
[31m-  return ret;[m
[31m-}[m
[31m-[m
[31m-function endReadable(stream) {[m
[31m-  var state = stream._readableState;[m
[31m-[m
[31m-  // If we get here before consuming all the bytes, then that is a[m
[31m-  // bug in node.  Should never happen.[m
[31m-  if (state.length > 0)[m
[31m-    throw new Error('endReadable called on non-empty stream');[m
[31m-[m
[31m-  if (!state.endEmitted) {[m
[31m-    state.ended = true;[m
[31m-    processNextTick(endReadableNT, state, stream);[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-function endReadableNT(state, stream) {[m
[31m-  // Check that we didn't get one last unshift.[m
[31m-  if (!state.endEmitted && state.length === 0) {[m
[31m-    state.endEmitted = true;[m
[31m-    stream.readable = false;[m
[31m-    stream.emit('end');[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-function forEach (xs, f) {[m
[31m-  for (var i = 0, l = xs.length; i < l; i++) {[m
[31m-    f(xs[i], i);[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-function indexOf (xs, x) {[m
[31m-  for (var i = 0, l = xs.length; i < l; i++) {[m
[31m-    if (xs[i] === x) return i;[m
[31m-  }[m
[31m-  return -1;[m
[31m-}[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/lib/_stream_transform.js b/node_modules/mongodb/node_modules/readable-stream/lib/_stream_transform.js[m
[1mdeleted file mode 100644[m
[1mindex 3675d18..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/lib/_stream_transform.js[m
[1m+++ /dev/null[m
[36m@@ -1,197 +0,0 @@[m
[31m-// a transform stream is a readable/writable stream where you do[m
[31m-// something with the data.  Sometimes it's called a "filter",[m
[31m-// but that's not a great name for it, since that implies a thing where[m
[31m-// some bits pass through, and others are simply ignored.  (That would[m
[31m-// be a valid example of a transform, of course.)[m
[31m-//[m
[31m-// While the output is causally related to the input, it's not a[m
[31m-// necessarily symmetric or synchronous transformation.  For example,[m
[31m-// a zlib stream might take multiple plain-text writes(), and then[m
[31m-// emit a single compressed chunk some time in the future.[m
[31m-//[m
[31m-// Here's how this works:[m
[31m-//[m
[31m-// The Transform stream has all the aspects of the readable and writable[m
[31m-// stream classes.  When you write(chunk), that calls _write(chunk,cb)[m
[31m-// internally, and returns false if there's a lot of pending writes[m
[31m-// buffered up.  When you call read(), that calls _read(n) until[m
[31m-// there's enough pending readable data buffered up.[m
[31m-//[m
[31m-// In a transform stream, the written data is placed in a buffer.  When[m
[31m-// _read(n) is called, it transforms the queued up data, calling the[m
[31m-// buffered _write cb's as it consumes chunks.  If consuming a single[m
[31m-// written chunk would result in multiple output chunks, then the first[m
[31m-// outputted bit calls the readcb, and subsequent chunks just go into[m
[31m-// the read buffer, and will cause it to emit 'readable' if necessary.[m
[31m-//[m
[31m-// This way, back-pressure is actually determined by the reading side,[m
[31m-// since _read has to be called to start processing a new chunk.  However,[m
[31m-// a pathological inflate type of transform can cause excessive buffering[m
[31m-// here.  For example, imagine a stream where every byte of input is[m
[31m-// interpreted as an integer from 0-255, and then results in that many[m
[31m-// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in[m
[31m-// 1kb of data being output.  In this case, you could write a very small[m
[31m-// amount of input, and end up with a very large amount of output.  In[m
[31m-// such a pathological inflating mechanism, there'd be no way to tell[m
[31m-// the system to stop doing the transform.  A single 4MB write could[m
[31m-// cause the system to run out of memory.[m
[31m-//[m
[31m-// However, even in such a pathological case, only a single written chunk[m
[31m-// would be consumed, and then the rest would wait (un-transformed) until[m
[31m-// the results of the previous transformed chunk were consumed.[m
[31m-[m
[31m-'use strict';[m
[31m-[m
[31m-module.exports = Transform;[m
[31m-[m
[31m-var Duplex = require('./_stream_duplex');[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var util = require('core-util-is');[m
[31m-util.inherits = require('inherits');[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-util.inherits(Transform, Duplex);[m
[31m-[m
[31m-[m
[31m-function TransformState(stream) {[m
[31m-  this.afterTransform = function(er, data) {[m
[31m-    return afterTransform(stream, er, data);[m
[31m-  };[m
[31m-[m
[31m-  this.needTransform = false;[m
[31m-  this.transforming = false;[m
[31m-  this.writecb = null;[m
[31m-  this.writechunk = null;[m
[31m-}[m
[31m-[m
[31m-function afterTransform(stream, er, data) {[m
[31m-  var ts = stream._transformState;[m
[31m-  ts.transforming = false;[m
[31m-[m
[31m-  var cb = ts.writecb;[m
[31m-[m
[31m-  if (!cb)[m
[31m-    return stream.emit('error', new Error('no writecb in Transform class'));[m
[31m-[m
[31m-  ts.writechunk = null;[m
[31m-  ts.writecb = null;[m
[31m-[m
[31m-  if (data !== null && data !== undefined)[m
[31m-    stream.push(data);[m
[31m-[m
[31m-  if (cb)[m
[31m-    cb(er);[m
[31m-[m
[31m-  var rs = stream._readableState;[m
[31m-  rs.reading = false;[m
[31m-  if (rs.needReadable || rs.length < rs.highWaterMark) {[m
[31m-    stream._read(rs.highWaterMark);[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-[m
[31m-function Transform(options) {[m
[31m-  if (!(this instanceof Transform))[m
[31m-    return new Transform(options);[m
[31m-[m
[31m-  Duplex.call(this, options);[m
[31m-[m
[31m-  this._transformState = new TransformState(this);[m
[31m-[m
[31m-  // when the writable side finishes, then flush out anything remaining.[m
[31m-  var stream = this;[m
[31m-[m
[31m-  // start out asking for a readable event once data is transformed.[m
[31m-  this._readableState.needReadable = true;[m
[31m-[m
[31m-  // we have implemented the _read method, and done the other things[m
[31m-  // that Readable wants before the first _read call, so unset the[m
[31m-  // sync guard flag.[m
[31m-  this._readableState.sync = false;[m
[31m-[m
[31m-  if (options) {[m
[31m-    if (typeof options.transform === 'function')[m
[31m-      this._transform = options.transform;[m
[31m-[m
[31m-    if (typeof options.flush === 'function')[m
[31m-      this._flush = options.flush;[m
[31m-  }[m
[31m-[m
[31m-  this.once('prefinish', function() {[m
[31m-    if (typeof this._flush === 'function')[m
[31m-      this._flush(function(er) {[m
[31m-        done(stream, er);[m
[31m-      });[m
[31m-    else[m
[31m-      done(stream);[m
[31m-  });[m
[31m-}[m
[31m-[m
[31m-Transform.prototype.push = function(chunk, encoding) {[m
[31m-  this._transformState.needTransform = false;[m
[31m-  return Duplex.prototype.push.call(this, chunk, encoding);[m
[31m-};[m
[31m-[m
[31m-// This is the part where you do stuff![m
[31m-// override this function in implementation classes.[m
[31m-// 'chunk' is an input chunk.[m
[31m-//[m
[31m-// Call `push(newChunk)` to pass along transformed output[m
[31m-// to the readable side.  You may call 'push' zero or more times.[m
[31m-//[m
[31m-// Call `cb(err)` when you are done with this chunk.  If you pass[m
[31m-// an error, then that'll put the hurt on the whole operation.  If you[m
[31m-// never call cb(), then you'll never get another chunk.[m
[31m-Transform.prototype._transform = function(chunk, encoding, cb) {[m
[31m-  throw new Error('not implemented');[m
[31m-};[m
[31m-[m
[31m-Transform.prototype._write = function(chunk, encoding, cb) {[m
[31m-  var ts = this._transformState;[m
[31m-  ts.writecb = cb;[m
[31m-  ts.writechunk = chunk;[m
[31m-  ts.writeencoding = encoding;[m
[31m-  if (!ts.transforming) {[m
[31m-    var rs = this._readableState;[m
[31m-    if (ts.needTransform ||[m
[31m-        rs.needReadable ||[m
[31m-        rs.length < rs.highWaterMark)[m
[31m-      this._read(rs.highWaterMark);[m
[31m-  }[m
[31m-};[m
[31m-[m
[31m-// Doesn't matter what the args are here.[m
[31m-// _transform does all the work.[m
[31m-// That we got here means that the readable side wants more data.[m
[31m-Transform.prototype._read = function(n) {[m
[31m-  var ts = this._transformState;[m
[31m-[m
[31m-  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {[m
[31m-    ts.transforming = true;[m
[31m-    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);[m
[31m-  } else {[m
[31m-    // mark that we need a transform, so that any data that comes in[m
[31m-    // will get processed, now that we've asked for it.[m
[31m-    ts.needTransform = true;[m
[31m-  }[m
[31m-};[m
[31m-[m
[31m-[m
[31m-function done(stream, er) {[m
[31m-  if (er)[m
[31m-    return stream.emit('error', er);[m
[31m-[m
[31m-  // if there's nothing in the write buffer, then that means[m
[31m-  // that nothing more will ever be provided[m
[31m-  var ws = stream._writableState;[m
[31m-  var ts = stream._transformState;[m
[31m-[m
[31m-  if (ws.length)[m
[31m-    throw new Error('calling transform done when ws.length != 0');[m
[31m-[m
[31m-  if (ts.transforming)[m
[31m-    throw new Error('calling transform done when still transforming');[m
[31m-[m
[31m-  return stream.push(null);[m
[31m-}[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/lib/_stream_writable.js b/node_modules/mongodb/node_modules/readable-stream/lib/_stream_writable.js[m
[1mdeleted file mode 100644[m
[1mindex 23a2ba2..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/lib/_stream_writable.js[m
[1m+++ /dev/null[m
[36m@@ -1,527 +0,0 @@[m
[31m-// A bit simpler than readable streams.[m
[31m-// Implement an async ._write(chunk, encoding, cb), and it'll handle all[m
[31m-// the drain event emission and buffering.[m
[31m-[m
[31m-'use strict';[m
[31m-[m
[31m-module.exports = Writable;[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var processNextTick = require('process-nextick-args');[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var Buffer = require('buffer').Buffer;[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-Writable.WritableState = WritableState;[m
[31m-[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var util = require('core-util-is');[m
[31m-util.inherits = require('inherits');[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var internalUtil = {[m
[31m-  deprecate: require('util-deprecate')[m
[31m-};[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-[m
[31m-[m
[31m-/*<replacement>*/[m
[31m-var Stream;[m
[31m-(function (){try{[m
[31m-  Stream = require('st' + 'ream');[m
[31m-}catch(_){}finally{[m
[31m-  if (!Stream)[m
[31m-    Stream = require('events').EventEmitter;[m
[31m-}}())[m
[31m-/*</replacement>*/[m
[31m-[m
[31m-var Buffer = require('buffer').Buffer;[m
[31m-[m
[31m-util.inherits(Writable, Stream);[m
[31m-[m
[31m-function nop() {}[m
[31m-[m
[31m-function WriteReq(chunk, encoding, cb) {[m
[31m-  this.chunk = chunk;[m
[31m-  this.encoding = encoding;[m
[31m-  this.callback = cb;[m
[31m-  this.next = null;[m
[31m-}[m
[31m-[m
[31m-function WritableState(options, stream) {[m
[31m-  var Duplex = require('./_stream_duplex');[m
[31m-[m
[31m-  options = options || {};[m
[31m-[m
[31m-  // object stream flag to indicate whether or not this stream[m
[31m-  // contains buffers or objects.[m
[31m-  this.objectMode = !!options.objectMode;[m
[31m-[m
[31m-  if (stream instanceof Duplex)[m
[31m-    this.objectMode = this.objectMode || !!options.writableObjectMode;[m
[31m-[m
[31m-  // the point at which write() starts returning false[m
[31m-  // Note: 0 is a valid value, means that we always return false if[m
[31m-  // the entire buffer is not flushed immediately on write()[m
[31m-  var hwm = options.highWaterMark;[m
[31m-  var defaultHwm = this.objectMode ? 16 : 16 * 1024;[m
[31m-  this.highWaterMark = (hwm || hwm === 0) ? hwm : defaultHwm;[m
[31m-[m
[31m-  // cast to ints.[m
[31m-  this.highWaterMark = ~~this.highWaterMark;[m
[31m-[m
[31m-  this.needDrain = false;[m
[31m-  // at the start of calling end()[m
[31m-  this.ending = false;[m
[31m-  // when end() has been called, and returned[m
[31m-  this.ended = false;[m
[31m-  // when 'finish' is emitted[m
[31m-  this.finished = false;[m
[31m-[m
[31m-  // should we decode strings into buffers before passing to _write?[m
[31m-  // this is here so that some node-core streams can optimize string[m
[31m-  // handling at a lower level.[m
[31m-  var noDecode = options.decodeStrings === false;[m
[31m-  this.decodeStrings = !noDecode;[m
[31m-[m
[31m-  // Crypto is kind of old and crusty.  Historically, its default string[m
[31m-  // encoding is 'binary' so we have to make this configurable.[m
[31m-  // Everything else in the universe uses 'utf8', though.[m
[31m-  this.defaultEncoding = options.defaultEncoding || 'utf8';[m
[31m-[m
[31m-  // not an actual buffer we keep track of, but a measurement[m
[31m-  // of how much we're waiting to get pushed to some underlying[m
[31m-  // socket or file.[m
[31m-  this.length = 0;[m
[31m-[m
[31m-  // a flag to see when we're in the middle of a write.[m
[31m-  this.writing = false;[m
[31m-[m
[31m-  // when true all writes will be buffered until .uncork() call[m
[31m-  this.corked = 0;[m
[31m-[m
[31m-  // a flag to be able to tell if the onwrite cb is called immediately,[m
[31m-  // or on a later tick.  We set this to true at first, because any[m
[31m-  // actions that shouldn't happen until "later" should generally also[m
[31m-  // not happen before the first write call.[m
[31m-  this.sync = true;[m
[31m-[m
[31m-  // a flag to know if we're processing previously buffered items, which[m
[31m-  // may call the _write() callback in the same tick, so that we don't[m
[31m-  // end up in an overlapped onwrite situation.[m
[31m-  this.bufferProcessing = false;[m
[31m-[m
[31m-  // the callback that's passed to _write(chunk,cb)[m
[31m-  this.onwrite = function(er) {[m
[31m-    onwrite(stream, er);[m
[31m-  };[m
[31m-[m
[31m-  // the callback that the user supplies to write(chunk,encoding,cb)[m
[31m-  this.writecb = null;[m
[31m-[m
[31m-  // the amount that is being written when _write is called.[m
[31m-  this.writelen = 0;[m
[31m-[m
[31m-  this.bufferedRequest = null;[m
[31m-  this.lastBufferedRequest = null;[m
[31m-[m
[31m-  // number of pending user-supplied write callbacks[m
[31m-  // this must be 0 before 'finish' can be emitted[m
[31m-  this.pendingcb = 0;[m
[31m-[m
[31m-  // emit prefinish if the only thing we're waiting for is _write cbs[m
[31m-  // This is relevant for synchronous Transform streams[m
[31m-  this.prefinished = false;[m
[31m-[m
[31m-  // True if the error was already emitted and should not be thrown again[m
[31m-  this.errorEmitted = false;[m
[31m-}[m
[31m-[m
[31m-WritableState.prototype.getBuffer = function writableStateGetBuffer() {[m
[31m-  var current = this.bufferedRequest;[m
[31m-  var out = [];[m
[31m-  while (current) {[m
[31m-    out.push(current);[m
[31m-    current = current.next;[m
[31m-  }[m
[31m-  return out;[m
[31m-};[m
[31m-[m
[31m-(function (){try {[m
[31m-Object.defineProperty(WritableState.prototype, 'buffer', {[m
[31m-  get: internalUtil.deprecate(function() {[m
[31m-    return this.getBuffer();[m
[31m-  }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' +[m
[31m-     'instead.')[m
[31m-});[m
[31m-}catch(_){}}());[m
[31m-[m
[31m-[m
[31m-function Writable(options) {[m
[31m-  var Duplex = require('./_stream_duplex');[m
[31m-[m
[31m-  // Writable ctor is applied to Duplexes, though they're not[m
[31m-  // instanceof Writable, they're instanceof Readable.[m
[31m-  if (!(this instanceof Writable) && !(this instanceof Duplex))[m
[31m-    return new Writable(options);[m
[31m-[m
[31m-  this._writableState = new WritableState(options, this);[m
[31m-[m
[31m-  // legacy.[m
[31m-  this.writable = true;[m
[31m-[m
[31m-  if (options) {[m
[31m-    if (typeof options.write === 'function')[m
[31m-      this._write = options.write;[m
[31m-[m
[31m-    if (typeof options.writev === 'function')[m
[31m-      this._writev = options.writev;[m
[31m-  }[m
[31m-[m
[31m-  Stream.call(this);[m
[31m-}[m
[31m-[m
[31m-// Otherwise people can pipe Writable streams, which is just wrong.[m
[31m-Writable.prototype.pipe = function() {[m
[31m-  this.emit('error', new Error('Cannot pipe. Not readable.'));[m
[31m-};[m
[31m-[m
[31m-[m
[31m-function writeAfterEnd(stream, cb) {[m
[31m-  var er = new Error('write after end');[m
[31m-  // TODO: defer error events consistently everywhere, not just the cb[m
[31m-  stream.emit('error', er);[m
[31m-  processNextTick(cb, er);[m
[31m-}[m
[31m-[m
[31m-// If we get something that is not a buffer, string, null, or undefined,[m
[31m-// and we're not in objectMode, then that's an error.[m
[31m-// Otherwise stream chunks are all considered to be of length=1, and the[m
[31m-// watermarks determine how many objects to keep in the buffer, rather than[m
[31m-// how many bytes or characters.[m
[31m-function validChunk(stream, state, chunk, cb) {[m
[31m-  var valid = true;[m
[31m-[m
[31m-  if (!(Buffer.isBuffer(chunk)) &&[m
[31m-      typeof chunk !== 'string' &&[m
[31m-      chunk !== null &&[m
[31m-      chunk !== undefined &&[m
[31m-      !state.objectMode) {[m
[31m-    var er = new TypeError('Invalid non-string/buffer chunk');[m
[31m-    stream.emit('error', er);[m
[31m-    processNextTick(cb, er);[m
[31m-    valid = false;[m
[31m-  }[m
[31m-  return valid;[m
[31m-}[m
[31m-[m
[31m-Writable.prototype.write = function(chunk, encoding, cb) {[m
[31m-  var state = this._writableState;[m
[31m-  var ret = false;[m
[31m-[m
[31m-  if (typeof encoding === 'function') {[m
[31m-    cb = encoding;[m
[31m-    encoding = null;[m
[31m-  }[m
[31m-[m
[31m-  if (Buffer.isBuffer(chunk))[m
[31m-    encoding = 'buffer';[m
[31m-  else if (!encoding)[m
[31m-    encoding = state.defaultEncoding;[m
[31m-[m
[31m-  if (typeof cb !== 'function')[m
[31m-    cb = nop;[m
[31m-[m
[31m-  if (state.ended)[m
[31m-    writeAfterEnd(this, cb);[m
[31m-  else if (validChunk(this, state, chunk, cb)) {[m
[31m-    state.pendingcb++;[m
[31m-    ret = writeOrBuffer(this, state, chunk, encoding, cb);[m
[31m-  }[m
[31m-[m
[31m-  return ret;[m
[31m-};[m
[31m-[m
[31m-Writable.prototype.cork = function() {[m
[31m-  var state = this._writableState;[m
[31m-[m
[31m-  state.corked++;[m
[31m-};[m
[31m-[m
[31m-Writable.prototype.uncork = function() {[m
[31m-  var state = this._writableState;[m
[31m-[m
[31m-  if (state.corked) {[m
[31m-    state.corked--;[m
[31m-[m
[31m-    if (!state.writing &&[m
[31m-        !state.corked &&[m
[31m-        !state.finished &&[m
[31m-        !state.bufferProcessing &&[m
[31m-        state.bufferedRequest)[m
[31m-      clearBuffer(this, state);[m
[31m-  }[m
[31m-};[m
[31m-[m
[31m-Writable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {[m
[31m-  // node::ParseEncoding() requires lower case.[m
[31m-  if (typeof encoding === 'string')[m
[31m-    encoding = encoding.toLowerCase();[m
[31m-  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64',[m
[31m-'ucs2', 'ucs-2','utf16le', 'utf-16le', 'raw'][m
[31m-.indexOf((encoding + '').toLowerCase()) > -1))[m
[31m-    throw new TypeError('Unknown encoding: ' + encoding);[m
[31m-  this._writableState.defaultEncoding = encoding;[m
[31m-};[m
[31m-[m
[31m-function decodeChunk(state, chunk, encoding) {[m
[31m-  if (!state.objectMode &&[m
[31m-      state.decodeStrings !== false &&[m
[31m-      typeof chunk === 'string') {[m
[31m-    chunk = new Buffer(chunk, encoding);[m
[31m-  }[m
[31m-  return chunk;[m
[31m-}[m
[31m-[m
[31m-// if we're already writing something, then just put this[m
[31m-// in the queue, and wait our turn.  Otherwise, call _write[m
[31m-// If we return false, then we need a drain event, so set that flag.[m
[31m-function writeOrBuffer(stream, state, chunk, encoding, cb) {[m
[31m-  chunk = decodeChunk(state, chunk, encoding);[m
[31m-[m
[31m-  if (Buffer.isBuffer(chunk))[m
[31m-    encoding = 'buffer';[m
[31m-  var len = state.objectMode ? 1 : chunk.length;[m
[31m-[m
[31m-  state.length += len;[m
[31m-[m
[31m-  var ret = state.length < state.highWaterMark;[m
[31m-  // we must ensure that previous needDrain will not be reset to false.[m
[31m-  if (!ret)[m
[31m-    state.needDrain = true;[m
[31m-[m
[31m-  if (state.writing || state.corked) {[m
[31m-    var last = state.lastBufferedRequest;[m
[31m-    state.lastBufferedRequest = new WriteReq(chunk, encoding, cb);[m
[31m-    if (last) {[m
[31m-      last.next = state.lastBufferedRequest;[m
[31m-    } else {[m
[31m-      state.bufferedRequest = state.lastBufferedRequest;[m
[31m-    }[m
[31m-  } else {[m
[31m-    doWrite(stream, state, false, len, chunk, encoding, cb);[m
[31m-  }[m
[31m-[m
[31m-  return ret;[m
[31m-}[m
[31m-[m
[31m-function doWrite(stream, state, writev, len, chunk, encoding, cb) {[m
[31m-  state.writelen = len;[m
[31m-  state.writecb = cb;[m
[31m-  state.writing = true;[m
[31m-  state.sync = true;[m
[31m-  if (writev)[m
[31m-    stream._writev(chunk, state.onwrite);[m
[31m-  else[m
[31m-    stream._write(chunk, encoding, state.onwrite);[m
[31m-  state.sync = false;[m
[31m-}[m
[31m-[m
[31m-function onwriteError(stream, state, sync, er, cb) {[m
[31m-  --state.pendingcb;[m
[31m-  if (sync)[m
[31m-    processNextTick(cb, er);[m
[31m-  else[m
[31m-    cb(er);[m
[31m-[m
[31m-  stream._writableState.errorEmitted = true;[m
[31m-  stream.emit('error', er);[m
[31m-}[m
[31m-[m
[31m-function onwriteStateUpdate(state) {[m
[31m-  state.writing = false;[m
[31m-  state.writecb = null;[m
[31m-  state.length -= state.writelen;[m
[31m-  state.writelen = 0;[m
[31m-}[m
[31m-[m
[31m-function onwrite(stream, er) {[m
[31m-  var state = stream._writableState;[m
[31m-  var sync = state.sync;[m
[31m-  var cb = state.writecb;[m
[31m-[m
[31m-  onwriteStateUpdate(state);[m
[31m-[m
[31m-  if (er)[m
[31m-    onwriteError(stream, state, sync, er, cb);[m
[31m-  else {[m
[31m-    // Check if we're actually ready to finish, but don't emit yet[m
[31m-    var finished = needFinish(state);[m
[31m-[m
[31m-    if (!finished &&[m
[31m-        !state.corked &&[m
[31m-        !state.bufferProcessing &&[m
[31m-        state.bufferedRequest) {[m
[31m-      clearBuffer(stream, state);[m
[31m-    }[m
[31m-[m
[31m-    if (sync) {[m
[31m-      processNextTick(afterWrite, stream, state, finished, cb);[m
[31m-    } else {[m
[31m-      afterWrite(stream, state, finished, cb);[m
[31m-    }[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-function afterWrite(stream, state, finished, cb) {[m
[31m-  if (!finished)[m
[31m-    onwriteDrain(stream, state);[m
[31m-  state.pendingcb--;[m
[31m-  cb();[m
[31m-  finishMaybe(stream, state);[m
[31m-}[m
[31m-[m
[31m-// Must force callback to be called on nextTick, so that we don't[m
[31m-// emit 'drain' before the write() consumer gets the 'false' return[m
[31m-// value, and has a chance to attach a 'drain' listener.[m
[31m-function onwriteDrain(stream, state) {[m
[31m-  if (state.length === 0 && state.needDrain) {[m
[31m-    state.needDrain = false;[m
[31m-    stream.emit('drain');[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-[m
[31m-// if there's something in the buffer waiting, then process it[m
[31m-function clearBuffer(stream, state) {[m
[31m-  state.bufferProcessing = true;[m
[31m-  var entry = state.bufferedRequest;[m
[31m-[m
[31m-  if (stream._writev && entry && entry.next) {[m
[31m-    // Fast case, write everything using _writev()[m
[31m-    var buffer = [];[m
[31m-    var cbs = [];[m
[31m-    while (entry) {[m
[31m-      cbs.push(entry.callback);[m
[31m-      buffer.push(entry);[m
[31m-      entry = entry.next;[m
[31m-    }[m
[31m-[m
[31m-    // count the one we are adding, as well.[m
[31m-    // TODO(isaacs) clean this up[m
[31m-    state.pendingcb++;[m
[31m-    state.lastBufferedRequest = null;[m
[31m-    doWrite(stream, state, true, state.length, buffer, '', function(err) {[m
[31m-      for (var i = 0; i < cbs.length; i++) {[m
[31m-        state.pendingcb--;[m
[31m-        cbs[i](err);[m
[31m-      }[m
[31m-    });[m
[31m-[m
[31m-    // Clear buffer[m
[31m-  } else {[m
[31m-    // Slow case, write chunks one-by-one[m
[31m-    while (entry) {[m
[31m-      var chunk = entry.chunk;[m
[31m-      var encoding = entry.encoding;[m
[31m-      var cb = entry.callback;[m
[31m-      var len = state.objectMode ? 1 : chunk.length;[m
[31m-[m
[31m-      doWrite(stream, state, false, len, chunk, encoding, cb);[m
[31m-      entry = entry.next;[m
[31m-      // if we didn't call the onwrite immediately, then[m
[31m-      // it means that we need to wait until it does.[m
[31m-      // also, that means that the chunk and cb are currently[m
[31m-      // being processed, so move the buffer counter past them.[m
[31m-      if (state.writing) {[m
[31m-        break;[m
[31m-      }[m
[31m-    }[m
[31m-[m
[31m-    if (entry === null)[m
[31m-      state.lastBufferedRequest = null;[m
[31m-  }[m
[31m-  state.bufferedRequest = entry;[m
[31m-  state.bufferProcessing = false;[m
[31m-}[m
[31m-[m
[31m-Writable.prototype._write = function(chunk, encoding, cb) {[m
[31m-  cb(new Error('not implemented'));[m
[31m-};[m
[31m-[m
[31m-Writable.prototype._writev = null;[m
[31m-[m
[31m-Writable.prototype.end = function(chunk, encoding, cb) {[m
[31m-  var state = this._writableState;[m
[31m-[m
[31m-  if (typeof chunk === 'function') {[m
[31m-    cb = chunk;[m
[31m-    chunk = null;[m
[31m-    encoding = null;[m
[31m-  } else if (typeof encoding === 'function') {[m
[31m-    cb = encoding;[m
[31m-    encoding = null;[m
[31m-  }[m
[31m-[m
[31m-  if (chunk !== null && chunk !== undefined)[m
[31m-    this.write(chunk, encoding);[m
[31m-[m
[31m-  // .end() fully uncorks[m
[31m-  if (state.corked) {[m
[31m-    state.corked = 1;[m
[31m-    this.uncork();[m
[31m-  }[m
[31m-[m
[31m-  // ignore unnecessary end() calls.[m
[31m-  if (!state.ending && !state.finished)[m
[31m-    endWritable(this, state, cb);[m
[31m-};[m
[31m-[m
[31m-[m
[31m-function needFinish(state) {[m
[31m-  return (state.ending &&[m
[31m-          state.length === 0 &&[m
[31m-          state.bufferedRequest === null &&[m
[31m-          !state.finished &&[m
[31m-          !state.writing);[m
[31m-}[m
[31m-[m
[31m-function prefinish(stream, state) {[m
[31m-  if (!state.prefinished) {[m
[31m-    state.prefinished = true;[m
[31m-    stream.emit('prefinish');[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-function finishMaybe(stream, state) {[m
[31m-  var need = needFinish(state);[m
[31m-  if (need) {[m
[31m-    if (state.pendingcb === 0) {[m
[31m-      prefinish(stream, state);[m
[31m-      state.finished = true;[m
[31m-      stream.emit('finish');[m
[31m-    } else {[m
[31m-      prefinish(stream, state);[m
[31m-    }[m
[31m-  }[m
[31m-  return need;[m
[31m-}[m
[31m-[m
[31m-function endWritable(stream, state, cb) {[m
[31m-  state.ending = true;[m
[31m-  finishMaybe(stream, state);[m
[31m-  if (cb) {[m
[31m-    if (state.finished)[m
[31m-      processNextTick(cb);[m
[31m-    else[m
[31m-      stream.once('finish', cb);[m
[31m-  }[m
[31m-  state.ended = true;[m
[31m-}[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/package.json b/node_modules/mongodb/node_modules/readable-stream/package.json[m
[1mdeleted file mode 100644[m
[1mindex 15d3708..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/package.json[m
[1m+++ /dev/null[m
[36m@@ -1,100 +0,0 @@[m
[31m-{[m
[31m-  "_args": [[m
[31m-    [[m
[31m-      "readable-stream@latest",[m
[31m-      "C:\\Users\\Silken\\node\\IDE-A\\node_modules\\mongodb"[m
[31m-    ][m
[31m-  ],[m
[31m-  "_from": "readable-stream@latest",[m
[31m-  "_id": "readable-stream@2.0.4",[m
[31m-  "_inCache": true,[m
[31m-  "_location": "/mongodb/readable-stream",[m
[31m-  "_nodeVersion": "4.1.1",[m
[31m-  "_npmUser": {[m
[31m-    "email": "calvin.metcalf@gmail.com",[m
[31m-    "name": "cwmma"[m
[31m-  },[m
[31m-  "_npmVersion": "2.14.4",[m
[31m-  "_phantomChildren": {},[m
[31m-  "_requested": {[m
[31m-    "name": "readable-stream",[m
[31m-    "raw": "readable-stream@latest",[m
[31m-    "rawSpec": "latest",[m
[31m-    "scope": null,[m
[31m-    "spec": "latest",[m
[31m-    "type": "tag"[m
[31m-  },[m
[31m-  "_requiredBy": [[m
[31m-    "/mongodb"[m
[31m-  ],[m
[31m-  "_resolved": "https://registry.npmjs.org/readable-stream/-/readable-stream-2.0.4.tgz",[m
[31m-  "_shasum": "2523ef27ffa339d7ba9da8603f2d0599d06edbd8",[m
[31m-  "_shrinkwrap": null,[m
[31m-  "_spec": "readable-stream@latest",[m
[31m-  "_where": "C:\\Users\\Silken\\node\\IDE-A\\node_modules\\mongodb",[m
[31m-  "browser": {[m
[31m-    "util": false[m
[31m-  },[m
[31m-  "bugs": {[m
[31m-    "url": "https://github.com/nodejs/readable-stream/issues"[m
[31m-  },[m
[31m-  "dependencies": {[m
[31m-    "core-util-is": "~1.0.0",[m
[31m-    "inherits": "~2.0.1",[m
[31m-    "isarray": "0.0.1",[m
[31m-    "process-nextick-args": "~1.0.0",[m
[31m-    "string_decoder": "~0.10.x",[m
[31m-    "util-deprecate": "~1.0.1"[m
[31m-  },[m
[31m-  "description": "Streams3, a user-land copy of the stream library from iojs v2.x",[m
[31m-  "devDependencies": {[m
[31m-    "tap": "~0.2.6",[m
[31m-    "tape": "~4.0.0",[m
[31m-    "zuul": "~3.0.0"[m
[31m-  },[m
[31m-  "directories": {},[m
[31m-  "dist": {[m
[31m-    "shasum": "2523ef27ffa339d7ba9da8603f2d0599d06edbd8",[m
[31m-    "tarball": "http://registry.npmjs.org/readable-stream/-/readable-stream-2.0.4.tgz"[m
[31m-  },[m
[31m-  "gitHead": "f2a4f4a659bacbe742a494b7d2aede64fab0d4f9",[m
[31m-  "homepage": "https://github.com/nodejs/readable-stream#readme",[m
[31m-  "installable": true,[m
[31m-  "keywords": [[m
[31m-    "pipe",[m
[31m-    "readable",[m
[31m-    "stream"[m
[31m-  ],[m
[31m-  "license": "MIT",[m
[31m-  "main": "readable.js",[m
[31m-  "maintainers": [[m
[31m-    {[m
[31m-      "name": "isaacs",[m
[31m-      "email": "isaacs@npmjs.com"[m
[31m-    },[m
[31m-    {[m
[31m-      "name": "tootallnate",[m
[31m-      "email": "nathan@tootallnate.net"[m
[31m-    },[m
[31m-    {[m
[31m-      "name": "rvagg",[m
[31m-      "email": "rod@vagg.org"[m
[31m-    },[m
[31m-    {[m
[31m-      "name": "cwmma",[m
[31m-      "email": "calvin.metcalf@gmail.com"[m
[31m-    }[m
[31m-  ],[m
[31m-  "name": "readable-stream",[m
[31m-  "optionalDependencies": {},[m
[31m-  "repository": {[m
[31m-    "type": "git",[m
[31m-    "url": "git://github.com/nodejs/readable-stream.git"[m
[31m-  },[m
[31m-  "scripts": {[m
[31m-    "browser": "npm run write-zuul && zuul -- test/browser.js",[m
[31m-    "test": "tap test/parallel/*.js",[m
[31m-    "write-zuul": "printf \"ui: tape\nbrowsers:\n  - name: $BROWSER_NAME\n    version: $BROWSER_VERSION\n\">.zuul.yml"[m
[31m-  },[m
[31m-  "version": "2.0.4"[m
[31m-}[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/passthrough.js b/node_modules/mongodb/node_modules/readable-stream/passthrough.js[m
[1mdeleted file mode 100644[m
[1mindex 27e8d8a..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/passthrough.js[m
[1m+++ /dev/null[m
[36m@@ -1 +0,0 @@[m
[31m-module.exports = require("./lib/_stream_passthrough.js")[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/readable.js b/node_modules/mongodb/node_modules/readable-stream/readable.js[m
[1mdeleted file mode 100644[m
[1mindex 6222a57..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/readable.js[m
[1m+++ /dev/null[m
[36m@@ -1,12 +0,0 @@[m
[31m-var Stream = (function (){[m
[31m-  try {[m
[31m-    return require('st' + 'ream'); // hack to fix a circular dependency issue when used with browserify[m
[31m-  } catch(_){}[m
[31m-}());[m
[31m-exports = module.exports = require('./lib/_stream_readable.js');[m
[31m-exports.Stream = Stream || exports;[m
[31m-exports.Readable = exports;[m
[31m-exports.Writable = require('./lib/_stream_writable.js');[m
[31m-exports.Duplex = require('./lib/_stream_duplex.js');[m
[31m-exports.Transform = require('./lib/_stream_transform.js');[m
[31m-exports.PassThrough = require('./lib/_stream_passthrough.js');[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/transform.js b/node_modules/mongodb/node_modules/readable-stream/transform.js[m
[1mdeleted file mode 100644[m
[1mindex 5d482f0..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/transform.js[m
[1m+++ /dev/null[m
[36m@@ -1 +0,0 @@[m
[31m-module.exports = require("./lib/_stream_transform.js")[m
[1mdiff --git a/node_modules/mongodb/node_modules/readable-stream/writable.js b/node_modules/mongodb/node_modules/readable-stream/writable.js[m
[1mdeleted file mode 100644[m
[1mindex e1e9efd..0000000[m
[1m--- a/node_modules/mongodb/node_modules/readable-stream/writable.js[m
[1m+++ /dev/null[m
[36m@@ -1 +0,0 @@[m
[31m-module.exports = require("./lib/_stream_writable.js")[m
[1mdiff --git a/node_modules/mongodb/package.json b/node_modules/mongodb/package.json[m
[1mindex 0586035..dfb2a14 100644[m
[1m--- a/node_modules/mongodb/package.json[m
[1m+++ b/node_modules/mongodb/package.json[m
[36m@@ -1,61 +1,23 @@[m
 {[m
[31m-  "_args": [[m
[31m-    [[m
[31m-      "mongodb@~1.4",[m
[31m-      "C:\\Users\\Silken\\node\\IDE-A"[m
[31m-    ][m
[31m-  ],[m
[31m-  "_from": "mongodb@>=1.4.0 <1.5.0",[m
[31m-  "_id": "mongodb@1.4.39",[m
[31m-  "_inCache": true,[m
[31m-  "_location": "/mongodb",[m
[31m-  "_nodeVersion": "2.3.3",[m
[31m-  "_npmUser": {[m
[31m-    "email": "christkv@gmail.com",[m
[31m-    "name": "christkv"[m
[31m-  },[m
[31m-  "_npmVersion": "2.11.3",[m
[31m-  "_phantomChildren": {[m
[31m-    "core-util-is": "1.0.2",[m
[31m-    "inherits": "2.0.1",[m
[31m-    "isarray": "0.0.1",[m
[31m-    "nan": "1.8.4",[m
[31m-    "process-nextick-args": "1.0.3",[m
[31m-    "string_decoder": "0.10.31",[m
[31m-    "util-deprecate": "1.0.2"[m
[31m-  },[m
[31m-  "_requested": {[m
[31m-    "name": "mongodb",[m
[31m-    "raw": "mongodb@~1.4",[m
[31m-    "rawSpec": "~1.4",[m
[31m-    "scope": null,[m
[31m-    "spec": ">=1.4.0 <1.5.0",[m
[31m-    "type": "range"[m
[31m-  },[m
[31m-  "_requiredBy": [[m
[31m-    "/"[m
[32m+[m[32m  "name": "mongodb",[m
[32m+[m[32m  "description": "A node.js driver for MongoDB",[m
[32m+[m[32m  "keywords": [[m
[32m+[m[32m    "mongodb",[m
[32m+[m[32m    "mongo",[m
[32m+[m[32m    "driver",[m
[32m+[m[32m    "db"[m
   ],[m
[31m-  "_resolved": "https://registry.npmjs.org/mongodb/-/mongodb-1.4.39.tgz",[m
[31m-  "_shasum": "f5b25c7f7df06c968cd5d3c68280adc9a6404591",[m
[31m-  "_shrinkwrap": null,[m
[31m-  "_spec": "mongodb@~1.4",[m
[31m-  "_where": "C:\\Users\\Silken\\node\\IDE-A",[m
[32m+[m[32m  "version": "1.4.39",[m
   "author": {[m
[31m-    "email": "christkv@gmail.com",[m
[31m-    "name": "Christian Amor Kvalheim"[m
[31m-  },[m
[31m-  "bugs": {[m
[31m-    "url": "http://github.com/mongodb/node-mongodb-native/issues"[m
[31m-  },[m
[31m-  "config": {[m
[31m-    "native": false[m
[32m+[m[32m    "name": "Christian Amor Kvalheim",[m
[32m+[m[32m    "email": "christkv@gmail.com"[m
   },[m
   "contributors": [[m
     {[m
[31m-      "name": "Shimon Doodkin"[m
[32m+[m[32m      "name": "Aaron Heckmann"[m
     },[m
     {[m
[31m-      "name": "Aaron Heckmann"[m
[32m+[m[32m      "name": "Christoph Pojer"[m
     },[m
     {[m
       "name": "Pau Ramon Revilla"[m
[36m@@ -133,7 +95,7 @@[m
       "name": "Alex Gorbatchev"[m
     },[m
     {[m
[31m-      "name": "Christoph Pojer"[m
[32m+[m[32m      "name": "Shimon Doodkin"[m
     },[m
     {[m
       "name": "Kyle Mueller"[m
[36m@@ -214,70 +176,77 @@[m
       "name": "Samantha Ritter"[m
     }[m
   ],[m
[32m+[m[32m  "repository": {[m
[32m+[m[32m    "type": "git",[m
[32m+[m[32m    "url": "git+ssh://git@github.com/mongodb/node-mongodb-native.git"[m
[32m+[m[32m  },[m
[32m+[m[32m  "bugs": {[m
[32m+[m[32m    "url": "http://github.com/mongodb/node-mongodb-native/issues"[m
[32m+[m[32m  },[m
   "dependencies": {[m
     "bson": "~0.2",[m
     "kerberos": "0.0.11",[m
     "readable-stream": "latest"[m
   },[m
[31m-  "description": "A node.js driver for MongoDB",[m
   "devDependencies": {[m
     "dox": "0.4.4",[m
[32m+[m[32m    "uglify-js": "1.2.5",[m
     "ejs": "0.6.1",[m
[31m-    "gleak": "0.5.0",[m
[31m-    "integra": "0.1.8",[m
[31m-    "markdown": "0.3.1",[m
[31m-    "mongodb-tools": "~1.0",[m
[31m-    "mongodb-version-manager": "^0.7.1",[m
[32m+[m[32m    "request": "2.12.0",[m
     "nodeunit": "0.7.3",[m
[32m+[m[32m    "markdown": "0.3.1",[m
[32m+[m[32m    "integra": "0.1.8",[m
     "optimist": "latest",[m
[31m-    "request": "2.12.0",[m
     "rimraf": "2.2.6",[m
     "semver": "4.1.0",[m
[31m-    "uglify-js": "1.2.5"[m
[32m+[m[32m    "gleak": "0.5.0",[m
[32m+[m[32m    "mongodb-tools": "~1.0",[m
[32m+[m[32m    "mongodb-version-manager": "^0.7.1"[m
   },[m
[32m+[m[32m  "optionalDependencies": {[m
[32m+[m[32m    "kerberos": "0.0.11",[m
[32m+[m[32m    "readable-stream": "latest"[m
[32m+[m[32m  },[m
[32m+[m[32m  "config": {[m
[32m+[m[32m    "native": false[m
[32m+[m[32m  },[m
[32m+[m[32m  "main": "./lib/mongodb/index",[m
[32m+[m[32m  "homepage": "http://mongodb.github.com/node-mongodb-native/",[m
   "directories": {[m
     "lib": "./lib/mongodb"[m
   },[m
[31m-  "dist": {[m
[31m-    "shasum": "f5b25c7f7df06c968cd5d3c68280adc9a6404591",[m
[31m-    "tarball": "http://registry.npmjs.org/mongodb/-/mongodb-1.4.39.tgz"[m
[31m-  },[m
   "engines": {[m
     "node": ">=0.6.19"[m
   },[m
[31m-  "gitHead": "62514af41e52a83116b6686ee36b8583dadde2ea",[m
[31m-  "homepage": "http://mongodb.github.com/node-mongodb-native/",[m
[31m-  "installable": true,[m
[31m-  "keywords": [[m
[31m-    "db",[m
[31m-    "driver",[m
[31m-    "mongo",[m
[31m-    "mongodb"[m
[31m-  ],[m
[32m+[m[32m  "scripts": {[m
[32m+[m[32m    "test": "node test/runner.js -t functional"[m
[32m+[m[32m  },[m
   "licenses": [[m
     {[m
       "type": "Apache License, Version 2.0",[m
       "url": "http://www.apache.org/licenses/LICENSE-2.0"[m
     }[m
   ],[m
[31m-  "main": "./lib/mongodb/index",[m
[32m+[m[32m  "gitHead": "62514af41e52a83116b6686ee36b8583dadde2ea",[m
[32m+[m[32m  "_id": "mongodb@1.4.39",[m
[32m+[m[32m  "_shasum": "f5b25c7f7df06c968cd5d3c68280adc9a6404591",[m
[32m+[m[32m  "_from": "mongodb@>=1.4.0 <1.5.0",[m
[32m+[m[32m  "_npmVersion": "2.11.3",[m
[32m+[m[32m  "_nodeVersion": "2.3.3",[m
[32m+[m[32m  "_npmUser": {[m
[32m+[m[32m    "name": "christkv",[m
[32m+[m[32m    "email": "christkv@gmail.com"[m
[32m+[m[32m  },[m
   "maintainers": [[m
     {[m
       "name": "christkv",[m
       "email": "christkv@gmail.com"[m
     }[m
   ],[m
[31m-  "name": "mongodb",[m
[31m-  "optionalDependencies": {[m
[31m-    "kerberos": "0.0.11",[m
[31m-    "readable-stream": "latest"[m
[31m-  },[m
[31m-  "repository": {[m
[31m-    "type": "git",[m
[31m-    "url": "http://github.com/mongodb/node-mongodb-native.git"[m
[31m-  },[m
[31m-  "scripts": {[m
[31m-    "test": "node test/runner.js -t functional"[m
[32m+[m[32m  "dist": {[m
[32m+[m[32m    "shasum": "f5b25c7f7df06c968cd5d3c68280adc9a6404591",[m
[32m+[m[32m    "tarball": "http://registry.npmjs.org/mongodb/-/mongodb-1.4.39.tgz"[m
   },[m
[31m-  "version": "1.4.39"[m
[32m+[m[32m  "_resolved": "https://registry.npmjs.org/mongodb/-/mongodb-1.4.39.tgz",[m
[32m+[m[32m  "readme": "ERROR: No README data found!"[m
 }[m
[1mdiff --git a/package.json b/package.json[m
[1mindex f36ec6d..a65dbb3 100644[m
[1m--- a/package.json[m
[1m+++ b/package.json[m
[36m@@ -19,7 +19,7 @@[m
     "express": "~4.13.1",[m
     "express-stormpath": "^2.3.0",[m
     "jade": "~1.11.0",[m
[31m-    "mongodb": "~1.4",[m
[32m+[m[32m    "mongodb": "^1.4.39",[m
     "monk": "~1.0.1",[m
     "morgan": "~1.6.1",[m
     "node-gyp": "^3.0.3",[m
